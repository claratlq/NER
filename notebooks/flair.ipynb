{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on:\n",
        "\n",
        "https://www.dominodatalab.com/blog/named-entity-recognition-ner-challenges-and-model\n",
        "\n",
        "https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF5NMHVx2BTS"
      },
      "source": [
        "# Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4HtQ4IPGJtX",
        "outputId": "00f15e83-9dde-486d-9f8a-1e2e17aa45c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: plot_keras_history in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (1.1.38)\n",
            "Requirement already satisfied: matplotlib in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from plot_keras_history) (3.6.2)\n",
            "Requirement already satisfied: pandas in /home/digitalhub/.local/lib/python3.8/site-packages (from plot_keras_history) (1.3.4)\n",
            "Requirement already satisfied: scipy in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from plot_keras_history) (1.4.1)\n",
            "Requirement already satisfied: support_developer>=1.0.2 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from plot_keras_history) (1.0.5)\n",
            "Requirement already satisfied: sanitize_ml_labels>=1.0.48 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from plot_keras_history) (1.0.50)\n",
            "Requirement already satisfied: compress_json in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from sanitize_ml_labels>=1.0.48->plot_keras_history) (1.0.8)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/digitalhub/.local/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.19 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/digitalhub/.local/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (9.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from matplotlib->plot_keras_history) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->plot_keras_history) (1.16.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from pandas->plot_keras_history) (2022.6)\n",
            "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/home/digitalhub/.pyenv/versions/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Requirement already satisfied: keras in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (2.11.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/home/digitalhub/.pyenv/versions/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Found existing installation: tensorflow 2.11.0\n",
            "Uninstalling tensorflow-2.11.0:\n",
            "  Successfully uninstalled tensorflow-2.11.0\n",
            "Requirement already satisfied: tensorflow in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (2.3.0)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "  Using cached h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorflow) (0.38.4)\n",
            "Requirement already satisfied: scipy==1.4.1 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
            "Collecting gast==0.3.3\n",
            "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "  Using cached tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Using cached numpy-1.18.5-cp38-cp38-manylinux1_x86_64.whl (20.6 MB)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (65.6.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/digitalhub/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/digitalhub/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/digitalhub/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Collecting importlib-metadata>=4.4\n",
            "  Using cached importlib_metadata-5.1.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/digitalhub/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/digitalhub/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/digitalhub/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.26.13)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
            "Installing collected packages: importlib-metadata, numpy, tensorflow-estimator, h5py, gast\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 3.10.1\n",
            "    Uninstalling importlib-metadata-3.10.1:\n",
            "      Successfully uninstalled importlib-metadata-3.10.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.7.0\n",
            "    Uninstalling h5py-3.7.0:\n",
            "      Successfully uninstalled h5py-3.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-gpu 2.7.0 requires keras<2.8,>=2.7.0rc0, but you have keras 2.11.0 which is incompatible.\n",
            "tensorflow-gpu 2.7.0 requires tensorflow-estimator<2.8,~=2.7.0rc0, but you have tensorflow-estimator 2.3.0 which is incompatible.\n",
            "matplotlib 3.6.2 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "konoha 4.6.5 requires importlib-metadata<4.0.0,>=3.7.0, but you have importlib-metadata 5.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 importlib-metadata-5.1.0 numpy-1.18.5 tensorflow-estimator-2.3.0\n",
            "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/home/digitalhub/.pyenv/versions/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Requirement already satisfied: pyconll in /home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages (3.1.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/home/digitalhub/.pyenv/versions/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-5js_wk4b\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-5js_wk4b\n"
          ]
        }
      ],
      "source": [
        "!pip install plot_keras_history\n",
        "!pip install keras\n",
        "!pip uninstall tensorflow -y\n",
        "!pip install tensorflow\n",
        "!pip install pyconll\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install conllu\n",
        "!pip install flair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuRfitpw2NAW"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M3XPDgA9FP0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-12 13:51:20.206422: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-12-12 13:51:20.206435: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "Using TensorFlow backend.\n",
            "Using TensorFlow backend.\n",
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'transpose_shape' from 'keras.utils.generic_utils' (/home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/utils/generic_utils.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [3], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multilabel_confusion_matrix\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_contrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_load_utils\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizers\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras_contrib/__init__.py:2\u001b[0m\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras_contrib/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[0;32m----> <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras_contrib/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras_contrib/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras_contrib/__init__.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras_contrib/backend/__init__.py:1\u001b[0m\n\u001b[0;32m----> <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras_contrib/backend/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras_contrib/backend/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m# We import all keras backend functions here,\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras_contrib/backend/__init__.py?line=3'>4</a>\u001b[0m \u001b[39m# so that files in this repo can import both\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras_contrib/backend/__init__.py?line=4'>5</a>\u001b[0m \u001b[39m# core and contrib backend functions with a\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras_contrib/backend/__init__.py?line=5'>6</a>\u001b[0m \u001b[39m# single import statement.\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras_contrib/backend/__init__.py?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m K\u001b[39m.\u001b[39mbackend() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtheano\u001b[39m\u001b[39m'\u001b[39m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/__init__.py:21\u001b[0m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/__init__.py?line=14'>15</a>\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/__init__.py?line=15'>16</a>\u001b[0m \n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/__init__.py?line=16'>17</a>\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/__init__.py?line=17'>18</a>\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/__init__.py?line=18'>19</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/__init__.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m---> <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/__init__.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/__init__.py?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/__init__.py?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/models/__init__.py:18\u001b[0m\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/models/__init__.py?line=0'>1</a>\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/models/__init__.py?line=1'>2</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/models/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/models/__init__.py?line=12'>13</a>\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/models/__init__.py?line=13'>14</a>\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/models/__init__.py?line=14'>15</a>\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/models/__init__.py?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/models/__init__.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/models/__init__.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/functional.py:26\u001b[0m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/functional.py?line=21'>22</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/functional.py?line=23'>24</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/functional.py?line=25'>26</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/functional.py?line=26'>27</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m layout_map \u001b[39mas\u001b[39;00m layout_map_lib\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/engine/functional.py?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/__init__.py:1\u001b[0m\n\u001b[0;32m----> <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mload_backend\u001b[39;00m \u001b[39mimport\u001b[39;00m epsilon\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mload_backend\u001b[39;00m \u001b[39mimport\u001b[39;00m set_epsilon\n\u001b[1;32m      <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mload_backend\u001b[39;00m \u001b[39mimport\u001b[39;00m floatx\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/load_backend.py:90\u001b[0m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/load_backend.py?line=87'>88</a>\u001b[0m \u001b[39melif\u001b[39;00m _BACKEND \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/load_backend.py?line=88'>89</a>\u001b[0m     sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39mUsing TensorFlow backend.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/load_backend.py?line=89'>90</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtensorflow_backend\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/load_backend.py?line=90'>91</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/load_backend.py?line=91'>92</a>\u001b[0m     \u001b[39m# Try and load external backend.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/load_backend.py?line=92'>93</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/tensorflow_backend.py:25\u001b[0m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/tensorflow_backend.py?line=21'>22</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/tensorflow_backend.py?line=22'>23</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdistutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m StrictVersion\n\u001b[0;32m---> <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/tensorflow_backend.py?line=24'>25</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m transpose_shape\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/tensorflow_backend.py?line=26'>27</a>\u001b[0m py_all \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m\n\u001b[1;32m     <a href='file:///home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/backend/tensorflow_backend.py?line=27'>28</a>\u001b[0m py_any \u001b[39m=\u001b[39m \u001b[39many\u001b[39m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'transpose_shape' from 'keras.utils.generic_utils' (/home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/keras/utils/generic_utils.py)"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import operator\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pyconll\n",
        "import tensorflow as tf\n",
        "import flair\n",
        "\n",
        "from plot_keras_history import plot_history\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from keras_contrib.utils import save_load_utils\n",
        "\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib import losses\n",
        "from keras_contrib import metrics\n",
        "\n",
        "from typing import List\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus, CONLL_03\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.embeddings import WordEmbeddings, TokenEmbeddings, FlairEmbeddings, PooledFlairEmbeddings, StackedEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0.11.3'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flair.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pre-trained library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/huggingface_hub/file_download.py:592: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:24:30,717 loading file /home/digitalhub/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
            "2022-12-12 11:24:32,061 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
            "SENTENCE: My name is Clara, I live in Singapore, I work for DSTA.\n",
            "----------------------------------------------------------------\n",
            "The following NER tags are found:\n",
            "Span[3:4]: \"Clara\" → PER (0.9991)\n",
            "Span[8:9]: \"Singapore\" → LOC (0.9993)\n",
            "Span[13:14]: \"DSTA\" → ORG (0.9981)\n",
            "\n",
            "\n",
            "SENTENCE: Missiles and other explosives or ammonium nitrate are dangerous.\n",
            "----------------------------------------------------------------\n",
            "The following NER tags are found:\n",
            "\n",
            "\n",
            "SENTENCE: Ammonium nitrate was also used in the IRA's bombing of London's Canary Wharf in 1996.\n",
            "----------------------------------------------------------------\n",
            "The following NER tags are found:\n",
            "Span[7:8]: \"IRA\" → ORG (1.0)\n",
            "Span[11:12]: \"London\" → LOC (0.9951)\n",
            "Span[13:15]: \"Canary Wharf\" → LOC (0.9991)\n",
            "\n",
            "\n",
            "SENTENCE: These have included such naval craft as the ship of the line, battleship, submarine, and aircraft carrier; aircraft such as the fighter, bomber, and helicopter; and ground vehicles such as the chariot and tank.\n",
            "----------------------------------------------------------------\n",
            "The following NER tags are found:\n",
            "\n",
            "\n",
            "SENTENCE: George Washington went to Washington\n",
            "----------------------------------------------------------------\n",
            "The following NER tags are found:\n",
            "Span[0:2]: \"George Washington\" → PER (0.9985)\n",
            "Span[4:5]: \"Washington\" → LOC (0.9706)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create some test sentences\n",
        "sentences = [\n",
        "            'My name is Clara, I live in Singapore, I work for DSTA.',\n",
        "            'Missiles and other explosives or ammonium nitrate are dangerous.',\n",
        "            'Ammonium nitrate was also used in the IRA\\'s bombing of London\\'s Canary Wharf in 1996.',\n",
        "            'These have included such naval craft as the ship of the line, battleship, submarine, and aircraft carrier; aircraft such as the fighter, bomber, and helicopter; and ground vehicles such as the chariot and tank.',\n",
        "            'George Washington went to Washington'\n",
        "            ]\n",
        "\n",
        "# load the NER tagger\n",
        "tagger = SequenceTagger.load('ner')\n",
        "\n",
        "for i in sentences: \n",
        "\n",
        "    sentence = Sentence(i)\n",
        "\n",
        "    # run NER over sentence\n",
        "    tagger.predict(sentence)\n",
        "\n",
        "    # print sentence\n",
        "    print('SENTENCE: ' + i)\n",
        "    print('----------------------------------------------------------------')\n",
        "\n",
        "    # print predicted NER spans\n",
        "    print('The following NER tags are found:')\n",
        "    # iterate over entities and print\n",
        "    for entity in sentence.get_spans('ner'):\n",
        "        print(entity)\n",
        "    \n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stacked (Word + Flair forward + backward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orqxebPu3cBh"
      },
      "source": [
        "## On domain-specific (re3d) data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:11:33,761 Reading data from entity-recognition-datasets-master/data/re3d/CONLL-format/data/splits\n",
            "2022-12-08 10:11:33,763 Train: entity-recognition-datasets-master/data/re3d/CONLL-format/data/splits/train.conll\n",
            "2022-12-08 10:11:33,763 Dev: entity-recognition-datasets-master/data/re3d/CONLL-format/data/splits/val.conll\n",
            "2022-12-08 10:11:33,764 Test: entity-recognition-datasets-master/data/re3d/CONLL-format/data/splits/test.conll\n"
          ]
        }
      ],
      "source": [
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = 'entity-recognition-datasets-master/data/re3d/CONLL-format/data/splits'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.conll',\n",
        "                              test_file='test.conll',\n",
        "                              dev_file='val.conll')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"Operation Steel Curtain ( Arabic : ا ل ح ج ا ب ا ل ف و ل ا ذ ي Al Hejab Elfulathi ) was a military operation executed by coalition forces in early November 2005 to reduce the flow of foreign insurgents crossing the border and joining the Iraqi insurgency .\" → [\"coalition forces\"/Organisation, \"early November 2005\"/Temporal, \"foreign insurgents\"/Organisation, \"Iraqi\"/Nationality]\n",
            "771\n"
          ]
        }
      ],
      "source": [
        "print(corpus.train[0].to_tagged_string('ner'))\n",
        "print(len(corpus.train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:11:34,192 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "771it [00:00, 46820.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:11:34,246 Dictionary created for label 'ner' with 11 values: Organisation (seen 1113 times), Location (seen 647 times), Person (seen 415 times), Temporal (seen 179 times), Quantity (seen 151 times), Weapon (seen 81 times), DocumentReference (seen 50 times), MilitaryPlatform (seen 48 times), Nationality (seen 34 times), Money (seen 20 times)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Define tags to predict\n",
        "tag_type = 'ner'# make tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_label_dictionary(label_type=tag_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Embeddings\n",
        "\n",
        "from typing import List\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_types = [\n",
        "    # init standard GloVe embedding\n",
        "    WordEmbeddings('glove'),\n",
        "\n",
        "    # init Flair forward and backwards embeddings\n",
        "    FlairEmbeddings('news-forward'),\n",
        "    FlairEmbeddings('news-backward'),\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:11:37,419 SequenceTagger predicts: Dictionary with 41 tags: O, S-Organisation, B-Organisation, E-Organisation, I-Organisation, S-Location, B-Location, E-Location, I-Location, S-Person, B-Person, E-Person, I-Person, S-Temporal, B-Temporal, E-Temporal, I-Temporal, S-Quantity, B-Quantity, E-Quantity, I-Quantity, S-Weapon, B-Weapon, E-Weapon, I-Weapon, S-DocumentReference, B-DocumentReference, E-DocumentReference, I-DocumentReference, S-MilitaryPlatform, B-MilitaryPlatform, E-MilitaryPlatform, I-MilitaryPlatform, S-Nationality, B-Nationality, E-Nationality, I-Nationality, S-Money, B-Money, E-Money, I-Money\n",
            "SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
            "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=43, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\n",
            "2022-12-08 10:11:37,559 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:11:37,560 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
            "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=43, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-12-08 10:11:37,560 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:11:37,561 Corpus: \"Corpus: 771 train + 98 dev + 96 test sentences\"\n",
            "2022-12-08 10:11:37,561 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:11:37,562 Parameters:\n",
            "2022-12-08 10:11:37,563  - learning_rate: \"0.100000\"\n",
            "2022-12-08 10:11:37,564  - mini_batch_size: \"32\"\n",
            "2022-12-08 10:11:37,564  - patience: \"3\"\n",
            "2022-12-08 10:11:37,565  - anneal_factor: \"0.5\"\n",
            "2022-12-08 10:11:37,566  - max_epochs: \"150\"\n",
            "2022-12-08 10:11:37,566  - shuffle: \"True\"\n",
            "2022-12-08 10:11:37,567  - train_with_dev: \"False\"\n",
            "2022-12-08 10:11:37,567  - batch_growth_annealing: \"False\"\n",
            "2022-12-08 10:11:37,568 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:11:37,568 Model training base path: \"resources/taggers/re3d-ner\"\n",
            "2022-12-08 10:11:37,569 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:11:37,569 Device: cpu\n",
            "2022-12-08 10:11:37,569 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:11:37,570 Embeddings storage mode: cpu\n",
            "2022-12-08 10:11:37,570 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/flair/trainers/trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:11:45,608 epoch 1 - iter 2/25 - loss 3.51568870 - samples/sec: 7.96 - lr: 0.100000\n",
            "2022-12-08 10:11:53,708 epoch 1 - iter 4/25 - loss 2.86969593 - samples/sec: 7.90 - lr: 0.100000\n",
            "2022-12-08 10:12:00,867 epoch 1 - iter 6/25 - loss 2.60209506 - samples/sec: 8.94 - lr: 0.100000\n",
            "2022-12-08 10:12:09,591 epoch 1 - iter 8/25 - loss 2.39064374 - samples/sec: 7.34 - lr: 0.100000\n",
            "2022-12-08 10:12:17,554 epoch 1 - iter 10/25 - loss 2.27275103 - samples/sec: 8.04 - lr: 0.100000\n",
            "2022-12-08 10:12:25,963 epoch 1 - iter 12/25 - loss 2.16142430 - samples/sec: 7.61 - lr: 0.100000\n",
            "2022-12-08 10:12:41,867 epoch 1 - iter 14/25 - loss 2.13654410 - samples/sec: 4.02 - lr: 0.100000\n",
            "2022-12-08 10:12:51,122 epoch 1 - iter 16/25 - loss 2.07022120 - samples/sec: 6.92 - lr: 0.100000\n",
            "2022-12-08 10:12:59,732 epoch 1 - iter 18/25 - loss 2.03364964 - samples/sec: 7.43 - lr: 0.100000\n",
            "2022-12-08 10:13:09,244 epoch 1 - iter 20/25 - loss 2.03030997 - samples/sec: 6.73 - lr: 0.100000\n",
            "2022-12-08 10:13:20,845 epoch 1 - iter 22/25 - loss 2.01011942 - samples/sec: 5.52 - lr: 0.100000\n",
            "2022-12-08 10:13:29,675 epoch 1 - iter 24/25 - loss 2.00210669 - samples/sec: 7.25 - lr: 0.100000\n",
            "2022-12-08 10:13:30,294 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:13:30,295 EPOCH 1 done: loss 1.9992 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:12<00:00,  3.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:13:42,610 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:13:42,620 DEV : loss 1.4683295488357544 - f1-score (micro avg)  0.0\n",
            "2022-12-08 10:13:42,631 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:13:42,632 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:13:45,831 epoch 2 - iter 2/25 - loss 1.83819530 - samples/sec: 20.01 - lr: 0.100000\n",
            "2022-12-08 10:13:46,979 epoch 2 - iter 4/25 - loss 1.71710311 - samples/sec: 55.84 - lr: 0.100000\n",
            "2022-12-08 10:13:48,349 epoch 2 - iter 6/25 - loss 1.66848926 - samples/sec: 46.74 - lr: 0.100000\n",
            "2022-12-08 10:13:50,002 epoch 2 - iter 8/25 - loss 1.66514727 - samples/sec: 38.75 - lr: 0.100000\n",
            "2022-12-08 10:13:51,425 epoch 2 - iter 10/25 - loss 1.64207479 - samples/sec: 45.02 - lr: 0.100000\n",
            "2022-12-08 10:13:52,933 epoch 2 - iter 12/25 - loss 1.59278062 - samples/sec: 42.49 - lr: 0.100000\n",
            "2022-12-08 10:13:54,146 epoch 2 - iter 14/25 - loss 1.58561721 - samples/sec: 52.81 - lr: 0.100000\n",
            "2022-12-08 10:13:55,577 epoch 2 - iter 16/25 - loss 1.58154899 - samples/sec: 44.76 - lr: 0.100000\n",
            "2022-12-08 10:13:56,852 epoch 2 - iter 18/25 - loss 1.56667962 - samples/sec: 50.26 - lr: 0.100000\n",
            "2022-12-08 10:13:58,470 epoch 2 - iter 20/25 - loss 1.58325020 - samples/sec: 39.57 - lr: 0.100000\n",
            "2022-12-08 10:13:59,741 epoch 2 - iter 22/25 - loss 1.56770802 - samples/sec: 50.42 - lr: 0.100000\n",
            "2022-12-08 10:14:01,128 epoch 2 - iter 24/25 - loss 1.55823232 - samples/sec: 46.18 - lr: 0.100000\n",
            "2022-12-08 10:14:01,247 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:14:01,247 EPOCH 2 done: loss 1.5554 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:14:01,995 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:14:02,003 DEV : loss 1.1850744485855103 - f1-score (micro avg)  0.1035\n",
            "2022-12-08 10:14:02,013 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:14:02,014 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:14:02,633 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:14:03,810 epoch 3 - iter 2/25 - loss 1.30107398 - samples/sec: 54.47 - lr: 0.100000\n",
            "2022-12-08 10:14:05,446 epoch 3 - iter 4/25 - loss 1.29285517 - samples/sec: 39.14 - lr: 0.100000\n",
            "2022-12-08 10:14:08,171 epoch 3 - iter 6/25 - loss 1.30280647 - samples/sec: 23.50 - lr: 0.100000\n",
            "2022-12-08 10:14:09,686 epoch 3 - iter 8/25 - loss 1.28689238 - samples/sec: 42.30 - lr: 0.100000\n",
            "2022-12-08 10:14:11,152 epoch 3 - iter 10/25 - loss 1.29003280 - samples/sec: 43.68 - lr: 0.100000\n",
            "2022-12-08 10:14:12,504 epoch 3 - iter 12/25 - loss 1.29638095 - samples/sec: 47.36 - lr: 0.100000\n",
            "2022-12-08 10:14:13,683 epoch 3 - iter 14/25 - loss 1.28623953 - samples/sec: 54.37 - lr: 0.100000\n",
            "2022-12-08 10:14:15,177 epoch 3 - iter 16/25 - loss 1.29399373 - samples/sec: 42.88 - lr: 0.100000\n",
            "2022-12-08 10:14:16,633 epoch 3 - iter 18/25 - loss 1.30351489 - samples/sec: 43.99 - lr: 0.100000\n",
            "2022-12-08 10:14:18,139 epoch 3 - iter 20/25 - loss 1.30074344 - samples/sec: 42.52 - lr: 0.100000\n",
            "2022-12-08 10:14:19,281 epoch 3 - iter 22/25 - loss 1.29130528 - samples/sec: 56.10 - lr: 0.100000\n",
            "2022-12-08 10:14:20,700 epoch 3 - iter 24/25 - loss 1.28223501 - samples/sec: 45.17 - lr: 0.100000\n",
            "2022-12-08 10:14:20,821 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:14:20,822 EPOCH 3 done: loss 1.2824 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:14:21,590 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:14:21,598 DEV : loss 0.9740524888038635 - f1-score (micro avg)  0.2033\n",
            "2022-12-08 10:14:21,608 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:14:21,609 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:14:22,310 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:14:24,023 epoch 4 - iter 2/25 - loss 1.11493661 - samples/sec: 37.41 - lr: 0.100000\n",
            "2022-12-08 10:14:25,519 epoch 4 - iter 4/25 - loss 1.11558232 - samples/sec: 42.82 - lr: 0.100000\n",
            "2022-12-08 10:14:27,213 epoch 4 - iter 6/25 - loss 1.12761700 - samples/sec: 37.80 - lr: 0.100000\n",
            "2022-12-08 10:14:28,686 epoch 4 - iter 8/25 - loss 1.10621057 - samples/sec: 43.48 - lr: 0.100000\n",
            "2022-12-08 10:14:30,096 epoch 4 - iter 10/25 - loss 1.10617279 - samples/sec: 45.44 - lr: 0.100000\n",
            "2022-12-08 10:14:31,636 epoch 4 - iter 12/25 - loss 1.08666927 - samples/sec: 41.59 - lr: 0.100000\n",
            "2022-12-08 10:14:32,696 epoch 4 - iter 14/25 - loss 1.07524849 - samples/sec: 60.45 - lr: 0.100000\n",
            "2022-12-08 10:14:33,990 epoch 4 - iter 16/25 - loss 1.06662850 - samples/sec: 49.52 - lr: 0.100000\n",
            "2022-12-08 10:14:37,200 epoch 4 - iter 18/25 - loss 1.05928145 - samples/sec: 19.95 - lr: 0.100000\n",
            "2022-12-08 10:14:39,157 epoch 4 - iter 20/25 - loss 1.05716434 - samples/sec: 32.73 - lr: 0.100000\n",
            "2022-12-08 10:14:40,214 epoch 4 - iter 22/25 - loss 1.05081078 - samples/sec: 60.62 - lr: 0.100000\n",
            "2022-12-08 10:14:41,496 epoch 4 - iter 24/25 - loss 1.04821101 - samples/sec: 49.96 - lr: 0.100000\n",
            "2022-12-08 10:14:41,618 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:14:41,619 EPOCH 4 done: loss 1.0477 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:14:42,427 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:14:42,436 DEV : loss 0.773407518863678 - f1-score (micro avg)  0.3082\n",
            "2022-12-08 10:14:42,448 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:14:42,449 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:14:43,209 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:14:45,470 epoch 5 - iter 2/25 - loss 0.99210726 - samples/sec: 28.35 - lr: 0.100000\n",
            "2022-12-08 10:14:47,648 epoch 5 - iter 4/25 - loss 0.95925124 - samples/sec: 29.40 - lr: 0.100000\n",
            "2022-12-08 10:14:48,769 epoch 5 - iter 6/25 - loss 0.95316990 - samples/sec: 57.19 - lr: 0.100000\n",
            "2022-12-08 10:14:50,002 epoch 5 - iter 8/25 - loss 0.94404477 - samples/sec: 51.97 - lr: 0.100000\n",
            "2022-12-08 10:14:51,323 epoch 5 - iter 10/25 - loss 0.92936436 - samples/sec: 48.48 - lr: 0.100000\n",
            "2022-12-08 10:14:52,497 epoch 5 - iter 12/25 - loss 0.91967761 - samples/sec: 54.57 - lr: 0.100000\n",
            "2022-12-08 10:14:54,468 epoch 5 - iter 14/25 - loss 0.91912850 - samples/sec: 32.49 - lr: 0.100000\n",
            "2022-12-08 10:14:56,143 epoch 5 - iter 16/25 - loss 0.90496281 - samples/sec: 38.25 - lr: 0.100000\n",
            "2022-12-08 10:14:57,345 epoch 5 - iter 18/25 - loss 0.89386433 - samples/sec: 53.29 - lr: 0.100000\n",
            "2022-12-08 10:15:00,631 epoch 5 - iter 20/25 - loss 0.89051932 - samples/sec: 19.49 - lr: 0.100000\n",
            "2022-12-08 10:15:02,038 epoch 5 - iter 22/25 - loss 0.88398969 - samples/sec: 45.54 - lr: 0.100000\n",
            "2022-12-08 10:15:03,373 epoch 5 - iter 24/25 - loss 0.87729481 - samples/sec: 48.02 - lr: 0.100000\n",
            "2022-12-08 10:15:03,485 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:15:03,486 EPOCH 5 done: loss 0.8778 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:15:04,277 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:15:04,286 DEV : loss 0.7003260254859924 - f1-score (micro avg)  0.3927\n",
            "2022-12-08 10:15:04,296 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:15:04,296 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:15:05,062 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:15:06,676 epoch 6 - iter 2/25 - loss 0.74267075 - samples/sec: 39.69 - lr: 0.100000\n",
            "2022-12-08 10:15:08,297 epoch 6 - iter 4/25 - loss 0.82372457 - samples/sec: 39.51 - lr: 0.100000\n",
            "2022-12-08 10:15:09,723 epoch 6 - iter 6/25 - loss 0.82978417 - samples/sec: 44.93 - lr: 0.100000\n",
            "2022-12-08 10:15:11,357 epoch 6 - iter 8/25 - loss 0.80842014 - samples/sec: 39.19 - lr: 0.100000\n",
            "2022-12-08 10:15:12,790 epoch 6 - iter 10/25 - loss 0.81095840 - samples/sec: 44.70 - lr: 0.100000\n",
            "2022-12-08 10:15:15,968 epoch 6 - iter 12/25 - loss 0.80629323 - samples/sec: 20.15 - lr: 0.100000\n",
            "2022-12-08 10:15:17,369 epoch 6 - iter 14/25 - loss 0.80344242 - samples/sec: 45.71 - lr: 0.100000\n",
            "2022-12-08 10:15:18,656 epoch 6 - iter 16/25 - loss 0.79272194 - samples/sec: 49.80 - lr: 0.100000\n",
            "2022-12-08 10:15:19,919 epoch 6 - iter 18/25 - loss 0.79293335 - samples/sec: 50.70 - lr: 0.100000\n",
            "2022-12-08 10:15:21,483 epoch 6 - iter 20/25 - loss 0.79308917 - samples/sec: 40.97 - lr: 0.100000\n",
            "2022-12-08 10:15:23,373 epoch 6 - iter 22/25 - loss 0.79476190 - samples/sec: 33.89 - lr: 0.100000\n",
            "2022-12-08 10:15:24,566 epoch 6 - iter 24/25 - loss 0.78566588 - samples/sec: 53.70 - lr: 0.100000\n",
            "2022-12-08 10:15:24,698 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:15:24,699 EPOCH 6 done: loss 0.7856 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:15:25,658 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:15:25,667 DEV : loss 0.6193915009498596 - f1-score (micro avg)  0.524\n",
            "2022-12-08 10:15:25,677 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:15:25,679 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:15:26,372 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:15:27,713 epoch 7 - iter 2/25 - loss 0.85784826 - samples/sec: 47.79 - lr: 0.100000\n",
            "2022-12-08 10:15:28,965 epoch 7 - iter 4/25 - loss 0.74221494 - samples/sec: 51.17 - lr: 0.100000\n",
            "2022-12-08 10:15:32,053 epoch 7 - iter 6/25 - loss 0.73976764 - samples/sec: 20.73 - lr: 0.100000\n",
            "2022-12-08 10:15:33,571 epoch 7 - iter 8/25 - loss 0.72725455 - samples/sec: 42.21 - lr: 0.100000\n",
            "2022-12-08 10:15:34,794 epoch 7 - iter 10/25 - loss 0.72131224 - samples/sec: 52.39 - lr: 0.100000\n",
            "2022-12-08 10:15:36,310 epoch 7 - iter 12/25 - loss 0.72544215 - samples/sec: 42.27 - lr: 0.100000\n",
            "2022-12-08 10:15:37,783 epoch 7 - iter 14/25 - loss 0.73419676 - samples/sec: 43.47 - lr: 0.100000\n",
            "2022-12-08 10:15:39,521 epoch 7 - iter 16/25 - loss 0.72790303 - samples/sec: 36.86 - lr: 0.100000\n",
            "2022-12-08 10:15:40,942 epoch 7 - iter 18/25 - loss 0.71553456 - samples/sec: 45.07 - lr: 0.100000\n",
            "2022-12-08 10:15:42,405 epoch 7 - iter 20/25 - loss 0.70962137 - samples/sec: 43.79 - lr: 0.100000\n",
            "2022-12-08 10:15:43,892 epoch 7 - iter 22/25 - loss 0.70422887 - samples/sec: 43.06 - lr: 0.100000\n",
            "2022-12-08 10:15:45,260 epoch 7 - iter 24/25 - loss 0.69748167 - samples/sec: 46.83 - lr: 0.100000\n",
            "2022-12-08 10:15:45,390 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:15:45,391 EPOCH 7 done: loss 0.6991 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:15:46,247 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:15:46,256 DEV : loss 0.5624843239784241 - f1-score (micro avg)  0.5385\n",
            "2022-12-08 10:15:46,267 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:15:46,269 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:15:46,969 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:15:48,575 epoch 8 - iter 2/25 - loss 0.63948803 - samples/sec: 39.88 - lr: 0.100000\n",
            "2022-12-08 10:15:49,743 epoch 8 - iter 4/25 - loss 0.66810920 - samples/sec: 54.89 - lr: 0.100000\n",
            "2022-12-08 10:15:52,942 epoch 8 - iter 6/25 - loss 0.65025167 - samples/sec: 20.01 - lr: 0.100000\n",
            "2022-12-08 10:15:54,036 epoch 8 - iter 8/25 - loss 0.63575657 - samples/sec: 58.60 - lr: 0.100000\n",
            "2022-12-08 10:15:55,514 epoch 8 - iter 10/25 - loss 0.64579918 - samples/sec: 43.31 - lr: 0.100000\n",
            "2022-12-08 10:15:57,199 epoch 8 - iter 12/25 - loss 0.64623779 - samples/sec: 38.02 - lr: 0.100000\n",
            "2022-12-08 10:15:58,844 epoch 8 - iter 14/25 - loss 0.64253093 - samples/sec: 38.93 - lr: 0.100000\n",
            "2022-12-08 10:16:00,139 epoch 8 - iter 16/25 - loss 0.65058445 - samples/sec: 49.48 - lr: 0.100000\n",
            "2022-12-08 10:16:01,876 epoch 8 - iter 18/25 - loss 0.64276074 - samples/sec: 36.90 - lr: 0.100000\n",
            "2022-12-08 10:16:03,192 epoch 8 - iter 20/25 - loss 0.63730409 - samples/sec: 48.66 - lr: 0.100000\n",
            "2022-12-08 10:16:04,684 epoch 8 - iter 22/25 - loss 0.63823385 - samples/sec: 42.95 - lr: 0.100000\n",
            "2022-12-08 10:16:05,703 epoch 8 - iter 24/25 - loss 0.64188021 - samples/sec: 62.88 - lr: 0.100000\n",
            "2022-12-08 10:16:05,835 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:16:05,836 EPOCH 8 done: loss 0.6433 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:16:06,660 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:16:06,669 DEV : loss 0.5259146690368652 - f1-score (micro avg)  0.5874\n",
            "2022-12-08 10:16:06,679 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:16:06,680 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:16:07,372 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:16:08,730 epoch 9 - iter 2/25 - loss 0.51153246 - samples/sec: 47.19 - lr: 0.100000\n",
            "2022-12-08 10:16:10,255 epoch 9 - iter 4/25 - loss 0.53828096 - samples/sec: 41.98 - lr: 0.100000\n",
            "2022-12-08 10:16:11,696 epoch 9 - iter 6/25 - loss 0.55221275 - samples/sec: 44.46 - lr: 0.100000\n",
            "2022-12-08 10:16:13,126 epoch 9 - iter 8/25 - loss 0.56123693 - samples/sec: 44.79 - lr: 0.100000\n",
            "2022-12-08 10:16:14,734 epoch 9 - iter 10/25 - loss 0.55983643 - samples/sec: 39.85 - lr: 0.100000\n",
            "2022-12-08 10:16:15,902 epoch 9 - iter 12/25 - loss 0.56586578 - samples/sec: 54.84 - lr: 0.100000\n",
            "2022-12-08 10:16:17,080 epoch 9 - iter 14/25 - loss 0.58337131 - samples/sec: 54.37 - lr: 0.100000\n",
            "2022-12-08 10:16:18,278 epoch 9 - iter 16/25 - loss 0.59160690 - samples/sec: 53.50 - lr: 0.100000\n",
            "2022-12-08 10:16:20,049 epoch 9 - iter 18/25 - loss 0.61219045 - samples/sec: 36.18 - lr: 0.100000\n",
            "2022-12-08 10:16:21,308 epoch 9 - iter 20/25 - loss 0.60683462 - samples/sec: 50.85 - lr: 0.100000\n",
            "2022-12-08 10:16:24,364 epoch 9 - iter 22/25 - loss 0.60079855 - samples/sec: 20.95 - lr: 0.100000\n",
            "2022-12-08 10:16:25,542 epoch 9 - iter 24/25 - loss 0.59553263 - samples/sec: 54.39 - lr: 0.100000\n",
            "2022-12-08 10:16:25,648 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:16:25,650 EPOCH 9 done: loss 0.5956 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:16:26,413 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:16:26,423 DEV : loss 0.5068708062171936 - f1-score (micro avg)  0.5795\n",
            "2022-12-08 10:16:26,438 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:16:26,439 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:16:27,835 epoch 10 - iter 2/25 - loss 0.66371172 - samples/sec: 45.86 - lr: 0.100000\n",
            "2022-12-08 10:16:29,224 epoch 10 - iter 4/25 - loss 0.59798666 - samples/sec: 46.14 - lr: 0.100000\n",
            "2022-12-08 10:16:30,638 epoch 10 - iter 6/25 - loss 0.56134841 - samples/sec: 45.31 - lr: 0.100000\n",
            "2022-12-08 10:16:31,982 epoch 10 - iter 8/25 - loss 0.52949410 - samples/sec: 47.66 - lr: 0.100000\n",
            "2022-12-08 10:16:35,216 epoch 10 - iter 10/25 - loss 0.52241194 - samples/sec: 19.80 - lr: 0.100000\n",
            "2022-12-08 10:16:36,994 epoch 10 - iter 12/25 - loss 0.54326639 - samples/sec: 36.02 - lr: 0.100000\n",
            "2022-12-08 10:16:38,456 epoch 10 - iter 14/25 - loss 0.56072163 - samples/sec: 43.83 - lr: 0.100000\n",
            "2022-12-08 10:16:39,829 epoch 10 - iter 16/25 - loss 0.55981717 - samples/sec: 46.64 - lr: 0.100000\n",
            "2022-12-08 10:16:41,010 epoch 10 - iter 18/25 - loss 0.55916519 - samples/sec: 54.26 - lr: 0.100000\n",
            "2022-12-08 10:16:42,038 epoch 10 - iter 20/25 - loss 0.55597525 - samples/sec: 62.33 - lr: 0.100000\n",
            "2022-12-08 10:16:43,211 epoch 10 - iter 22/25 - loss 0.55687138 - samples/sec: 54.63 - lr: 0.100000\n",
            "2022-12-08 10:16:44,340 epoch 10 - iter 24/25 - loss 0.55681203 - samples/sec: 56.79 - lr: 0.100000\n",
            "2022-12-08 10:16:44,445 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:16:44,446 EPOCH 10 done: loss 0.5565 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:16:45,273 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:16:45,282 DEV : loss 0.457415372133255 - f1-score (micro avg)  0.6299\n",
            "2022-12-08 10:16:45,291 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:16:45,293 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:16:45,964 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:16:47,106 epoch 11 - iter 2/25 - loss 0.42374633 - samples/sec: 56.21 - lr: 0.100000\n",
            "2022-12-08 10:16:48,578 epoch 11 - iter 4/25 - loss 0.48767035 - samples/sec: 43.53 - lr: 0.100000\n",
            "2022-12-08 10:16:49,732 epoch 11 - iter 6/25 - loss 0.49617179 - samples/sec: 55.50 - lr: 0.100000\n",
            "2022-12-08 10:16:51,107 epoch 11 - iter 8/25 - loss 0.52632470 - samples/sec: 46.59 - lr: 0.100000\n",
            "2022-12-08 10:16:54,083 epoch 11 - iter 10/25 - loss 0.53012003 - samples/sec: 21.51 - lr: 0.100000\n",
            "2022-12-08 10:16:55,269 epoch 11 - iter 12/25 - loss 0.52789318 - samples/sec: 54.03 - lr: 0.100000\n",
            "2022-12-08 10:16:56,676 epoch 11 - iter 14/25 - loss 0.52976284 - samples/sec: 45.52 - lr: 0.100000\n",
            "2022-12-08 10:16:57,844 epoch 11 - iter 16/25 - loss 0.53128968 - samples/sec: 54.85 - lr: 0.100000\n",
            "2022-12-08 10:16:59,527 epoch 11 - iter 18/25 - loss 0.52407197 - samples/sec: 38.09 - lr: 0.100000\n",
            "2022-12-08 10:17:00,876 epoch 11 - iter 20/25 - loss 0.53070666 - samples/sec: 47.49 - lr: 0.100000\n",
            "2022-12-08 10:17:01,941 epoch 11 - iter 22/25 - loss 0.52920288 - samples/sec: 60.16 - lr: 0.100000\n",
            "2022-12-08 10:17:03,549 epoch 11 - iter 24/25 - loss 0.53689313 - samples/sec: 39.85 - lr: 0.100000\n",
            "2022-12-08 10:17:03,661 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:17:03,662 EPOCH 11 done: loss 0.5366 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:17:04,493 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:17:04,503 DEV : loss 0.44067618250846863 - f1-score (micro avg)  0.6128\n",
            "2022-12-08 10:17:04,512 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:17:04,513 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:17:07,706 epoch 12 - iter 2/25 - loss 0.42740158 - samples/sec: 20.06 - lr: 0.100000\n",
            "2022-12-08 10:17:09,067 epoch 12 - iter 4/25 - loss 0.45377713 - samples/sec: 47.07 - lr: 0.100000\n",
            "2022-12-08 10:17:10,545 epoch 12 - iter 6/25 - loss 0.46476415 - samples/sec: 43.35 - lr: 0.100000\n",
            "2022-12-08 10:17:11,876 epoch 12 - iter 8/25 - loss 0.47878360 - samples/sec: 48.11 - lr: 0.100000\n",
            "2022-12-08 10:17:13,174 epoch 12 - iter 10/25 - loss 0.47681265 - samples/sec: 49.37 - lr: 0.100000\n",
            "2022-12-08 10:17:14,550 epoch 12 - iter 12/25 - loss 0.48289086 - samples/sec: 46.53 - lr: 0.100000\n",
            "2022-12-08 10:17:15,944 epoch 12 - iter 14/25 - loss 0.48207630 - samples/sec: 45.97 - lr: 0.100000\n",
            "2022-12-08 10:17:16,939 epoch 12 - iter 16/25 - loss 0.47586139 - samples/sec: 64.45 - lr: 0.100000\n",
            "2022-12-08 10:17:18,029 epoch 12 - iter 18/25 - loss 0.48320729 - samples/sec: 58.78 - lr: 0.100000\n",
            "2022-12-08 10:17:19,267 epoch 12 - iter 20/25 - loss 0.49007823 - samples/sec: 51.73 - lr: 0.100000\n",
            "2022-12-08 10:17:20,719 epoch 12 - iter 22/25 - loss 0.49112404 - samples/sec: 44.14 - lr: 0.100000\n",
            "2022-12-08 10:17:21,988 epoch 12 - iter 24/25 - loss 0.48562535 - samples/sec: 50.51 - lr: 0.100000\n",
            "2022-12-08 10:17:22,104 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:17:22,106 EPOCH 12 done: loss 0.4868 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:17:22,884 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:17:22,892 DEV : loss 0.44053924083709717 - f1-score (micro avg)  0.6171\n",
            "2022-12-08 10:17:22,901 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:17:22,902 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:17:24,346 epoch 13 - iter 2/25 - loss 0.37353289 - samples/sec: 44.34 - lr: 0.100000\n",
            "2022-12-08 10:17:27,369 epoch 13 - iter 4/25 - loss 0.44012835 - samples/sec: 21.18 - lr: 0.100000\n",
            "2022-12-08 10:17:28,638 epoch 13 - iter 6/25 - loss 0.44040131 - samples/sec: 50.47 - lr: 0.100000\n",
            "2022-12-08 10:17:30,160 epoch 13 - iter 8/25 - loss 0.43021018 - samples/sec: 42.10 - lr: 0.100000\n",
            "2022-12-08 10:17:31,579 epoch 13 - iter 10/25 - loss 0.44934240 - samples/sec: 45.14 - lr: 0.100000\n",
            "2022-12-08 10:17:32,990 epoch 13 - iter 12/25 - loss 0.45628293 - samples/sec: 45.38 - lr: 0.100000\n",
            "2022-12-08 10:17:34,464 epoch 13 - iter 14/25 - loss 0.46842749 - samples/sec: 43.47 - lr: 0.100000\n",
            "2022-12-08 10:17:36,191 epoch 13 - iter 16/25 - loss 0.46760283 - samples/sec: 37.09 - lr: 0.100000\n",
            "2022-12-08 10:17:37,888 epoch 13 - iter 18/25 - loss 0.46250015 - samples/sec: 37.76 - lr: 0.100000\n",
            "2022-12-08 10:17:39,189 epoch 13 - iter 20/25 - loss 0.46029400 - samples/sec: 49.23 - lr: 0.100000\n",
            "2022-12-08 10:17:40,690 epoch 13 - iter 22/25 - loss 0.46583294 - samples/sec: 42.68 - lr: 0.100000\n",
            "2022-12-08 10:17:41,914 epoch 13 - iter 24/25 - loss 0.46342745 - samples/sec: 52.35 - lr: 0.100000\n",
            "2022-12-08 10:17:42,068 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:17:42,069 EPOCH 13 done: loss 0.4652 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:17:42,838 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:17:42,847 DEV : loss 0.39791473746299744 - f1-score (micro avg)  0.649\n",
            "2022-12-08 10:17:42,857 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:17:42,859 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:17:43,576 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:17:45,179 epoch 14 - iter 2/25 - loss 0.40257160 - samples/sec: 39.97 - lr: 0.100000\n",
            "2022-12-08 10:17:46,712 epoch 14 - iter 4/25 - loss 0.41388396 - samples/sec: 41.79 - lr: 0.100000\n",
            "2022-12-08 10:17:48,550 epoch 14 - iter 6/25 - loss 0.43787537 - samples/sec: 34.85 - lr: 0.100000\n",
            "2022-12-08 10:17:50,415 epoch 14 - iter 8/25 - loss 0.44537603 - samples/sec: 34.34 - lr: 0.100000\n",
            "2022-12-08 10:17:51,651 epoch 14 - iter 10/25 - loss 0.43559544 - samples/sec: 51.86 - lr: 0.100000\n",
            "2022-12-08 10:17:52,929 epoch 14 - iter 12/25 - loss 0.42713021 - samples/sec: 50.11 - lr: 0.100000\n",
            "2022-12-08 10:17:54,173 epoch 14 - iter 14/25 - loss 0.43056395 - samples/sec: 51.52 - lr: 0.100000\n",
            "2022-12-08 10:17:55,748 epoch 14 - iter 16/25 - loss 0.43103205 - samples/sec: 40.69 - lr: 0.100000\n",
            "2022-12-08 10:17:58,936 epoch 14 - iter 18/25 - loss 0.42448619 - samples/sec: 20.08 - lr: 0.100000\n",
            "2022-12-08 10:18:00,493 epoch 14 - iter 20/25 - loss 0.43399674 - samples/sec: 41.12 - lr: 0.100000\n",
            "2022-12-08 10:18:01,510 epoch 14 - iter 22/25 - loss 0.43353028 - samples/sec: 63.03 - lr: 0.100000\n",
            "2022-12-08 10:18:02,710 epoch 14 - iter 24/25 - loss 0.44471813 - samples/sec: 53.39 - lr: 0.100000\n",
            "2022-12-08 10:18:02,799 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:18:02,800 EPOCH 14 done: loss 0.4449 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:18:03,658 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:18:03,665 DEV : loss 0.39402130246162415 - f1-score (micro avg)  0.65\n",
            "2022-12-08 10:18:03,676 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:18:03,677 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:18:04,381 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:18:06,176 epoch 15 - iter 2/25 - loss 0.46989321 - samples/sec: 35.70 - lr: 0.100000\n",
            "2022-12-08 10:18:07,807 epoch 15 - iter 4/25 - loss 0.41813636 - samples/sec: 39.27 - lr: 0.100000\n",
            "2022-12-08 10:18:08,988 epoch 15 - iter 6/25 - loss 0.43373811 - samples/sec: 54.25 - lr: 0.100000\n",
            "2022-12-08 10:18:10,391 epoch 15 - iter 8/25 - loss 0.43894927 - samples/sec: 45.69 - lr: 0.100000\n",
            "2022-12-08 10:18:12,116 epoch 15 - iter 10/25 - loss 0.43917778 - samples/sec: 37.13 - lr: 0.100000\n",
            "2022-12-08 10:18:15,287 epoch 15 - iter 12/25 - loss 0.43534847 - samples/sec: 20.19 - lr: 0.100000\n",
            "2022-12-08 10:18:16,650 epoch 15 - iter 14/25 - loss 0.43427615 - samples/sec: 47.01 - lr: 0.100000\n",
            "2022-12-08 10:18:18,000 epoch 15 - iter 16/25 - loss 0.43482141 - samples/sec: 47.44 - lr: 0.100000\n",
            "2022-12-08 10:18:19,415 epoch 15 - iter 18/25 - loss 0.43390900 - samples/sec: 45.28 - lr: 0.100000\n",
            "2022-12-08 10:18:20,679 epoch 15 - iter 20/25 - loss 0.42890180 - samples/sec: 50.66 - lr: 0.100000\n",
            "2022-12-08 10:18:22,126 epoch 15 - iter 22/25 - loss 0.43009631 - samples/sec: 44.27 - lr: 0.100000\n",
            "2022-12-08 10:18:23,644 epoch 15 - iter 24/25 - loss 0.42708656 - samples/sec: 42.23 - lr: 0.100000\n",
            "2022-12-08 10:18:23,789 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:18:23,790 EPOCH 15 done: loss 0.4274 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:18:24,682 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:18:24,690 DEV : loss 0.410897821187973 - f1-score (micro avg)  0.6297\n",
            "2022-12-08 10:18:24,700 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:18:24,700 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:18:26,023 epoch 16 - iter 2/25 - loss 0.50224054 - samples/sec: 48.42 - lr: 0.100000\n",
            "2022-12-08 10:18:27,397 epoch 16 - iter 4/25 - loss 0.41224231 - samples/sec: 46.61 - lr: 0.100000\n",
            "2022-12-08 10:18:30,408 epoch 16 - iter 6/25 - loss 0.39491914 - samples/sec: 21.27 - lr: 0.100000\n",
            "2022-12-08 10:18:31,671 epoch 16 - iter 8/25 - loss 0.40681734 - samples/sec: 50.75 - lr: 0.100000\n",
            "2022-12-08 10:18:33,414 epoch 16 - iter 10/25 - loss 0.40126334 - samples/sec: 36.73 - lr: 0.100000\n",
            "2022-12-08 10:18:34,676 epoch 16 - iter 12/25 - loss 0.38830845 - samples/sec: 50.78 - lr: 0.100000\n",
            "2022-12-08 10:18:36,056 epoch 16 - iter 14/25 - loss 0.38465326 - samples/sec: 46.44 - lr: 0.100000\n",
            "2022-12-08 10:18:37,519 epoch 16 - iter 16/25 - loss 0.39435537 - samples/sec: 43.78 - lr: 0.100000\n",
            "2022-12-08 10:18:38,904 epoch 16 - iter 18/25 - loss 0.40594314 - samples/sec: 46.26 - lr: 0.100000\n",
            "2022-12-08 10:18:40,321 epoch 16 - iter 20/25 - loss 0.40673916 - samples/sec: 45.21 - lr: 0.100000\n",
            "2022-12-08 10:18:41,531 epoch 16 - iter 22/25 - loss 0.40526939 - samples/sec: 52.94 - lr: 0.100000\n",
            "2022-12-08 10:18:43,339 epoch 16 - iter 24/25 - loss 0.40928565 - samples/sec: 35.42 - lr: 0.100000\n",
            "2022-12-08 10:18:43,449 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:18:43,451 EPOCH 16 done: loss 0.4087 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:18:44,228 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:18:44,239 DEV : loss 0.3874638080596924 - f1-score (micro avg)  0.6476\n",
            "2022-12-08 10:18:44,249 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:18:44,251 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:18:45,654 epoch 17 - iter 2/25 - loss 0.38705890 - samples/sec: 45.67 - lr: 0.100000\n",
            "2022-12-08 10:18:48,714 epoch 17 - iter 4/25 - loss 0.38314296 - samples/sec: 20.92 - lr: 0.100000\n",
            "2022-12-08 10:18:49,839 epoch 17 - iter 6/25 - loss 0.37112429 - samples/sec: 56.98 - lr: 0.100000\n",
            "2022-12-08 10:18:51,284 epoch 17 - iter 8/25 - loss 0.38047604 - samples/sec: 44.33 - lr: 0.100000\n",
            "2022-12-08 10:18:52,479 epoch 17 - iter 10/25 - loss 0.37922323 - samples/sec: 53.63 - lr: 0.100000\n",
            "2022-12-08 10:18:53,794 epoch 17 - iter 12/25 - loss 0.38334711 - samples/sec: 48.72 - lr: 0.100000\n",
            "2022-12-08 10:18:55,331 epoch 17 - iter 14/25 - loss 0.38223681 - samples/sec: 41.69 - lr: 0.100000\n",
            "2022-12-08 10:18:57,014 epoch 17 - iter 16/25 - loss 0.37692527 - samples/sec: 38.04 - lr: 0.100000\n",
            "2022-12-08 10:18:58,680 epoch 17 - iter 18/25 - loss 0.37397503 - samples/sec: 38.46 - lr: 0.100000\n",
            "2022-12-08 10:19:00,181 epoch 17 - iter 20/25 - loss 0.37795933 - samples/sec: 42.67 - lr: 0.100000\n",
            "2022-12-08 10:19:01,675 epoch 17 - iter 22/25 - loss 0.37639773 - samples/sec: 42.87 - lr: 0.100000\n",
            "2022-12-08 10:19:02,775 epoch 17 - iter 24/25 - loss 0.38729893 - samples/sec: 58.27 - lr: 0.100000\n",
            "2022-12-08 10:19:02,901 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:19:02,902 EPOCH 17 done: loss 0.3869 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:19:03,684 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:19:03,696 DEV : loss 0.3701637089252472 - f1-score (micro avg)  0.6568\n",
            "2022-12-08 10:19:03,706 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:19:03,707 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:19:04,401 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:19:07,695 epoch 18 - iter 2/25 - loss 0.43063982 - samples/sec: 19.44 - lr: 0.100000\n",
            "2022-12-08 10:19:08,792 epoch 18 - iter 4/25 - loss 0.40695302 - samples/sec: 58.39 - lr: 0.100000\n",
            "2022-12-08 10:19:10,176 epoch 18 - iter 6/25 - loss 0.40375535 - samples/sec: 46.28 - lr: 0.100000\n",
            "2022-12-08 10:19:11,050 epoch 18 - iter 8/25 - loss 0.38938940 - samples/sec: 73.37 - lr: 0.100000\n",
            "2022-12-08 10:19:12,810 epoch 18 - iter 10/25 - loss 0.37302787 - samples/sec: 36.41 - lr: 0.100000\n",
            "2022-12-08 10:19:14,233 epoch 18 - iter 12/25 - loss 0.37806692 - samples/sec: 45.03 - lr: 0.100000\n",
            "2022-12-08 10:19:15,663 epoch 18 - iter 14/25 - loss 0.37248168 - samples/sec: 44.79 - lr: 0.100000\n",
            "2022-12-08 10:19:17,345 epoch 18 - iter 16/25 - loss 0.36394397 - samples/sec: 38.08 - lr: 0.100000\n",
            "2022-12-08 10:19:18,705 epoch 18 - iter 18/25 - loss 0.36356004 - samples/sec: 47.10 - lr: 0.100000\n",
            "2022-12-08 10:19:19,989 epoch 18 - iter 20/25 - loss 0.36700979 - samples/sec: 49.92 - lr: 0.100000\n",
            "2022-12-08 10:19:21,361 epoch 18 - iter 22/25 - loss 0.37113095 - samples/sec: 46.69 - lr: 0.100000\n",
            "2022-12-08 10:19:23,073 epoch 18 - iter 24/25 - loss 0.37515056 - samples/sec: 37.41 - lr: 0.100000\n",
            "2022-12-08 10:19:23,225 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:19:23,226 EPOCH 18 done: loss 0.3752 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:19:24,145 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:19:24,156 DEV : loss 0.366158127784729 - f1-score (micro avg)  0.6335\n",
            "2022-12-08 10:19:24,167 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:19:24,168 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:19:25,502 epoch 19 - iter 2/25 - loss 0.30979414 - samples/sec: 47.99 - lr: 0.100000\n",
            "2022-12-08 10:19:27,173 epoch 19 - iter 4/25 - loss 0.33568384 - samples/sec: 38.35 - lr: 0.100000\n",
            "2022-12-08 10:19:28,546 epoch 19 - iter 6/25 - loss 0.34273272 - samples/sec: 46.66 - lr: 0.100000\n",
            "2022-12-08 10:19:30,073 epoch 19 - iter 8/25 - loss 0.35293783 - samples/sec: 41.95 - lr: 0.100000\n",
            "2022-12-08 10:19:31,410 epoch 19 - iter 10/25 - loss 0.36238116 - samples/sec: 47.89 - lr: 0.100000\n",
            "2022-12-08 10:19:33,141 epoch 19 - iter 12/25 - loss 0.35429977 - samples/sec: 36.99 - lr: 0.100000\n",
            "2022-12-08 10:19:34,308 epoch 19 - iter 14/25 - loss 0.34917777 - samples/sec: 54.92 - lr: 0.100000\n",
            "2022-12-08 10:19:37,406 epoch 19 - iter 16/25 - loss 0.35232987 - samples/sec: 20.67 - lr: 0.100000\n",
            "2022-12-08 10:19:38,658 epoch 19 - iter 18/25 - loss 0.36170497 - samples/sec: 51.21 - lr: 0.100000\n",
            "2022-12-08 10:19:40,090 epoch 19 - iter 20/25 - loss 0.36647090 - samples/sec: 44.74 - lr: 0.100000\n",
            "2022-12-08 10:19:41,717 epoch 19 - iter 22/25 - loss 0.36352662 - samples/sec: 39.37 - lr: 0.100000\n",
            "2022-12-08 10:19:44,196 epoch 19 - iter 24/25 - loss 0.36277099 - samples/sec: 25.83 - lr: 0.100000\n",
            "2022-12-08 10:19:44,362 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:19:44,363 EPOCH 19 done: loss 0.3617 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  3.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:19:45,377 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:19:45,387 DEV : loss 0.3435453474521637 - f1-score (micro avg)  0.6453\n",
            "2022-12-08 10:19:45,398 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:19:45,399 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:19:46,821 epoch 20 - iter 2/25 - loss 0.29718935 - samples/sec: 45.07 - lr: 0.100000\n",
            "2022-12-08 10:19:48,481 epoch 20 - iter 4/25 - loss 0.35261269 - samples/sec: 38.59 - lr: 0.100000\n",
            "2022-12-08 10:19:49,736 epoch 20 - iter 6/25 - loss 0.33193694 - samples/sec: 51.03 - lr: 0.100000\n",
            "2022-12-08 10:19:51,182 epoch 20 - iter 8/25 - loss 0.34475248 - samples/sec: 44.29 - lr: 0.100000\n",
            "2022-12-08 10:19:52,692 epoch 20 - iter 10/25 - loss 0.34568815 - samples/sec: 42.44 - lr: 0.100000\n",
            "2022-12-08 10:19:54,304 epoch 20 - iter 12/25 - loss 0.34528107 - samples/sec: 39.73 - lr: 0.100000\n",
            "2022-12-08 10:19:55,534 epoch 20 - iter 14/25 - loss 0.34297476 - samples/sec: 52.10 - lr: 0.100000\n",
            "2022-12-08 10:19:56,675 epoch 20 - iter 16/25 - loss 0.33730861 - samples/sec: 56.17 - lr: 0.100000\n",
            "2022-12-08 10:19:58,113 epoch 20 - iter 18/25 - loss 0.34302612 - samples/sec: 44.56 - lr: 0.100000\n",
            "2022-12-08 10:19:59,716 epoch 20 - iter 20/25 - loss 0.34257551 - samples/sec: 39.96 - lr: 0.100000\n",
            "2022-12-08 10:20:02,118 epoch 20 - iter 22/25 - loss 0.34704172 - samples/sec: 26.65 - lr: 0.100000\n",
            "2022-12-08 10:20:05,392 epoch 20 - iter 24/25 - loss 0.34757245 - samples/sec: 19.56 - lr: 0.100000\n",
            "2022-12-08 10:20:05,509 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:20:05,510 EPOCH 20 done: loss 0.3475 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:20:06,286 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:20:06,294 DEV : loss 0.35169848799705505 - f1-score (micro avg)  0.6667\n",
            "2022-12-08 10:20:06,306 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:20:06,307 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:20:07,000 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:20:08,344 epoch 21 - iter 2/25 - loss 0.28339786 - samples/sec: 47.68 - lr: 0.100000\n",
            "2022-12-08 10:20:09,432 epoch 21 - iter 4/25 - loss 0.31758805 - samples/sec: 58.89 - lr: 0.100000\n",
            "2022-12-08 10:20:10,719 epoch 21 - iter 6/25 - loss 0.29885401 - samples/sec: 49.79 - lr: 0.100000\n",
            "2022-12-08 10:20:12,172 epoch 21 - iter 8/25 - loss 0.30978519 - samples/sec: 44.08 - lr: 0.100000\n",
            "2022-12-08 10:20:13,464 epoch 21 - iter 10/25 - loss 0.32237376 - samples/sec: 49.62 - lr: 0.100000\n",
            "2022-12-08 10:20:14,959 epoch 21 - iter 12/25 - loss 0.31907482 - samples/sec: 42.85 - lr: 0.100000\n",
            "2022-12-08 10:20:16,433 epoch 21 - iter 14/25 - loss 0.32702735 - samples/sec: 43.45 - lr: 0.100000\n",
            "2022-12-08 10:20:17,944 epoch 21 - iter 16/25 - loss 0.32613091 - samples/sec: 42.39 - lr: 0.100000\n",
            "2022-12-08 10:20:19,449 epoch 21 - iter 18/25 - loss 0.32761011 - samples/sec: 42.57 - lr: 0.100000\n",
            "2022-12-08 10:20:23,006 epoch 21 - iter 20/25 - loss 0.32973724 - samples/sec: 18.00 - lr: 0.100000\n",
            "2022-12-08 10:20:24,561 epoch 21 - iter 22/25 - loss 0.32861381 - samples/sec: 41.19 - lr: 0.100000\n",
            "2022-12-08 10:20:25,489 epoch 21 - iter 24/25 - loss 0.33193902 - samples/sec: 69.05 - lr: 0.100000\n",
            "2022-12-08 10:20:25,572 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:20:25,573 EPOCH 21 done: loss 0.3319 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:20:26,326 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:20:26,335 DEV : loss 0.3639715611934662 - f1-score (micro avg)  0.6273\n",
            "2022-12-08 10:20:26,345 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:20:26,347 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:20:27,813 epoch 22 - iter 2/25 - loss 0.32640451 - samples/sec: 43.70 - lr: 0.100000\n",
            "2022-12-08 10:20:29,560 epoch 22 - iter 4/25 - loss 0.32564343 - samples/sec: 36.65 - lr: 0.100000\n",
            "2022-12-08 10:20:30,946 epoch 22 - iter 6/25 - loss 0.31396096 - samples/sec: 46.23 - lr: 0.100000\n",
            "2022-12-08 10:20:32,361 epoch 22 - iter 8/25 - loss 0.32038154 - samples/sec: 45.25 - lr: 0.100000\n",
            "2022-12-08 10:20:33,914 epoch 22 - iter 10/25 - loss 0.31483067 - samples/sec: 41.27 - lr: 0.100000\n",
            "2022-12-08 10:20:35,201 epoch 22 - iter 12/25 - loss 0.32400393 - samples/sec: 49.79 - lr: 0.100000\n",
            "2022-12-08 10:20:36,854 epoch 22 - iter 14/25 - loss 0.31569031 - samples/sec: 38.73 - lr: 0.100000\n",
            "2022-12-08 10:20:37,908 epoch 22 - iter 16/25 - loss 0.31165239 - samples/sec: 60.83 - lr: 0.100000\n",
            "2022-12-08 10:20:39,397 epoch 22 - iter 18/25 - loss 0.31324420 - samples/sec: 43.01 - lr: 0.100000\n",
            "2022-12-08 10:20:40,688 epoch 22 - iter 20/25 - loss 0.31863293 - samples/sec: 49.64 - lr: 0.100000\n",
            "2022-12-08 10:20:44,219 epoch 22 - iter 22/25 - loss 0.32268882 - samples/sec: 18.13 - lr: 0.100000\n",
            "2022-12-08 10:20:45,567 epoch 22 - iter 24/25 - loss 0.32421180 - samples/sec: 47.54 - lr: 0.100000\n",
            "2022-12-08 10:20:45,679 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:20:45,681 EPOCH 22 done: loss 0.3261 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:20:46,458 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:20:46,468 DEV : loss 0.3197213113307953 - f1-score (micro avg)  0.682\n",
            "2022-12-08 10:20:46,479 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:20:46,480 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:20:47,212 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:20:48,341 epoch 23 - iter 2/25 - loss 0.30139674 - samples/sec: 56.74 - lr: 0.100000\n",
            "2022-12-08 10:20:49,530 epoch 23 - iter 4/25 - loss 0.27720004 - samples/sec: 53.91 - lr: 0.100000\n",
            "2022-12-08 10:20:50,988 epoch 23 - iter 6/25 - loss 0.26227530 - samples/sec: 43.93 - lr: 0.100000\n",
            "2022-12-08 10:20:53,170 epoch 23 - iter 8/25 - loss 0.27711363 - samples/sec: 29.35 - lr: 0.100000\n",
            "2022-12-08 10:20:56,659 epoch 23 - iter 10/25 - loss 0.29232282 - samples/sec: 18.35 - lr: 0.100000\n",
            "2022-12-08 10:20:58,273 epoch 23 - iter 12/25 - loss 0.30930726 - samples/sec: 39.69 - lr: 0.100000\n",
            "2022-12-08 10:20:59,320 epoch 23 - iter 14/25 - loss 0.31206461 - samples/sec: 61.22 - lr: 0.100000\n",
            "2022-12-08 10:21:00,517 epoch 23 - iter 16/25 - loss 0.30658871 - samples/sec: 53.55 - lr: 0.100000\n",
            "2022-12-08 10:21:02,183 epoch 23 - iter 18/25 - loss 0.31350400 - samples/sec: 38.45 - lr: 0.100000\n",
            "2022-12-08 10:21:03,342 epoch 23 - iter 20/25 - loss 0.31146175 - samples/sec: 55.30 - lr: 0.100000\n",
            "2022-12-08 10:21:04,790 epoch 23 - iter 22/25 - loss 0.31309291 - samples/sec: 44.24 - lr: 0.100000\n",
            "2022-12-08 10:21:06,412 epoch 23 - iter 24/25 - loss 0.32156751 - samples/sec: 39.49 - lr: 0.100000\n",
            "2022-12-08 10:21:06,521 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:21:06,522 EPOCH 23 done: loss 0.3216 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:21:07,302 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:21:07,312 DEV : loss 0.39436376094818115 - f1-score (micro avg)  0.6277\n",
            "2022-12-08 10:21:07,322 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:21:07,323 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:21:08,743 epoch 24 - iter 2/25 - loss 0.30912065 - samples/sec: 45.10 - lr: 0.100000\n",
            "2022-12-08 10:21:09,808 epoch 24 - iter 4/25 - loss 0.30589121 - samples/sec: 60.20 - lr: 0.100000\n",
            "2022-12-08 10:21:11,191 epoch 24 - iter 6/25 - loss 0.33491403 - samples/sec: 46.31 - lr: 0.100000\n",
            "2022-12-08 10:21:12,545 epoch 24 - iter 8/25 - loss 0.31961107 - samples/sec: 47.34 - lr: 0.100000\n",
            "2022-12-08 10:21:14,006 epoch 24 - iter 10/25 - loss 0.31896329 - samples/sec: 43.82 - lr: 0.100000\n",
            "2022-12-08 10:21:15,565 epoch 24 - iter 12/25 - loss 0.31857818 - samples/sec: 41.10 - lr: 0.100000\n",
            "2022-12-08 10:21:17,020 epoch 24 - iter 14/25 - loss 0.31650931 - samples/sec: 44.02 - lr: 0.100000\n",
            "2022-12-08 10:21:20,393 epoch 24 - iter 16/25 - loss 0.30704178 - samples/sec: 18.98 - lr: 0.100000\n",
            "2022-12-08 10:21:21,752 epoch 24 - iter 18/25 - loss 0.30302381 - samples/sec: 47.16 - lr: 0.100000\n",
            "2022-12-08 10:21:23,157 epoch 24 - iter 20/25 - loss 0.31262343 - samples/sec: 45.59 - lr: 0.100000\n",
            "2022-12-08 10:21:24,584 epoch 24 - iter 22/25 - loss 0.30809684 - samples/sec: 44.91 - lr: 0.100000\n",
            "2022-12-08 10:21:25,934 epoch 24 - iter 24/25 - loss 0.30848685 - samples/sec: 47.45 - lr: 0.100000\n",
            "2022-12-08 10:21:26,015 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:21:26,016 EPOCH 24 done: loss 0.3082 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:21:26,782 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:21:26,789 DEV : loss 0.309669554233551 - f1-score (micro avg)  0.6785\n",
            "2022-12-08 10:21:26,801 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:21:26,801 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:21:28,421 epoch 25 - iter 2/25 - loss 0.29527377 - samples/sec: 39.55 - lr: 0.100000\n",
            "2022-12-08 10:21:29,860 epoch 25 - iter 4/25 - loss 0.29321449 - samples/sec: 44.50 - lr: 0.100000\n",
            "2022-12-08 10:21:31,392 epoch 25 - iter 6/25 - loss 0.29958160 - samples/sec: 41.83 - lr: 0.100000\n",
            "2022-12-08 10:21:32,918 epoch 25 - iter 8/25 - loss 0.30949931 - samples/sec: 41.97 - lr: 0.100000\n",
            "2022-12-08 10:21:34,190 epoch 25 - iter 10/25 - loss 0.30428850 - samples/sec: 50.37 - lr: 0.100000\n",
            "2022-12-08 10:21:37,465 epoch 25 - iter 12/25 - loss 0.30003715 - samples/sec: 19.55 - lr: 0.100000\n",
            "2022-12-08 10:21:39,115 epoch 25 - iter 14/25 - loss 0.30167901 - samples/sec: 38.84 - lr: 0.100000\n",
            "2022-12-08 10:21:40,539 epoch 25 - iter 16/25 - loss 0.30074552 - samples/sec: 44.97 - lr: 0.100000\n",
            "2022-12-08 10:21:41,779 epoch 25 - iter 18/25 - loss 0.29306276 - samples/sec: 51.65 - lr: 0.100000\n",
            "2022-12-08 10:21:43,195 epoch 25 - iter 20/25 - loss 0.29171414 - samples/sec: 45.26 - lr: 0.100000\n",
            "2022-12-08 10:21:44,601 epoch 25 - iter 22/25 - loss 0.29492843 - samples/sec: 45.55 - lr: 0.100000\n",
            "2022-12-08 10:21:46,058 epoch 25 - iter 24/25 - loss 0.29501887 - samples/sec: 43.96 - lr: 0.100000\n",
            "2022-12-08 10:21:46,174 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:21:46,175 EPOCH 25 done: loss 0.2953 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:21:46,939 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:21:46,949 DEV : loss 0.30700013041496277 - f1-score (micro avg)  0.6667\n",
            "2022-12-08 10:21:46,959 BAD EPOCHS (no improvement): 3\n",
            "2022-12-08 10:21:46,960 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:21:48,507 epoch 26 - iter 2/25 - loss 0.29292175 - samples/sec: 41.41 - lr: 0.100000\n",
            "2022-12-08 10:21:51,804 epoch 26 - iter 4/25 - loss 0.26844104 - samples/sec: 19.42 - lr: 0.100000\n",
            "2022-12-08 10:21:53,395 epoch 26 - iter 6/25 - loss 0.27255364 - samples/sec: 40.30 - lr: 0.100000\n",
            "2022-12-08 10:21:54,607 epoch 26 - iter 8/25 - loss 0.28473442 - samples/sec: 52.85 - lr: 0.100000\n",
            "2022-12-08 10:21:56,195 epoch 26 - iter 10/25 - loss 0.28391867 - samples/sec: 40.33 - lr: 0.100000\n",
            "2022-12-08 10:21:57,387 epoch 26 - iter 12/25 - loss 0.28926197 - samples/sec: 53.79 - lr: 0.100000\n",
            "2022-12-08 10:21:58,598 epoch 26 - iter 14/25 - loss 0.28936148 - samples/sec: 52.88 - lr: 0.100000\n",
            "2022-12-08 10:22:00,241 epoch 26 - iter 16/25 - loss 0.29693665 - samples/sec: 39.00 - lr: 0.100000\n",
            "2022-12-08 10:22:01,706 epoch 26 - iter 18/25 - loss 0.29794872 - samples/sec: 43.72 - lr: 0.100000\n",
            "2022-12-08 10:22:02,942 epoch 26 - iter 20/25 - loss 0.30075989 - samples/sec: 51.84 - lr: 0.100000\n",
            "2022-12-08 10:22:04,458 epoch 26 - iter 22/25 - loss 0.29691589 - samples/sec: 42.28 - lr: 0.100000\n",
            "2022-12-08 10:22:05,724 epoch 26 - iter 24/25 - loss 0.29477830 - samples/sec: 50.61 - lr: 0.100000\n",
            "2022-12-08 10:22:05,845 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:22:05,846 EPOCH 26 done: loss 0.2950 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:22:06,622 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:22:06,630 DEV : loss 0.32519131898880005 - f1-score (micro avg)  0.6638\n",
            "2022-12-08 10:22:06,640 Epoch    26: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2022-12-08 10:22:06,641 BAD EPOCHS (no improvement): 4\n",
            "2022-12-08 10:22:06,642 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:22:07,955 epoch 27 - iter 2/25 - loss 0.22658344 - samples/sec: 48.78 - lr: 0.050000\n",
            "2022-12-08 10:22:09,217 epoch 27 - iter 4/25 - loss 0.26000057 - samples/sec: 50.77 - lr: 0.050000\n",
            "2022-12-08 10:22:10,656 epoch 27 - iter 6/25 - loss 0.26302923 - samples/sec: 44.52 - lr: 0.050000\n",
            "2022-12-08 10:22:13,816 epoch 27 - iter 8/25 - loss 0.26871513 - samples/sec: 20.26 - lr: 0.050000\n",
            "2022-12-08 10:22:15,026 epoch 27 - iter 10/25 - loss 0.25994186 - samples/sec: 52.94 - lr: 0.050000\n",
            "2022-12-08 10:22:16,322 epoch 27 - iter 12/25 - loss 0.26038568 - samples/sec: 49.43 - lr: 0.050000\n",
            "2022-12-08 10:22:17,948 epoch 27 - iter 14/25 - loss 0.25618073 - samples/sec: 39.41 - lr: 0.050000\n",
            "2022-12-08 10:22:19,886 epoch 27 - iter 16/25 - loss 0.25897796 - samples/sec: 33.05 - lr: 0.050000\n",
            "2022-12-08 10:22:21,499 epoch 27 - iter 18/25 - loss 0.26362943 - samples/sec: 39.69 - lr: 0.050000\n",
            "2022-12-08 10:22:22,647 epoch 27 - iter 20/25 - loss 0.26490994 - samples/sec: 55.84 - lr: 0.050000\n",
            "2022-12-08 10:22:23,986 epoch 27 - iter 22/25 - loss 0.26621114 - samples/sec: 47.86 - lr: 0.050000\n",
            "2022-12-08 10:22:25,517 epoch 27 - iter 24/25 - loss 0.26737580 - samples/sec: 41.84 - lr: 0.050000\n",
            "2022-12-08 10:22:25,631 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:22:25,632 EPOCH 27 done: loss 0.2680 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:22:26,404 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:22:26,411 DEV : loss 0.3340665102005005 - f1-score (micro avg)  0.6749\n",
            "2022-12-08 10:22:26,423 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:22:26,425 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:22:27,709 epoch 28 - iter 2/25 - loss 0.23715978 - samples/sec: 49.88 - lr: 0.050000\n",
            "2022-12-08 10:22:29,080 epoch 28 - iter 4/25 - loss 0.26043759 - samples/sec: 46.74 - lr: 0.050000\n",
            "2022-12-08 10:22:30,388 epoch 28 - iter 6/25 - loss 0.25990039 - samples/sec: 48.98 - lr: 0.050000\n",
            "2022-12-08 10:22:31,440 epoch 28 - iter 8/25 - loss 0.25727237 - samples/sec: 60.96 - lr: 0.050000\n",
            "2022-12-08 10:22:34,126 epoch 28 - iter 10/25 - loss 0.25408068 - samples/sec: 23.84 - lr: 0.050000\n",
            "2022-12-08 10:22:35,637 epoch 28 - iter 12/25 - loss 0.25733433 - samples/sec: 42.38 - lr: 0.050000\n",
            "2022-12-08 10:22:36,578 epoch 28 - iter 14/25 - loss 0.25546554 - samples/sec: 68.15 - lr: 0.050000\n",
            "2022-12-08 10:22:38,306 epoch 28 - iter 16/25 - loss 0.26056806 - samples/sec: 37.06 - lr: 0.050000\n",
            "2022-12-08 10:22:39,702 epoch 28 - iter 18/25 - loss 0.25990996 - samples/sec: 45.91 - lr: 0.050000\n",
            "2022-12-08 10:22:40,961 epoch 28 - iter 20/25 - loss 0.25708571 - samples/sec: 50.90 - lr: 0.050000\n",
            "2022-12-08 10:22:42,395 epoch 28 - iter 22/25 - loss 0.25686846 - samples/sec: 44.65 - lr: 0.050000\n",
            "2022-12-08 10:22:44,069 epoch 28 - iter 24/25 - loss 0.25766968 - samples/sec: 38.28 - lr: 0.050000\n",
            "2022-12-08 10:22:44,176 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:22:44,177 EPOCH 28 done: loss 0.2580 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:22:44,931 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:22:44,939 DEV : loss 0.2929023206233978 - f1-score (micro avg)  0.6806\n",
            "2022-12-08 10:22:44,949 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:22:44,950 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:22:46,499 epoch 29 - iter 2/25 - loss 0.24114126 - samples/sec: 41.32 - lr: 0.050000\n",
            "2022-12-08 10:22:47,959 epoch 29 - iter 4/25 - loss 0.27829054 - samples/sec: 43.88 - lr: 0.050000\n",
            "2022-12-08 10:22:49,347 epoch 29 - iter 6/25 - loss 0.26348169 - samples/sec: 46.18 - lr: 0.050000\n",
            "2022-12-08 10:22:50,452 epoch 29 - iter 8/25 - loss 0.26166644 - samples/sec: 57.98 - lr: 0.050000\n",
            "2022-12-08 10:22:51,686 epoch 29 - iter 10/25 - loss 0.25688407 - samples/sec: 51.93 - lr: 0.050000\n",
            "2022-12-08 10:22:52,712 epoch 29 - iter 12/25 - loss 0.25413654 - samples/sec: 62.48 - lr: 0.050000\n",
            "2022-12-08 10:22:53,905 epoch 29 - iter 14/25 - loss 0.24951602 - samples/sec: 53.71 - lr: 0.050000\n",
            "2022-12-08 10:22:55,585 epoch 29 - iter 16/25 - loss 0.24457443 - samples/sec: 38.14 - lr: 0.050000\n",
            "2022-12-08 10:22:58,540 epoch 29 - iter 18/25 - loss 0.25158704 - samples/sec: 21.66 - lr: 0.050000\n",
            "2022-12-08 10:23:00,128 epoch 29 - iter 20/25 - loss 0.25087137 - samples/sec: 40.34 - lr: 0.050000\n",
            "2022-12-08 10:23:01,639 epoch 29 - iter 22/25 - loss 0.25092016 - samples/sec: 42.40 - lr: 0.050000\n",
            "2022-12-08 10:23:02,872 epoch 29 - iter 24/25 - loss 0.25322779 - samples/sec: 51.96 - lr: 0.050000\n",
            "2022-12-08 10:23:02,971 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:23:02,972 EPOCH 29 done: loss 0.2533 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:23:03,720 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:23:03,731 DEV : loss 0.3028087615966797 - f1-score (micro avg)  0.6806\n",
            "2022-12-08 10:23:03,743 BAD EPOCHS (no improvement): 3\n",
            "2022-12-08 10:23:03,744 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:23:05,290 epoch 30 - iter 2/25 - loss 0.21765369 - samples/sec: 41.45 - lr: 0.050000\n",
            "2022-12-08 10:23:06,588 epoch 30 - iter 4/25 - loss 0.23034014 - samples/sec: 49.35 - lr: 0.050000\n",
            "2022-12-08 10:23:07,882 epoch 30 - iter 6/25 - loss 0.24291456 - samples/sec: 49.53 - lr: 0.050000\n",
            "2022-12-08 10:23:08,921 epoch 30 - iter 8/25 - loss 0.23849647 - samples/sec: 61.67 - lr: 0.050000\n",
            "2022-12-08 10:23:10,441 epoch 30 - iter 10/25 - loss 0.23387496 - samples/sec: 42.15 - lr: 0.050000\n",
            "2022-12-08 10:23:11,411 epoch 30 - iter 12/25 - loss 0.23511524 - samples/sec: 66.10 - lr: 0.050000\n",
            "2022-12-08 10:23:12,594 epoch 30 - iter 14/25 - loss 0.23749552 - samples/sec: 54.15 - lr: 0.050000\n",
            "2022-12-08 10:23:14,211 epoch 30 - iter 16/25 - loss 0.23830753 - samples/sec: 39.60 - lr: 0.050000\n",
            "2022-12-08 10:23:17,409 epoch 30 - iter 18/25 - loss 0.23862773 - samples/sec: 20.02 - lr: 0.050000\n",
            "2022-12-08 10:23:18,935 epoch 30 - iter 20/25 - loss 0.23852829 - samples/sec: 41.99 - lr: 0.050000\n",
            "2022-12-08 10:23:21,076 epoch 30 - iter 22/25 - loss 0.23810562 - samples/sec: 29.92 - lr: 0.050000\n",
            "2022-12-08 10:23:22,895 epoch 30 - iter 24/25 - loss 0.24036411 - samples/sec: 35.21 - lr: 0.050000\n",
            "2022-12-08 10:23:23,040 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:23:23,041 EPOCH 30 done: loss 0.2404 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:23:24,011 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:23:24,021 DEV : loss 0.3168567419052124 - f1-score (micro avg)  0.6738\n",
            "2022-12-08 10:23:24,031 Epoch    30: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-12-08 10:23:24,032 BAD EPOCHS (no improvement): 4\n",
            "2022-12-08 10:23:24,033 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:23:25,431 epoch 31 - iter 2/25 - loss 0.21237719 - samples/sec: 45.82 - lr: 0.025000\n",
            "2022-12-08 10:23:27,161 epoch 31 - iter 4/25 - loss 0.24570719 - samples/sec: 37.03 - lr: 0.025000\n",
            "2022-12-08 10:23:28,512 epoch 31 - iter 6/25 - loss 0.24478034 - samples/sec: 47.43 - lr: 0.025000\n",
            "2022-12-08 10:23:29,999 epoch 31 - iter 8/25 - loss 0.23657303 - samples/sec: 43.08 - lr: 0.025000\n",
            "2022-12-08 10:23:33,640 epoch 31 - iter 10/25 - loss 0.22626240 - samples/sec: 17.58 - lr: 0.025000\n",
            "2022-12-08 10:23:34,818 epoch 31 - iter 12/25 - loss 0.23321644 - samples/sec: 54.39 - lr: 0.025000\n",
            "2022-12-08 10:23:36,235 epoch 31 - iter 14/25 - loss 0.23338793 - samples/sec: 45.22 - lr: 0.025000\n",
            "2022-12-08 10:23:37,319 epoch 31 - iter 16/25 - loss 0.23929010 - samples/sec: 59.10 - lr: 0.025000\n",
            "2022-12-08 10:23:38,917 epoch 31 - iter 18/25 - loss 0.23674104 - samples/sec: 40.07 - lr: 0.025000\n",
            "2022-12-08 10:23:39,905 epoch 31 - iter 20/25 - loss 0.23765771 - samples/sec: 64.88 - lr: 0.025000\n",
            "2022-12-08 10:23:41,521 epoch 31 - iter 22/25 - loss 0.23681051 - samples/sec: 39.65 - lr: 0.025000\n",
            "2022-12-08 10:23:42,985 epoch 31 - iter 24/25 - loss 0.23729662 - samples/sec: 43.74 - lr: 0.025000\n",
            "2022-12-08 10:23:43,121 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:23:43,122 EPOCH 31 done: loss 0.2381 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:23:43,915 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:23:43,924 DEV : loss 0.2997512221336365 - f1-score (micro avg)  0.6629\n",
            "2022-12-08 10:23:43,934 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:23:43,936 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:23:47,297 epoch 32 - iter 2/25 - loss 0.22874869 - samples/sec: 19.05 - lr: 0.025000\n",
            "2022-12-08 10:23:48,603 epoch 32 - iter 4/25 - loss 0.25220266 - samples/sec: 49.07 - lr: 0.025000\n",
            "2022-12-08 10:23:49,897 epoch 32 - iter 6/25 - loss 0.23801989 - samples/sec: 49.49 - lr: 0.025000\n",
            "2022-12-08 10:23:51,434 epoch 32 - iter 8/25 - loss 0.23457526 - samples/sec: 41.67 - lr: 0.025000\n",
            "2022-12-08 10:23:52,622 epoch 32 - iter 10/25 - loss 0.23417127 - samples/sec: 53.93 - lr: 0.025000\n",
            "2022-12-08 10:23:53,847 epoch 32 - iter 12/25 - loss 0.22777573 - samples/sec: 52.30 - lr: 0.025000\n",
            "2022-12-08 10:23:55,373 epoch 32 - iter 14/25 - loss 0.22962232 - samples/sec: 41.98 - lr: 0.025000\n",
            "2022-12-08 10:23:57,276 epoch 32 - iter 16/25 - loss 0.23103868 - samples/sec: 33.66 - lr: 0.025000\n",
            "2022-12-08 10:23:58,437 epoch 32 - iter 18/25 - loss 0.23918636 - samples/sec: 55.16 - lr: 0.025000\n",
            "2022-12-08 10:24:00,000 epoch 32 - iter 20/25 - loss 0.23753053 - samples/sec: 41.00 - lr: 0.025000\n",
            "2022-12-08 10:24:01,128 epoch 32 - iter 22/25 - loss 0.23517770 - samples/sec: 56.79 - lr: 0.025000\n",
            "2022-12-08 10:24:02,560 epoch 32 - iter 24/25 - loss 0.23619065 - samples/sec: 44.74 - lr: 0.025000\n",
            "2022-12-08 10:24:02,682 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:24:02,682 EPOCH 32 done: loss 0.2357 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:24:03,444 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:24:03,455 DEV : loss 0.29447850584983826 - f1-score (micro avg)  0.6828\n",
            "2022-12-08 10:24:03,464 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:24:03,465 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:24:04,147 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:24:05,723 epoch 33 - iter 2/25 - loss 0.20258092 - samples/sec: 40.64 - lr: 0.025000\n",
            "2022-12-08 10:24:06,757 epoch 33 - iter 4/25 - loss 0.21809954 - samples/sec: 62.03 - lr: 0.025000\n",
            "2022-12-08 10:24:08,312 epoch 33 - iter 6/25 - loss 0.22850030 - samples/sec: 41.17 - lr: 0.025000\n",
            "2022-12-08 10:24:11,660 epoch 33 - iter 8/25 - loss 0.23231192 - samples/sec: 19.12 - lr: 0.025000\n",
            "2022-12-08 10:24:12,807 epoch 33 - iter 10/25 - loss 0.23768584 - samples/sec: 55.85 - lr: 0.025000\n",
            "2022-12-08 10:24:14,016 epoch 33 - iter 12/25 - loss 0.24055207 - samples/sec: 52.99 - lr: 0.025000\n",
            "2022-12-08 10:24:15,364 epoch 33 - iter 14/25 - loss 0.23563095 - samples/sec: 47.53 - lr: 0.025000\n",
            "2022-12-08 10:24:16,945 epoch 33 - iter 16/25 - loss 0.23635092 - samples/sec: 40.52 - lr: 0.025000\n",
            "2022-12-08 10:24:18,327 epoch 33 - iter 18/25 - loss 0.22902550 - samples/sec: 46.36 - lr: 0.025000\n",
            "2022-12-08 10:24:19,564 epoch 33 - iter 20/25 - loss 0.22622935 - samples/sec: 51.80 - lr: 0.025000\n",
            "2022-12-08 10:24:21,086 epoch 33 - iter 22/25 - loss 0.22460747 - samples/sec: 42.08 - lr: 0.025000\n",
            "2022-12-08 10:24:22,971 epoch 33 - iter 24/25 - loss 0.22928429 - samples/sec: 33.97 - lr: 0.025000\n",
            "2022-12-08 10:24:23,087 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:24:23,087 EPOCH 33 done: loss 0.2285 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:24:23,850 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:24:23,857 DEV : loss 0.2914526164531708 - f1-score (micro avg)  0.7076\n",
            "2022-12-08 10:24:23,870 BAD EPOCHS (no improvement): 0\n",
            "2022-12-08 10:24:23,871 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:24:24,578 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:24:26,089 epoch 34 - iter 2/25 - loss 0.22978332 - samples/sec: 42.41 - lr: 0.025000\n",
            "2022-12-08 10:24:27,248 epoch 34 - iter 4/25 - loss 0.25075141 - samples/sec: 55.30 - lr: 0.025000\n",
            "2022-12-08 10:24:28,442 epoch 34 - iter 6/25 - loss 0.22497943 - samples/sec: 53.65 - lr: 0.025000\n",
            "2022-12-08 10:24:29,832 epoch 34 - iter 8/25 - loss 0.21929865 - samples/sec: 46.09 - lr: 0.025000\n",
            "2022-12-08 10:24:31,094 epoch 34 - iter 10/25 - loss 0.21465572 - samples/sec: 50.77 - lr: 0.025000\n",
            "2022-12-08 10:24:32,617 epoch 34 - iter 12/25 - loss 0.21739495 - samples/sec: 42.05 - lr: 0.025000\n",
            "2022-12-08 10:24:34,376 epoch 34 - iter 14/25 - loss 0.21981222 - samples/sec: 36.41 - lr: 0.025000\n",
            "2022-12-08 10:24:35,710 epoch 34 - iter 16/25 - loss 0.21528834 - samples/sec: 48.03 - lr: 0.025000\n",
            "2022-12-08 10:24:37,033 epoch 34 - iter 18/25 - loss 0.21577090 - samples/sec: 48.41 - lr: 0.025000\n",
            "2022-12-08 10:24:38,201 epoch 34 - iter 20/25 - loss 0.22155878 - samples/sec: 54.85 - lr: 0.025000\n",
            "2022-12-08 10:24:39,642 epoch 34 - iter 22/25 - loss 0.22098095 - samples/sec: 44.46 - lr: 0.025000\n",
            "2022-12-08 10:24:42,822 epoch 34 - iter 24/25 - loss 0.21974836 - samples/sec: 20.14 - lr: 0.025000\n",
            "2022-12-08 10:24:42,945 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:24:42,946 EPOCH 34 done: loss 0.2199 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:24:43,701 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:24:43,709 DEV : loss 0.3013288378715515 - f1-score (micro avg)  0.6854\n",
            "2022-12-08 10:24:43,721 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:24:43,722 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:24:45,176 epoch 35 - iter 2/25 - loss 0.20881465 - samples/sec: 44.06 - lr: 0.025000\n",
            "2022-12-08 10:24:48,344 epoch 35 - iter 4/25 - loss 0.19151057 - samples/sec: 20.21 - lr: 0.025000\n",
            "2022-12-08 10:24:49,704 epoch 35 - iter 6/25 - loss 0.20734828 - samples/sec: 47.11 - lr: 0.025000\n",
            "2022-12-08 10:24:50,975 epoch 35 - iter 8/25 - loss 0.21298588 - samples/sec: 50.40 - lr: 0.025000\n",
            "2022-12-08 10:24:52,316 epoch 35 - iter 10/25 - loss 0.20819711 - samples/sec: 47.76 - lr: 0.025000\n",
            "2022-12-08 10:24:53,788 epoch 35 - iter 12/25 - loss 0.21437778 - samples/sec: 43.51 - lr: 0.025000\n",
            "2022-12-08 10:24:55,099 epoch 35 - iter 14/25 - loss 0.21800159 - samples/sec: 48.90 - lr: 0.025000\n",
            "2022-12-08 10:24:56,145 epoch 35 - iter 16/25 - loss 0.22070720 - samples/sec: 61.23 - lr: 0.025000\n",
            "2022-12-08 10:24:57,857 epoch 35 - iter 18/25 - loss 0.21971387 - samples/sec: 37.42 - lr: 0.025000\n",
            "2022-12-08 10:24:59,524 epoch 35 - iter 20/25 - loss 0.21974462 - samples/sec: 38.40 - lr: 0.025000\n",
            "2022-12-08 10:25:00,529 epoch 35 - iter 22/25 - loss 0.21940883 - samples/sec: 63.80 - lr: 0.025000\n",
            "2022-12-08 10:25:01,885 epoch 35 - iter 24/25 - loss 0.21916805 - samples/sec: 47.25 - lr: 0.025000\n",
            "2022-12-08 10:25:02,002 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:25:02,002 EPOCH 35 done: loss 0.2187 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:25:02,766 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:25:02,774 DEV : loss 0.29402536153793335 - f1-score (micro avg)  0.6914\n",
            "2022-12-08 10:25:02,785 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:25:02,786 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:25:04,486 epoch 36 - iter 2/25 - loss 0.20391524 - samples/sec: 37.68 - lr: 0.025000\n",
            "2022-12-08 10:25:05,991 epoch 36 - iter 4/25 - loss 0.22093808 - samples/sec: 42.58 - lr: 0.025000\n",
            "2022-12-08 10:25:07,316 epoch 36 - iter 6/25 - loss 0.20799868 - samples/sec: 48.32 - lr: 0.025000\n",
            "2022-12-08 10:25:08,988 epoch 36 - iter 8/25 - loss 0.19795424 - samples/sec: 38.32 - lr: 0.025000\n",
            "2022-12-08 10:25:10,317 epoch 36 - iter 10/25 - loss 0.20034124 - samples/sec: 48.19 - lr: 0.025000\n",
            "2022-12-08 10:25:13,169 epoch 36 - iter 12/25 - loss 0.20374969 - samples/sec: 22.45 - lr: 0.025000\n",
            "2022-12-08 10:25:14,865 epoch 36 - iter 14/25 - loss 0.21047682 - samples/sec: 37.76 - lr: 0.025000\n",
            "2022-12-08 10:25:16,047 epoch 36 - iter 16/25 - loss 0.21359963 - samples/sec: 54.21 - lr: 0.025000\n",
            "2022-12-08 10:25:17,365 epoch 36 - iter 18/25 - loss 0.21790615 - samples/sec: 48.61 - lr: 0.025000\n",
            "2022-12-08 10:25:18,644 epoch 36 - iter 20/25 - loss 0.21988355 - samples/sec: 50.06 - lr: 0.025000\n",
            "2022-12-08 10:25:20,395 epoch 36 - iter 22/25 - loss 0.22053822 - samples/sec: 36.58 - lr: 0.025000\n",
            "2022-12-08 10:25:21,725 epoch 36 - iter 24/25 - loss 0.22343552 - samples/sec: 48.18 - lr: 0.025000\n",
            "2022-12-08 10:25:21,817 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:25:21,818 EPOCH 36 done: loss 0.2231 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:25:22,622 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:25:22,631 DEV : loss 0.3000977337360382 - f1-score (micro avg)  0.675\n",
            "2022-12-08 10:25:22,641 BAD EPOCHS (no improvement): 3\n",
            "2022-12-08 10:25:22,643 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:25:24,187 epoch 37 - iter 2/25 - loss 0.18589522 - samples/sec: 41.48 - lr: 0.025000\n",
            "2022-12-08 10:25:25,664 epoch 37 - iter 4/25 - loss 0.20028767 - samples/sec: 43.35 - lr: 0.025000\n",
            "2022-12-08 10:25:28,788 epoch 37 - iter 6/25 - loss 0.20646739 - samples/sec: 20.50 - lr: 0.025000\n",
            "2022-12-08 10:25:30,331 epoch 37 - iter 8/25 - loss 0.21187740 - samples/sec: 41.50 - lr: 0.025000\n",
            "2022-12-08 10:25:32,041 epoch 37 - iter 10/25 - loss 0.21318333 - samples/sec: 37.47 - lr: 0.025000\n",
            "2022-12-08 10:25:33,348 epoch 37 - iter 12/25 - loss 0.21210313 - samples/sec: 49.01 - lr: 0.025000\n",
            "2022-12-08 10:25:34,453 epoch 37 - iter 14/25 - loss 0.21263400 - samples/sec: 57.97 - lr: 0.025000\n",
            "2022-12-08 10:25:36,272 epoch 37 - iter 16/25 - loss 0.21482329 - samples/sec: 35.21 - lr: 0.025000\n",
            "2022-12-08 10:25:37,992 epoch 37 - iter 18/25 - loss 0.21650484 - samples/sec: 37.25 - lr: 0.025000\n",
            "2022-12-08 10:25:38,974 epoch 37 - iter 20/25 - loss 0.21302207 - samples/sec: 65.26 - lr: 0.025000\n",
            "2022-12-08 10:25:40,216 epoch 37 - iter 22/25 - loss 0.21443970 - samples/sec: 51.59 - lr: 0.025000\n",
            "2022-12-08 10:25:41,403 epoch 37 - iter 24/25 - loss 0.21497091 - samples/sec: 53.95 - lr: 0.025000\n",
            "2022-12-08 10:25:41,517 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:25:41,518 EPOCH 37 done: loss 0.2152 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:25:42,278 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:25:42,287 DEV : loss 0.28405314683914185 - f1-score (micro avg)  0.6733\n",
            "2022-12-08 10:25:42,299 Epoch    37: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-12-08 10:25:42,299 BAD EPOCHS (no improvement): 4\n",
            "2022-12-08 10:25:42,300 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:25:44,026 epoch 38 - iter 2/25 - loss 0.28679888 - samples/sec: 37.10 - lr: 0.012500\n",
            "2022-12-08 10:25:45,108 epoch 38 - iter 4/25 - loss 0.23452723 - samples/sec: 59.20 - lr: 0.012500\n",
            "2022-12-08 10:25:48,252 epoch 38 - iter 6/25 - loss 0.23007558 - samples/sec: 20.37 - lr: 0.012500\n",
            "2022-12-08 10:25:49,947 epoch 38 - iter 8/25 - loss 0.22243407 - samples/sec: 37.79 - lr: 0.012500\n",
            "2022-12-08 10:25:51,256 epoch 38 - iter 10/25 - loss 0.22152696 - samples/sec: 48.94 - lr: 0.012500\n",
            "2022-12-08 10:25:53,004 epoch 38 - iter 12/25 - loss 0.21737834 - samples/sec: 36.65 - lr: 0.012500\n",
            "2022-12-08 10:25:54,469 epoch 38 - iter 14/25 - loss 0.21780891 - samples/sec: 43.71 - lr: 0.012500\n",
            "2022-12-08 10:25:55,922 epoch 38 - iter 16/25 - loss 0.22116474 - samples/sec: 44.11 - lr: 0.012500\n",
            "2022-12-08 10:25:57,205 epoch 38 - iter 18/25 - loss 0.21604898 - samples/sec: 49.90 - lr: 0.012500\n",
            "2022-12-08 10:25:58,489 epoch 38 - iter 20/25 - loss 0.21448834 - samples/sec: 49.90 - lr: 0.012500\n",
            "2022-12-08 10:26:00,097 epoch 38 - iter 22/25 - loss 0.21377495 - samples/sec: 39.84 - lr: 0.012500\n",
            "2022-12-08 10:26:01,389 epoch 38 - iter 24/25 - loss 0.21236699 - samples/sec: 49.60 - lr: 0.012500\n",
            "2022-12-08 10:26:01,517 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:26:01,518 EPOCH 38 done: loss 0.2119 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:26:02,426 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:26:02,434 DEV : loss 0.29184046387672424 - f1-score (micro avg)  0.6835\n",
            "2022-12-08 10:26:02,444 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:26:02,444 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:26:03,604 epoch 39 - iter 2/25 - loss 0.20662346 - samples/sec: 55.26 - lr: 0.012500\n",
            "2022-12-08 10:26:05,008 epoch 39 - iter 4/25 - loss 0.22639795 - samples/sec: 45.64 - lr: 0.012500\n",
            "2022-12-08 10:26:06,166 epoch 39 - iter 6/25 - loss 0.23466332 - samples/sec: 55.33 - lr: 0.012500\n",
            "2022-12-08 10:26:07,434 epoch 39 - iter 8/25 - loss 0.23662556 - samples/sec: 50.52 - lr: 0.012500\n",
            "2022-12-08 10:26:08,634 epoch 39 - iter 10/25 - loss 0.22916698 - samples/sec: 53.39 - lr: 0.012500\n",
            "2022-12-08 10:26:09,979 epoch 39 - iter 12/25 - loss 0.22912291 - samples/sec: 47.64 - lr: 0.012500\n",
            "2022-12-08 10:26:11,483 epoch 39 - iter 14/25 - loss 0.22715073 - samples/sec: 42.57 - lr: 0.012500\n",
            "2022-12-08 10:26:13,166 epoch 39 - iter 16/25 - loss 0.22252892 - samples/sec: 38.07 - lr: 0.012500\n",
            "2022-12-08 10:26:16,594 epoch 39 - iter 18/25 - loss 0.22401117 - samples/sec: 18.68 - lr: 0.012500\n",
            "2022-12-08 10:26:18,074 epoch 39 - iter 20/25 - loss 0.21899933 - samples/sec: 43.27 - lr: 0.012500\n",
            "2022-12-08 10:26:19,509 epoch 39 - iter 22/25 - loss 0.21586839 - samples/sec: 44.64 - lr: 0.012500\n",
            "2022-12-08 10:26:20,539 epoch 39 - iter 24/25 - loss 0.21577963 - samples/sec: 62.23 - lr: 0.012500\n",
            "2022-12-08 10:26:20,645 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:26:20,645 EPOCH 39 done: loss 0.2157 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:26:21,406 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:26:21,413 DEV : loss 0.292938768863678 - f1-score (micro avg)  0.6751\n",
            "2022-12-08 10:26:21,424 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:26:21,425 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:26:22,526 epoch 40 - iter 2/25 - loss 0.18945505 - samples/sec: 58.20 - lr: 0.012500\n",
            "2022-12-08 10:26:24,069 epoch 40 - iter 4/25 - loss 0.19541678 - samples/sec: 41.51 - lr: 0.012500\n",
            "2022-12-08 10:26:25,461 epoch 40 - iter 6/25 - loss 0.20162092 - samples/sec: 46.03 - lr: 0.012500\n",
            "2022-12-08 10:26:26,986 epoch 40 - iter 8/25 - loss 0.20484747 - samples/sec: 41.99 - lr: 0.012500\n",
            "2022-12-08 10:26:28,614 epoch 40 - iter 10/25 - loss 0.20660244 - samples/sec: 39.34 - lr: 0.012500\n",
            "2022-12-08 10:26:31,846 epoch 40 - iter 12/25 - loss 0.20358577 - samples/sec: 19.81 - lr: 0.012500\n",
            "2022-12-08 10:26:33,329 epoch 40 - iter 14/25 - loss 0.20142028 - samples/sec: 43.19 - lr: 0.012500\n",
            "2022-12-08 10:26:34,273 epoch 40 - iter 16/25 - loss 0.19710580 - samples/sec: 67.89 - lr: 0.012500\n",
            "2022-12-08 10:26:35,394 epoch 40 - iter 18/25 - loss 0.20009848 - samples/sec: 57.17 - lr: 0.012500\n",
            "2022-12-08 10:26:36,687 epoch 40 - iter 20/25 - loss 0.20371202 - samples/sec: 49.54 - lr: 0.012500\n",
            "2022-12-08 10:26:37,956 epoch 40 - iter 22/25 - loss 0.20532335 - samples/sec: 50.49 - lr: 0.012500\n",
            "2022-12-08 10:26:39,310 epoch 40 - iter 24/25 - loss 0.20707509 - samples/sec: 47.29 - lr: 0.012500\n",
            "2022-12-08 10:26:39,427 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:26:39,428 EPOCH 40 done: loss 0.2072 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:26:40,183 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:26:40,193 DEV : loss 0.2921699285507202 - f1-score (micro avg)  0.6817\n",
            "2022-12-08 10:26:40,205 BAD EPOCHS (no improvement): 3\n",
            "2022-12-08 10:26:40,206 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:26:41,309 epoch 41 - iter 2/25 - loss 0.20964253 - samples/sec: 58.08 - lr: 0.012500\n",
            "2022-12-08 10:26:42,729 epoch 41 - iter 4/25 - loss 0.21513193 - samples/sec: 45.10 - lr: 0.012500\n",
            "2022-12-08 10:26:44,185 epoch 41 - iter 6/25 - loss 0.21199990 - samples/sec: 44.02 - lr: 0.012500\n",
            "2022-12-08 10:26:45,759 epoch 41 - iter 8/25 - loss 0.21393705 - samples/sec: 40.69 - lr: 0.012500\n",
            "2022-12-08 10:26:47,000 epoch 41 - iter 10/25 - loss 0.21045824 - samples/sec: 51.60 - lr: 0.012500\n",
            "2022-12-08 10:26:48,402 epoch 41 - iter 12/25 - loss 0.20703785 - samples/sec: 45.71 - lr: 0.012500\n",
            "2022-12-08 10:26:51,404 epoch 41 - iter 14/25 - loss 0.20209508 - samples/sec: 21.33 - lr: 0.012500\n",
            "2022-12-08 10:26:53,015 epoch 41 - iter 16/25 - loss 0.20524308 - samples/sec: 39.77 - lr: 0.012500\n",
            "2022-12-08 10:26:54,727 epoch 41 - iter 18/25 - loss 0.20728532 - samples/sec: 37.39 - lr: 0.012500\n",
            "2022-12-08 10:26:55,713 epoch 41 - iter 20/25 - loss 0.20826485 - samples/sec: 65.03 - lr: 0.012500\n",
            "2022-12-08 10:26:57,202 epoch 41 - iter 22/25 - loss 0.20799990 - samples/sec: 43.01 - lr: 0.012500\n",
            "2022-12-08 10:26:58,860 epoch 41 - iter 24/25 - loss 0.20735837 - samples/sec: 38.63 - lr: 0.012500\n",
            "2022-12-08 10:26:59,026 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:26:59,026 EPOCH 41 done: loss 0.2069 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:26:59,805 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:26:59,813 DEV : loss 0.28613659739494324 - f1-score (micro avg)  0.678\n",
            "2022-12-08 10:26:59,823 Epoch    41: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2022-12-08 10:26:59,824 BAD EPOCHS (no improvement): 4\n",
            "2022-12-08 10:26:59,825 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:27:01,423 epoch 42 - iter 2/25 - loss 0.21214234 - samples/sec: 40.08 - lr: 0.006250\n",
            "2022-12-08 10:27:03,250 epoch 42 - iter 4/25 - loss 0.21177397 - samples/sec: 35.05 - lr: 0.006250\n",
            "2022-12-08 10:27:04,755 epoch 42 - iter 6/25 - loss 0.21393837 - samples/sec: 42.56 - lr: 0.006250\n",
            "2022-12-08 10:27:06,102 epoch 42 - iter 8/25 - loss 0.21897271 - samples/sec: 47.56 - lr: 0.006250\n",
            "2022-12-08 10:27:07,524 epoch 42 - iter 10/25 - loss 0.21093125 - samples/sec: 45.04 - lr: 0.006250\n",
            "2022-12-08 10:27:10,451 epoch 42 - iter 12/25 - loss 0.21044802 - samples/sec: 21.87 - lr: 0.006250\n",
            "2022-12-08 10:27:12,137 epoch 42 - iter 14/25 - loss 0.20952534 - samples/sec: 38.00 - lr: 0.006250\n",
            "2022-12-08 10:27:13,784 epoch 42 - iter 16/25 - loss 0.21279452 - samples/sec: 38.88 - lr: 0.006250\n",
            "2022-12-08 10:27:15,090 epoch 42 - iter 18/25 - loss 0.21039701 - samples/sec: 49.05 - lr: 0.006250\n",
            "2022-12-08 10:27:16,340 epoch 42 - iter 20/25 - loss 0.21193179 - samples/sec: 51.25 - lr: 0.006250\n",
            "2022-12-08 10:27:17,344 epoch 42 - iter 22/25 - loss 0.21248363 - samples/sec: 63.88 - lr: 0.006250\n",
            "2022-12-08 10:27:18,852 epoch 42 - iter 24/25 - loss 0.21028656 - samples/sec: 42.47 - lr: 0.006250\n",
            "2022-12-08 10:27:18,965 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:27:18,966 EPOCH 42 done: loss 0.2108 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:27:19,725 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:27:19,733 DEV : loss 0.2914345860481262 - f1-score (micro avg)  0.6798\n",
            "2022-12-08 10:27:19,742 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:27:19,743 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:27:20,874 epoch 43 - iter 2/25 - loss 0.20500881 - samples/sec: 56.64 - lr: 0.006250\n",
            "2022-12-08 10:27:22,389 epoch 43 - iter 4/25 - loss 0.19322290 - samples/sec: 42.27 - lr: 0.006250\n",
            "2022-12-08 10:27:23,925 epoch 43 - iter 6/25 - loss 0.19219225 - samples/sec: 41.71 - lr: 0.006250\n",
            "2022-12-08 10:27:24,964 epoch 43 - iter 8/25 - loss 0.20662414 - samples/sec: 61.66 - lr: 0.006250\n",
            "2022-12-08 10:27:26,107 epoch 43 - iter 10/25 - loss 0.20696237 - samples/sec: 56.05 - lr: 0.006250\n",
            "2022-12-08 10:27:27,639 epoch 43 - iter 12/25 - loss 0.20474114 - samples/sec: 41.82 - lr: 0.006250\n",
            "2022-12-08 10:27:31,023 epoch 43 - iter 14/25 - loss 0.20463618 - samples/sec: 18.92 - lr: 0.006250\n",
            "2022-12-08 10:27:32,488 epoch 43 - iter 16/25 - loss 0.20542477 - samples/sec: 43.70 - lr: 0.006250\n",
            "2022-12-08 10:27:33,766 epoch 43 - iter 18/25 - loss 0.20756421 - samples/sec: 50.12 - lr: 0.006250\n",
            "2022-12-08 10:27:35,077 epoch 43 - iter 20/25 - loss 0.20603140 - samples/sec: 48.88 - lr: 0.006250\n",
            "2022-12-08 10:27:36,633 epoch 43 - iter 22/25 - loss 0.20425641 - samples/sec: 41.17 - lr: 0.006250\n",
            "2022-12-08 10:27:38,140 epoch 43 - iter 24/25 - loss 0.20407053 - samples/sec: 42.52 - lr: 0.006250\n",
            "2022-12-08 10:27:38,245 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:27:38,246 EPOCH 43 done: loss 0.2035 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:27:38,989 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:27:38,997 DEV : loss 0.290463924407959 - f1-score (micro avg)  0.6779\n",
            "2022-12-08 10:27:39,006 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:27:39,008 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:27:40,271 epoch 44 - iter 2/25 - loss 0.20784100 - samples/sec: 50.71 - lr: 0.006250\n",
            "2022-12-08 10:27:41,924 epoch 44 - iter 4/25 - loss 0.20509161 - samples/sec: 38.75 - lr: 0.006250\n",
            "2022-12-08 10:27:43,565 epoch 44 - iter 6/25 - loss 0.21951528 - samples/sec: 39.02 - lr: 0.006250\n",
            "2022-12-08 10:27:45,255 epoch 44 - iter 8/25 - loss 0.20539819 - samples/sec: 37.91 - lr: 0.006250\n",
            "2022-12-08 10:27:46,601 epoch 44 - iter 10/25 - loss 0.20163755 - samples/sec: 47.61 - lr: 0.006250\n",
            "2022-12-08 10:27:47,929 epoch 44 - iter 12/25 - loss 0.20286299 - samples/sec: 48.22 - lr: 0.006250\n",
            "2022-12-08 10:27:51,126 epoch 44 - iter 14/25 - loss 0.20282150 - samples/sec: 20.03 - lr: 0.006250\n",
            "2022-12-08 10:27:52,516 epoch 44 - iter 16/25 - loss 0.20423955 - samples/sec: 46.09 - lr: 0.006250\n",
            "2022-12-08 10:27:53,600 epoch 44 - iter 18/25 - loss 0.20281844 - samples/sec: 59.07 - lr: 0.006250\n",
            "2022-12-08 10:27:55,148 epoch 44 - iter 20/25 - loss 0.20503561 - samples/sec: 41.39 - lr: 0.006250\n",
            "2022-12-08 10:27:56,208 epoch 44 - iter 22/25 - loss 0.20781335 - samples/sec: 60.41 - lr: 0.006250\n",
            "2022-12-08 10:27:57,571 epoch 44 - iter 24/25 - loss 0.21017518 - samples/sec: 47.03 - lr: 0.006250\n",
            "2022-12-08 10:27:57,682 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:27:57,683 EPOCH 44 done: loss 0.2098 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:27:58,435 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:27:58,443 DEV : loss 0.2919396162033081 - f1-score (micro avg)  0.6704\n",
            "2022-12-08 10:27:58,453 BAD EPOCHS (no improvement): 3\n",
            "2022-12-08 10:27:58,454 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:28:00,289 epoch 45 - iter 2/25 - loss 0.24747918 - samples/sec: 34.90 - lr: 0.006250\n",
            "2022-12-08 10:28:01,475 epoch 45 - iter 4/25 - loss 0.23106102 - samples/sec: 54.04 - lr: 0.006250\n",
            "2022-12-08 10:28:03,014 epoch 45 - iter 6/25 - loss 0.22136553 - samples/sec: 41.62 - lr: 0.006250\n",
            "2022-12-08 10:28:04,634 epoch 45 - iter 8/25 - loss 0.22634257 - samples/sec: 39.53 - lr: 0.006250\n",
            "2022-12-08 10:28:06,021 epoch 45 - iter 10/25 - loss 0.22300016 - samples/sec: 46.19 - lr: 0.006250\n",
            "2022-12-08 10:28:07,581 epoch 45 - iter 12/25 - loss 0.21915203 - samples/sec: 41.06 - lr: 0.006250\n",
            "2022-12-08 10:28:08,591 epoch 45 - iter 14/25 - loss 0.21493580 - samples/sec: 63.45 - lr: 0.006250\n",
            "2022-12-08 10:28:09,607 epoch 45 - iter 16/25 - loss 0.21364782 - samples/sec: 63.09 - lr: 0.006250\n",
            "2022-12-08 10:28:10,961 epoch 45 - iter 18/25 - loss 0.21425414 - samples/sec: 47.30 - lr: 0.006250\n",
            "2022-12-08 10:28:13,977 epoch 45 - iter 20/25 - loss 0.21067491 - samples/sec: 21.23 - lr: 0.006250\n",
            "2022-12-08 10:28:15,270 epoch 45 - iter 22/25 - loss 0.20813913 - samples/sec: 49.55 - lr: 0.006250\n",
            "2022-12-08 10:28:16,492 epoch 45 - iter 24/25 - loss 0.20389115 - samples/sec: 52.46 - lr: 0.006250\n",
            "2022-12-08 10:28:16,633 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:28:16,634 EPOCH 45 done: loss 0.2040 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:28:17,425 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:28:17,436 DEV : loss 0.2971685230731964 - f1-score (micro avg)  0.6694\n",
            "2022-12-08 10:28:17,445 Epoch    45: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2022-12-08 10:28:17,446 BAD EPOCHS (no improvement): 4\n",
            "2022-12-08 10:28:17,447 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:28:20,341 epoch 46 - iter 2/25 - loss 0.21109999 - samples/sec: 22.13 - lr: 0.003125\n",
            "2022-12-08 10:28:21,961 epoch 46 - iter 4/25 - loss 0.19813627 - samples/sec: 39.52 - lr: 0.003125\n",
            "2022-12-08 10:28:23,286 epoch 46 - iter 6/25 - loss 0.19199911 - samples/sec: 48.35 - lr: 0.003125\n",
            "2022-12-08 10:28:24,615 epoch 46 - iter 8/25 - loss 0.18972010 - samples/sec: 48.24 - lr: 0.003125\n",
            "2022-12-08 10:28:25,938 epoch 46 - iter 10/25 - loss 0.19857263 - samples/sec: 48.42 - lr: 0.003125\n",
            "2022-12-08 10:28:27,459 epoch 46 - iter 12/25 - loss 0.19107446 - samples/sec: 42.09 - lr: 0.003125\n",
            "2022-12-08 10:28:28,677 epoch 46 - iter 14/25 - loss 0.19650703 - samples/sec: 52.62 - lr: 0.003125\n",
            "2022-12-08 10:28:30,226 epoch 46 - iter 16/25 - loss 0.20196987 - samples/sec: 41.33 - lr: 0.003125\n",
            "2022-12-08 10:28:31,395 epoch 46 - iter 18/25 - loss 0.20234274 - samples/sec: 54.82 - lr: 0.003125\n",
            "2022-12-08 10:28:32,746 epoch 46 - iter 20/25 - loss 0.20424462 - samples/sec: 47.43 - lr: 0.003125\n",
            "2022-12-08 10:28:34,266 epoch 46 - iter 22/25 - loss 0.20793504 - samples/sec: 42.13 - lr: 0.003125\n",
            "2022-12-08 10:28:35,331 epoch 46 - iter 24/25 - loss 0.20720986 - samples/sec: 60.20 - lr: 0.003125\n",
            "2022-12-08 10:28:35,467 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:28:35,468 EPOCH 46 done: loss 0.2070 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:28:36,226 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:28:36,233 DEV : loss 0.2950187623500824 - f1-score (micro avg)  0.6722\n",
            "2022-12-08 10:28:36,244 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:28:36,245 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:28:37,193 epoch 47 - iter 2/25 - loss 0.24423565 - samples/sec: 67.61 - lr: 0.003125\n",
            "2022-12-08 10:28:40,319 epoch 47 - iter 4/25 - loss 0.21820243 - samples/sec: 20.48 - lr: 0.003125\n",
            "2022-12-08 10:28:41,945 epoch 47 - iter 6/25 - loss 0.21958935 - samples/sec: 39.37 - lr: 0.003125\n",
            "2022-12-08 10:28:43,120 epoch 47 - iter 8/25 - loss 0.20155798 - samples/sec: 54.56 - lr: 0.003125\n",
            "2022-12-08 10:28:44,620 epoch 47 - iter 10/25 - loss 0.20360692 - samples/sec: 42.69 - lr: 0.003125\n",
            "2022-12-08 10:28:45,853 epoch 47 - iter 12/25 - loss 0.20224907 - samples/sec: 51.98 - lr: 0.003125\n",
            "2022-12-08 10:28:47,651 epoch 47 - iter 14/25 - loss 0.20590830 - samples/sec: 35.62 - lr: 0.003125\n",
            "2022-12-08 10:28:49,363 epoch 47 - iter 16/25 - loss 0.20485120 - samples/sec: 37.41 - lr: 0.003125\n",
            "2022-12-08 10:28:50,784 epoch 47 - iter 18/25 - loss 0.20223955 - samples/sec: 45.08 - lr: 0.003125\n",
            "2022-12-08 10:28:51,784 epoch 47 - iter 20/25 - loss 0.20220789 - samples/sec: 64.03 - lr: 0.003125\n",
            "2022-12-08 10:28:53,234 epoch 47 - iter 22/25 - loss 0.20045239 - samples/sec: 44.21 - lr: 0.003125\n",
            "2022-12-08 10:28:54,686 epoch 47 - iter 24/25 - loss 0.19938891 - samples/sec: 44.11 - lr: 0.003125\n",
            "2022-12-08 10:28:54,799 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:28:54,800 EPOCH 47 done: loss 0.1999 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:28:55,559 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:28:55,567 DEV : loss 0.2933584749698639 - f1-score (micro avg)  0.6807\n",
            "2022-12-08 10:28:55,579 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:28:55,580 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:28:57,412 epoch 48 - iter 2/25 - loss 0.23163839 - samples/sec: 34.96 - lr: 0.003125\n",
            "2022-12-08 10:28:58,982 epoch 48 - iter 4/25 - loss 0.21263210 - samples/sec: 40.78 - lr: 0.003125\n",
            "2022-12-08 10:29:02,399 epoch 48 - iter 6/25 - loss 0.20529527 - samples/sec: 18.74 - lr: 0.003125\n",
            "2022-12-08 10:29:04,071 epoch 48 - iter 8/25 - loss 0.20620668 - samples/sec: 38.31 - lr: 0.003125\n",
            "2022-12-08 10:29:05,436 epoch 48 - iter 10/25 - loss 0.20606923 - samples/sec: 46.93 - lr: 0.003125\n",
            "2022-12-08 10:29:06,963 epoch 48 - iter 12/25 - loss 0.21223066 - samples/sec: 41.94 - lr: 0.003125\n",
            "2022-12-08 10:29:08,366 epoch 48 - iter 14/25 - loss 0.20814615 - samples/sec: 45.66 - lr: 0.003125\n",
            "2022-12-08 10:29:09,463 epoch 48 - iter 16/25 - loss 0.20466818 - samples/sec: 58.41 - lr: 0.003125\n",
            "2022-12-08 10:29:10,619 epoch 48 - iter 18/25 - loss 0.19939684 - samples/sec: 55.42 - lr: 0.003125\n",
            "2022-12-08 10:29:11,654 epoch 48 - iter 20/25 - loss 0.19854400 - samples/sec: 61.92 - lr: 0.003125\n",
            "2022-12-08 10:29:12,869 epoch 48 - iter 22/25 - loss 0.19961843 - samples/sec: 52.71 - lr: 0.003125\n",
            "2022-12-08 10:29:14,130 epoch 48 - iter 24/25 - loss 0.20404164 - samples/sec: 50.84 - lr: 0.003125\n",
            "2022-12-08 10:29:14,241 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:29:14,242 EPOCH 48 done: loss 0.2036 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:29:14,997 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:29:15,005 DEV : loss 0.29252463579177856 - f1-score (micro avg)  0.6798\n",
            "2022-12-08 10:29:15,014 BAD EPOCHS (no improvement): 3\n",
            "2022-12-08 10:29:15,016 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:29:16,122 epoch 49 - iter 2/25 - loss 0.16770540 - samples/sec: 57.92 - lr: 0.003125\n",
            "2022-12-08 10:29:17,369 epoch 49 - iter 4/25 - loss 0.18985222 - samples/sec: 51.38 - lr: 0.003125\n",
            "2022-12-08 10:29:18,635 epoch 49 - iter 6/25 - loss 0.19710074 - samples/sec: 50.62 - lr: 0.003125\n",
            "2022-12-08 10:29:19,679 epoch 49 - iter 8/25 - loss 0.19715514 - samples/sec: 61.37 - lr: 0.003125\n",
            "2022-12-08 10:29:20,827 epoch 49 - iter 10/25 - loss 0.20343890 - samples/sec: 55.83 - lr: 0.003125\n",
            "2022-12-08 10:29:22,251 epoch 49 - iter 12/25 - loss 0.20113273 - samples/sec: 44.99 - lr: 0.003125\n",
            "2022-12-08 10:29:23,836 epoch 49 - iter 14/25 - loss 0.20643216 - samples/sec: 40.41 - lr: 0.003125\n",
            "2022-12-08 10:29:25,353 epoch 49 - iter 16/25 - loss 0.20407217 - samples/sec: 42.20 - lr: 0.003125\n",
            "2022-12-08 10:29:26,721 epoch 49 - iter 18/25 - loss 0.20401174 - samples/sec: 46.83 - lr: 0.003125\n",
            "2022-12-08 10:29:29,645 epoch 49 - iter 20/25 - loss 0.20028544 - samples/sec: 21.90 - lr: 0.003125\n",
            "2022-12-08 10:29:31,061 epoch 49 - iter 22/25 - loss 0.20108232 - samples/sec: 45.25 - lr: 0.003125\n",
            "2022-12-08 10:29:32,678 epoch 49 - iter 24/25 - loss 0.20089223 - samples/sec: 39.61 - lr: 0.003125\n",
            "2022-12-08 10:29:32,815 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:29:32,816 EPOCH 49 done: loss 0.2010 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:29:33,662 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:29:33,669 DEV : loss 0.29397445917129517 - f1-score (micro avg)  0.675\n",
            "2022-12-08 10:29:33,680 Epoch    49: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2022-12-08 10:29:33,681 BAD EPOCHS (no improvement): 4\n",
            "2022-12-08 10:29:33,681 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:29:35,371 epoch 50 - iter 2/25 - loss 0.20956487 - samples/sec: 37.90 - lr: 0.001563\n",
            "2022-12-08 10:29:38,400 epoch 50 - iter 4/25 - loss 0.22517835 - samples/sec: 21.14 - lr: 0.001563\n",
            "2022-12-08 10:29:39,840 epoch 50 - iter 6/25 - loss 0.21989549 - samples/sec: 44.49 - lr: 0.001563\n",
            "2022-12-08 10:29:41,380 epoch 50 - iter 8/25 - loss 0.20809392 - samples/sec: 41.60 - lr: 0.001563\n",
            "2022-12-08 10:29:42,427 epoch 50 - iter 10/25 - loss 0.20985305 - samples/sec: 61.18 - lr: 0.001563\n",
            "2022-12-08 10:29:43,700 epoch 50 - iter 12/25 - loss 0.20688039 - samples/sec: 50.31 - lr: 0.001563\n",
            "2022-12-08 10:29:45,453 epoch 50 - iter 14/25 - loss 0.20831947 - samples/sec: 36.55 - lr: 0.001563\n",
            "2022-12-08 10:29:46,790 epoch 50 - iter 16/25 - loss 0.20386127 - samples/sec: 47.88 - lr: 0.001563\n",
            "2022-12-08 10:29:48,197 epoch 50 - iter 18/25 - loss 0.20725859 - samples/sec: 45.53 - lr: 0.001563\n",
            "2022-12-08 10:29:49,190 epoch 50 - iter 20/25 - loss 0.20228264 - samples/sec: 64.59 - lr: 0.001563\n",
            "2022-12-08 10:29:50,218 epoch 50 - iter 22/25 - loss 0.20260183 - samples/sec: 62.29 - lr: 0.001563\n",
            "2022-12-08 10:29:51,612 epoch 50 - iter 24/25 - loss 0.20686009 - samples/sec: 45.95 - lr: 0.001563\n",
            "2022-12-08 10:29:51,760 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:29:51,761 EPOCH 50 done: loss 0.2063 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:29:52,514 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:29:52,523 DEV : loss 0.29537585377693176 - f1-score (micro avg)  0.6778\n",
            "2022-12-08 10:29:52,532 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:29:52,532 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:29:54,097 epoch 51 - iter 2/25 - loss 0.21203142 - samples/sec: 40.94 - lr: 0.001563\n",
            "2022-12-08 10:29:55,473 epoch 51 - iter 4/25 - loss 0.20253648 - samples/sec: 46.56 - lr: 0.001563\n",
            "2022-12-08 10:29:57,227 epoch 51 - iter 6/25 - loss 0.20179828 - samples/sec: 36.50 - lr: 0.001563\n",
            "2022-12-08 10:29:58,549 epoch 51 - iter 8/25 - loss 0.20462258 - samples/sec: 48.45 - lr: 0.001563\n",
            "2022-12-08 10:29:59,696 epoch 51 - iter 10/25 - loss 0.20553526 - samples/sec: 55.87 - lr: 0.001563\n",
            "2022-12-08 10:30:02,514 epoch 51 - iter 12/25 - loss 0.20058076 - samples/sec: 22.72 - lr: 0.001563\n",
            "2022-12-08 10:30:03,793 epoch 51 - iter 14/25 - loss 0.19582331 - samples/sec: 50.08 - lr: 0.001563\n",
            "2022-12-08 10:30:05,184 epoch 51 - iter 16/25 - loss 0.20165979 - samples/sec: 46.06 - lr: 0.001563\n",
            "2022-12-08 10:30:06,662 epoch 51 - iter 18/25 - loss 0.19834350 - samples/sec: 43.32 - lr: 0.001563\n",
            "2022-12-08 10:30:08,397 epoch 51 - iter 20/25 - loss 0.20133577 - samples/sec: 36.93 - lr: 0.001563\n",
            "2022-12-08 10:30:09,493 epoch 51 - iter 22/25 - loss 0.20150665 - samples/sec: 58.42 - lr: 0.001563\n",
            "2022-12-08 10:30:10,934 epoch 51 - iter 24/25 - loss 0.19942701 - samples/sec: 44.46 - lr: 0.001563\n",
            "2022-12-08 10:30:11,050 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:30:11,051 EPOCH 51 done: loss 0.1991 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:30:11,881 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:30:11,888 DEV : loss 0.29333987832069397 - f1-score (micro avg)  0.6732\n",
            "2022-12-08 10:30:11,899 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:30:11,900 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:30:13,165 epoch 52 - iter 2/25 - loss 0.20548822 - samples/sec: 50.61 - lr: 0.001563\n",
            "2022-12-08 10:30:14,384 epoch 52 - iter 4/25 - loss 0.19641057 - samples/sec: 52.56 - lr: 0.001563\n",
            "2022-12-08 10:30:16,074 epoch 52 - iter 6/25 - loss 0.19494507 - samples/sec: 37.91 - lr: 0.001563\n",
            "2022-12-08 10:30:17,927 epoch 52 - iter 8/25 - loss 0.19118471 - samples/sec: 34.56 - lr: 0.001563\n",
            "2022-12-08 10:30:19,216 epoch 52 - iter 10/25 - loss 0.19361812 - samples/sec: 49.70 - lr: 0.001563\n",
            "2022-12-08 10:30:20,577 epoch 52 - iter 12/25 - loss 0.19518234 - samples/sec: 47.06 - lr: 0.001563\n",
            "2022-12-08 10:30:21,879 epoch 52 - iter 14/25 - loss 0.20324503 - samples/sec: 49.24 - lr: 0.001563\n",
            "2022-12-08 10:30:23,207 epoch 52 - iter 16/25 - loss 0.20241798 - samples/sec: 48.25 - lr: 0.001563\n",
            "2022-12-08 10:30:26,299 epoch 52 - iter 18/25 - loss 0.20157095 - samples/sec: 20.71 - lr: 0.001563\n",
            "2022-12-08 10:30:27,926 epoch 52 - iter 20/25 - loss 0.20218008 - samples/sec: 39.36 - lr: 0.001563\n",
            "2022-12-08 10:30:29,164 epoch 52 - iter 22/25 - loss 0.20086468 - samples/sec: 51.76 - lr: 0.001563\n",
            "2022-12-08 10:30:30,612 epoch 52 - iter 24/25 - loss 0.20125799 - samples/sec: 44.23 - lr: 0.001563\n",
            "2022-12-08 10:30:30,720 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:30:30,721 EPOCH 52 done: loss 0.2011 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:30:31,478 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:30:31,488 DEV : loss 0.29332539439201355 - f1-score (micro avg)  0.6769\n",
            "2022-12-08 10:30:31,497 BAD EPOCHS (no improvement): 3\n",
            "2022-12-08 10:30:31,498 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:30:33,107 epoch 53 - iter 2/25 - loss 0.21377884 - samples/sec: 39.81 - lr: 0.001563\n",
            "2022-12-08 10:30:34,832 epoch 53 - iter 4/25 - loss 0.21349289 - samples/sec: 37.14 - lr: 0.001563\n",
            "2022-12-08 10:30:35,876 epoch 53 - iter 6/25 - loss 0.21559284 - samples/sec: 61.37 - lr: 0.001563\n",
            "2022-12-08 10:30:38,866 epoch 53 - iter 8/25 - loss 0.20745107 - samples/sec: 21.42 - lr: 0.001563\n",
            "2022-12-08 10:30:40,405 epoch 53 - iter 10/25 - loss 0.21033770 - samples/sec: 41.62 - lr: 0.001563\n",
            "2022-12-08 10:30:41,825 epoch 53 - iter 12/25 - loss 0.20448620 - samples/sec: 45.10 - lr: 0.001563\n",
            "2022-12-08 10:30:42,947 epoch 53 - iter 14/25 - loss 0.20265986 - samples/sec: 57.09 - lr: 0.001563\n",
            "2022-12-08 10:30:44,616 epoch 53 - iter 16/25 - loss 0.20098176 - samples/sec: 38.39 - lr: 0.001563\n",
            "2022-12-08 10:30:46,079 epoch 53 - iter 18/25 - loss 0.20192016 - samples/sec: 43.77 - lr: 0.001563\n",
            "2022-12-08 10:30:47,496 epoch 53 - iter 20/25 - loss 0.20191132 - samples/sec: 45.21 - lr: 0.001563\n",
            "2022-12-08 10:30:48,951 epoch 53 - iter 22/25 - loss 0.20518327 - samples/sec: 44.03 - lr: 0.001563\n",
            "2022-12-08 10:30:50,107 epoch 53 - iter 24/25 - loss 0.20370806 - samples/sec: 55.43 - lr: 0.001563\n",
            "2022-12-08 10:30:50,206 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:30:50,206 EPOCH 53 done: loss 0.2035 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:30:51,120 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:30:51,132 DEV : loss 0.2931651473045349 - f1-score (micro avg)  0.6741\n",
            "2022-12-08 10:30:51,146 Epoch    53: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2022-12-08 10:30:51,147 BAD EPOCHS (no improvement): 4\n",
            "2022-12-08 10:30:51,148 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:30:52,443 epoch 54 - iter 2/25 - loss 0.21137559 - samples/sec: 49.45 - lr: 0.000781\n",
            "2022-12-08 10:30:53,998 epoch 54 - iter 4/25 - loss 0.20142164 - samples/sec: 41.19 - lr: 0.000781\n",
            "2022-12-08 10:30:57,254 epoch 54 - iter 6/25 - loss 0.20130789 - samples/sec: 19.66 - lr: 0.000781\n",
            "2022-12-08 10:30:58,490 epoch 54 - iter 8/25 - loss 0.19931346 - samples/sec: 51.86 - lr: 0.000781\n",
            "2022-12-08 10:31:00,082 epoch 54 - iter 10/25 - loss 0.21095750 - samples/sec: 40.23 - lr: 0.000781\n",
            "2022-12-08 10:31:01,334 epoch 54 - iter 12/25 - loss 0.21128075 - samples/sec: 51.15 - lr: 0.000781\n",
            "2022-12-08 10:31:02,502 epoch 54 - iter 14/25 - loss 0.20848253 - samples/sec: 54.89 - lr: 0.000781\n",
            "2022-12-08 10:31:03,796 epoch 54 - iter 16/25 - loss 0.20731817 - samples/sec: 49.49 - lr: 0.000781\n",
            "2022-12-08 10:31:04,770 epoch 54 - iter 18/25 - loss 0.20501457 - samples/sec: 65.81 - lr: 0.000781\n",
            "2022-12-08 10:31:06,280 epoch 54 - iter 20/25 - loss 0.20450362 - samples/sec: 42.41 - lr: 0.000781\n",
            "2022-12-08 10:31:07,276 epoch 54 - iter 22/25 - loss 0.20409035 - samples/sec: 64.37 - lr: 0.000781\n",
            "2022-12-08 10:31:08,992 epoch 54 - iter 24/25 - loss 0.20240677 - samples/sec: 37.32 - lr: 0.000781\n",
            "2022-12-08 10:31:09,119 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:31:09,120 EPOCH 54 done: loss 0.2020 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:31:09,904 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:31:09,911 DEV : loss 0.2931874990463257 - f1-score (micro avg)  0.6741\n",
            "2022-12-08 10:31:09,922 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:31:09,923 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:31:11,674 epoch 55 - iter 2/25 - loss 0.18987051 - samples/sec: 36.57 - lr: 0.000781\n",
            "2022-12-08 10:31:13,151 epoch 55 - iter 4/25 - loss 0.17512579 - samples/sec: 43.38 - lr: 0.000781\n",
            "2022-12-08 10:31:14,664 epoch 55 - iter 6/25 - loss 0.18768857 - samples/sec: 42.35 - lr: 0.000781\n",
            "2022-12-08 10:31:15,881 epoch 55 - iter 8/25 - loss 0.18979405 - samples/sec: 52.64 - lr: 0.000781\n",
            "2022-12-08 10:31:17,045 epoch 55 - iter 10/25 - loss 0.19140348 - samples/sec: 55.04 - lr: 0.000781\n",
            "2022-12-08 10:31:18,707 epoch 55 - iter 12/25 - loss 0.19425064 - samples/sec: 38.53 - lr: 0.000781\n",
            "2022-12-08 10:31:20,328 epoch 55 - iter 14/25 - loss 0.19534301 - samples/sec: 39.50 - lr: 0.000781\n",
            "2022-12-08 10:31:21,574 epoch 55 - iter 16/25 - loss 0.19949431 - samples/sec: 51.44 - lr: 0.000781\n",
            "2022-12-08 10:31:24,921 epoch 55 - iter 18/25 - loss 0.19580123 - samples/sec: 19.13 - lr: 0.000781\n",
            "2022-12-08 10:31:25,917 epoch 55 - iter 20/25 - loss 0.19258534 - samples/sec: 64.35 - lr: 0.000781\n",
            "2022-12-08 10:31:27,221 epoch 55 - iter 22/25 - loss 0.19825778 - samples/sec: 49.11 - lr: 0.000781\n",
            "2022-12-08 10:31:28,580 epoch 55 - iter 24/25 - loss 0.19816228 - samples/sec: 47.16 - lr: 0.000781\n",
            "2022-12-08 10:31:28,697 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:31:28,698 EPOCH 55 done: loss 0.1986 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:31:29,460 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:31:29,468 DEV : loss 0.29278016090393066 - f1-score (micro avg)  0.6742\n",
            "2022-12-08 10:31:29,478 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:31:29,480 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:31:30,536 epoch 56 - iter 2/25 - loss 0.19873633 - samples/sec: 60.67 - lr: 0.000781\n",
            "2022-12-08 10:31:32,215 epoch 56 - iter 4/25 - loss 0.18545155 - samples/sec: 38.15 - lr: 0.000781\n",
            "2022-12-08 10:31:33,796 epoch 56 - iter 6/25 - loss 0.20771099 - samples/sec: 40.53 - lr: 0.000781\n",
            "2022-12-08 10:31:34,935 epoch 56 - iter 8/25 - loss 0.20057443 - samples/sec: 56.28 - lr: 0.000781\n",
            "2022-12-08 10:31:36,388 epoch 56 - iter 10/25 - loss 0.19621449 - samples/sec: 44.06 - lr: 0.000781\n",
            "2022-12-08 10:31:37,657 epoch 56 - iter 12/25 - loss 0.19467311 - samples/sec: 50.48 - lr: 0.000781\n",
            "2022-12-08 10:31:40,882 epoch 56 - iter 14/25 - loss 0.20086422 - samples/sec: 19.86 - lr: 0.000781\n",
            "2022-12-08 10:31:41,903 epoch 56 - iter 16/25 - loss 0.20211535 - samples/sec: 62.76 - lr: 0.000781\n",
            "2022-12-08 10:31:43,578 epoch 56 - iter 18/25 - loss 0.20054589 - samples/sec: 38.23 - lr: 0.000781\n",
            "2022-12-08 10:31:45,071 epoch 56 - iter 20/25 - loss 0.20039893 - samples/sec: 42.91 - lr: 0.000781\n",
            "2022-12-08 10:31:46,318 epoch 56 - iter 22/25 - loss 0.20230764 - samples/sec: 51.34 - lr: 0.000781\n",
            "2022-12-08 10:31:47,552 epoch 56 - iter 24/25 - loss 0.20320041 - samples/sec: 51.95 - lr: 0.000781\n",
            "2022-12-08 10:31:47,662 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:31:47,663 EPOCH 56 done: loss 0.2030 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:31:48,440 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:31:48,448 DEV : loss 0.29318180680274963 - f1-score (micro avg)  0.6741\n",
            "2022-12-08 10:31:48,458 BAD EPOCHS (no improvement): 3\n",
            "2022-12-08 10:31:48,459 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:31:49,902 epoch 57 - iter 2/25 - loss 0.19898474 - samples/sec: 44.41 - lr: 0.000781\n",
            "2022-12-08 10:31:51,401 epoch 57 - iter 4/25 - loss 0.19895374 - samples/sec: 42.74 - lr: 0.000781\n",
            "2022-12-08 10:31:53,416 epoch 57 - iter 6/25 - loss 0.20032051 - samples/sec: 31.78 - lr: 0.000781\n",
            "2022-12-08 10:31:56,343 epoch 57 - iter 8/25 - loss 0.19763379 - samples/sec: 21.88 - lr: 0.000781\n",
            "2022-12-08 10:31:57,777 epoch 57 - iter 10/25 - loss 0.19662397 - samples/sec: 44.66 - lr: 0.000781\n",
            "2022-12-08 10:31:58,953 epoch 57 - iter 12/25 - loss 0.19796127 - samples/sec: 54.47 - lr: 0.000781\n",
            "2022-12-08 10:32:00,512 epoch 57 - iter 14/25 - loss 0.20720756 - samples/sec: 41.09 - lr: 0.000781\n",
            "2022-12-08 10:32:01,755 epoch 57 - iter 16/25 - loss 0.20652131 - samples/sec: 51.55 - lr: 0.000781\n",
            "2022-12-08 10:32:03,161 epoch 57 - iter 18/25 - loss 0.20699652 - samples/sec: 45.55 - lr: 0.000781\n",
            "2022-12-08 10:32:04,462 epoch 57 - iter 20/25 - loss 0.20272997 - samples/sec: 49.26 - lr: 0.000781\n",
            "2022-12-08 10:32:05,636 epoch 57 - iter 22/25 - loss 0.20434589 - samples/sec: 54.56 - lr: 0.000781\n",
            "2022-12-08 10:32:07,392 epoch 57 - iter 24/25 - loss 0.20184070 - samples/sec: 36.48 - lr: 0.000781\n",
            "2022-12-08 10:32:07,513 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:32:07,513 EPOCH 57 done: loss 0.2013 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:32:08,274 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:32:08,282 DEV : loss 0.2916466295719147 - f1-score (micro avg)  0.6751\n",
            "2022-12-08 10:32:08,292 Epoch    57: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2022-12-08 10:32:08,292 BAD EPOCHS (no improvement): 4\n",
            "2022-12-08 10:32:08,293 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:32:09,561 epoch 58 - iter 2/25 - loss 0.21342302 - samples/sec: 50.52 - lr: 0.000391\n",
            "2022-12-08 10:32:12,911 epoch 58 - iter 4/25 - loss 0.19594989 - samples/sec: 19.11 - lr: 0.000391\n",
            "2022-12-08 10:32:14,128 epoch 58 - iter 6/25 - loss 0.19463203 - samples/sec: 52.65 - lr: 0.000391\n",
            "2022-12-08 10:32:15,264 epoch 58 - iter 8/25 - loss 0.19206030 - samples/sec: 56.42 - lr: 0.000391\n",
            "2022-12-08 10:32:16,906 epoch 58 - iter 10/25 - loss 0.19106844 - samples/sec: 39.00 - lr: 0.000391\n",
            "2022-12-08 10:32:18,201 epoch 58 - iter 12/25 - loss 0.19305020 - samples/sec: 49.46 - lr: 0.000391\n",
            "2022-12-08 10:32:19,756 epoch 58 - iter 14/25 - loss 0.20006244 - samples/sec: 41.19 - lr: 0.000391\n",
            "2022-12-08 10:32:20,929 epoch 58 - iter 16/25 - loss 0.20028557 - samples/sec: 54.63 - lr: 0.000391\n",
            "2022-12-08 10:32:22,282 epoch 58 - iter 18/25 - loss 0.20008001 - samples/sec: 47.35 - lr: 0.000391\n",
            "2022-12-08 10:32:24,024 epoch 58 - iter 20/25 - loss 0.20601928 - samples/sec: 36.75 - lr: 0.000391\n",
            "2022-12-08 10:32:25,384 epoch 58 - iter 22/25 - loss 0.20268697 - samples/sec: 47.11 - lr: 0.000391\n",
            "2022-12-08 10:32:26,955 epoch 58 - iter 24/25 - loss 0.20229553 - samples/sec: 40.77 - lr: 0.000391\n",
            "2022-12-08 10:32:27,058 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:32:27,059 EPOCH 58 done: loss 0.2028 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:32:27,834 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:32:27,841 DEV : loss 0.2919526696205139 - f1-score (micro avg)  0.6742\n",
            "2022-12-08 10:32:27,852 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:32:27,854 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:32:29,148 epoch 59 - iter 2/25 - loss 0.23031901 - samples/sec: 49.52 - lr: 0.000391\n",
            "2022-12-08 10:32:30,399 epoch 59 - iter 4/25 - loss 0.20936313 - samples/sec: 51.21 - lr: 0.000391\n",
            "2022-12-08 10:32:32,054 epoch 59 - iter 6/25 - loss 0.20198284 - samples/sec: 38.69 - lr: 0.000391\n",
            "2022-12-08 10:32:33,761 epoch 59 - iter 8/25 - loss 0.21218237 - samples/sec: 37.52 - lr: 0.000391\n",
            "2022-12-08 10:32:36,891 epoch 59 - iter 10/25 - loss 0.20713890 - samples/sec: 20.46 - lr: 0.000391\n",
            "2022-12-08 10:32:38,359 epoch 59 - iter 12/25 - loss 0.20575463 - samples/sec: 43.64 - lr: 0.000391\n",
            "2022-12-08 10:32:39,761 epoch 59 - iter 14/25 - loss 0.21059104 - samples/sec: 45.67 - lr: 0.000391\n",
            "2022-12-08 10:32:41,100 epoch 59 - iter 16/25 - loss 0.20745526 - samples/sec: 47.85 - lr: 0.000391\n",
            "2022-12-08 10:32:42,411 epoch 59 - iter 18/25 - loss 0.20944994 - samples/sec: 48.87 - lr: 0.000391\n",
            "2022-12-08 10:32:44,128 epoch 59 - iter 20/25 - loss 0.20625486 - samples/sec: 37.30 - lr: 0.000391\n",
            "2022-12-08 10:32:45,344 epoch 59 - iter 22/25 - loss 0.20171375 - samples/sec: 52.69 - lr: 0.000391\n",
            "2022-12-08 10:32:46,837 epoch 59 - iter 24/25 - loss 0.20082450 - samples/sec: 42.89 - lr: 0.000391\n",
            "2022-12-08 10:32:46,951 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:32:46,952 EPOCH 59 done: loss 0.2004 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:32:47,727 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:32:47,735 DEV : loss 0.29184234142303467 - f1-score (micro avg)  0.6742\n",
            "2022-12-08 10:32:47,745 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:32:47,746 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:32:49,393 epoch 60 - iter 2/25 - loss 0.23811035 - samples/sec: 38.87 - lr: 0.000391\n",
            "2022-12-08 10:32:50,632 epoch 60 - iter 4/25 - loss 0.22624568 - samples/sec: 51.73 - lr: 0.000391\n",
            "2022-12-08 10:32:52,008 epoch 60 - iter 6/25 - loss 0.22983792 - samples/sec: 46.55 - lr: 0.000391\n",
            "2022-12-08 10:32:53,695 epoch 60 - iter 8/25 - loss 0.22902455 - samples/sec: 37.97 - lr: 0.000391\n",
            "2022-12-08 10:32:57,042 epoch 60 - iter 10/25 - loss 0.21834902 - samples/sec: 19.13 - lr: 0.000391\n",
            "2022-12-08 10:32:58,447 epoch 60 - iter 12/25 - loss 0.21191708 - samples/sec: 45.61 - lr: 0.000391\n",
            "2022-12-08 10:32:59,647 epoch 60 - iter 14/25 - loss 0.21229375 - samples/sec: 53.35 - lr: 0.000391\n",
            "2022-12-08 10:33:01,312 epoch 60 - iter 16/25 - loss 0.21207244 - samples/sec: 38.48 - lr: 0.000391\n",
            "2022-12-08 10:33:02,299 epoch 60 - iter 18/25 - loss 0.20862979 - samples/sec: 64.90 - lr: 0.000391\n",
            "2022-12-08 10:33:03,680 epoch 60 - iter 20/25 - loss 0.20376556 - samples/sec: 46.38 - lr: 0.000391\n",
            "2022-12-08 10:33:04,922 epoch 60 - iter 22/25 - loss 0.20315316 - samples/sec: 51.60 - lr: 0.000391\n",
            "2022-12-08 10:33:06,309 epoch 60 - iter 24/25 - loss 0.20102932 - samples/sec: 46.18 - lr: 0.000391\n",
            "2022-12-08 10:33:06,410 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:33:06,410 EPOCH 60 done: loss 0.2011 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:33:07,170 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:33:07,179 DEV : loss 0.29172247648239136 - f1-score (micro avg)  0.6742\n",
            "2022-12-08 10:33:07,189 BAD EPOCHS (no improvement): 3\n",
            "2022-12-08 10:33:07,191 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:33:08,594 epoch 61 - iter 2/25 - loss 0.22007731 - samples/sec: 45.67 - lr: 0.000391\n",
            "2022-12-08 10:33:09,804 epoch 61 - iter 4/25 - loss 0.20359632 - samples/sec: 52.96 - lr: 0.000391\n",
            "2022-12-08 10:33:10,986 epoch 61 - iter 6/25 - loss 0.18725706 - samples/sec: 54.19 - lr: 0.000391\n",
            "2022-12-08 10:33:12,131 epoch 61 - iter 8/25 - loss 0.18411848 - samples/sec: 55.96 - lr: 0.000391\n",
            "2022-12-08 10:33:13,608 epoch 61 - iter 10/25 - loss 0.19665762 - samples/sec: 43.39 - lr: 0.000391\n",
            "2022-12-08 10:33:15,060 epoch 61 - iter 12/25 - loss 0.19777798 - samples/sec: 44.11 - lr: 0.000391\n",
            "2022-12-08 10:33:16,617 epoch 61 - iter 14/25 - loss 0.19667881 - samples/sec: 41.13 - lr: 0.000391\n",
            "2022-12-08 10:33:17,927 epoch 61 - iter 16/25 - loss 0.19752523 - samples/sec: 48.92 - lr: 0.000391\n",
            "2022-12-08 10:33:19,187 epoch 61 - iter 18/25 - loss 0.20457528 - samples/sec: 50.83 - lr: 0.000391\n",
            "2022-12-08 10:33:20,532 epoch 61 - iter 20/25 - loss 0.20860861 - samples/sec: 47.62 - lr: 0.000391\n",
            "2022-12-08 10:33:23,778 epoch 61 - iter 22/25 - loss 0.20331216 - samples/sec: 19.72 - lr: 0.000391\n",
            "2022-12-08 10:33:25,160 epoch 61 - iter 24/25 - loss 0.20171043 - samples/sec: 46.36 - lr: 0.000391\n",
            "2022-12-08 10:33:25,247 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:33:25,248 EPOCH 61 done: loss 0.2021 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  4.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:33:26,185 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:33:26,194 DEV : loss 0.2916070818901062 - f1-score (micro avg)  0.6742\n",
            "2022-12-08 10:33:26,204 Epoch    61: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2022-12-08 10:33:26,205 BAD EPOCHS (no improvement): 4\n",
            "2022-12-08 10:33:26,206 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:33:29,529 epoch 62 - iter 2/25 - loss 0.20241119 - samples/sec: 19.26 - lr: 0.000195\n",
            "2022-12-08 10:33:31,063 epoch 62 - iter 4/25 - loss 0.21041818 - samples/sec: 41.76 - lr: 0.000195\n",
            "2022-12-08 10:33:32,296 epoch 62 - iter 6/25 - loss 0.22814513 - samples/sec: 51.95 - lr: 0.000195\n",
            "2022-12-08 10:33:33,453 epoch 62 - iter 8/25 - loss 0.21916750 - samples/sec: 55.39 - lr: 0.000195\n",
            "2022-12-08 10:33:35,170 epoch 62 - iter 10/25 - loss 0.20847340 - samples/sec: 37.30 - lr: 0.000195\n",
            "2022-12-08 10:33:36,797 epoch 62 - iter 12/25 - loss 0.21012415 - samples/sec: 39.38 - lr: 0.000195\n",
            "2022-12-08 10:33:37,755 epoch 62 - iter 14/25 - loss 0.20445101 - samples/sec: 66.91 - lr: 0.000195\n",
            "2022-12-08 10:33:39,184 epoch 62 - iter 16/25 - loss 0.20927666 - samples/sec: 44.81 - lr: 0.000195\n",
            "2022-12-08 10:33:40,596 epoch 62 - iter 18/25 - loss 0.21089552 - samples/sec: 45.37 - lr: 0.000195\n",
            "2022-12-08 10:33:41,834 epoch 62 - iter 20/25 - loss 0.20744261 - samples/sec: 51.74 - lr: 0.000195\n",
            "2022-12-08 10:33:43,109 epoch 62 - iter 22/25 - loss 0.20580334 - samples/sec: 50.26 - lr: 0.000195\n",
            "2022-12-08 10:33:44,515 epoch 62 - iter 24/25 - loss 0.20593947 - samples/sec: 45.56 - lr: 0.000195\n",
            "2022-12-08 10:33:44,626 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:33:44,627 EPOCH 62 done: loss 0.2061 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:33:45,386 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:33:45,397 DEV : loss 0.29170531034469604 - f1-score (micro avg)  0.6742\n",
            "2022-12-08 10:33:45,407 BAD EPOCHS (no improvement): 1\n",
            "2022-12-08 10:33:45,408 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:33:46,383 epoch 63 - iter 2/25 - loss 0.20137620 - samples/sec: 65.70 - lr: 0.000195\n",
            "2022-12-08 10:33:47,738 epoch 63 - iter 4/25 - loss 0.19035405 - samples/sec: 47.28 - lr: 0.000195\n",
            "2022-12-08 10:33:49,146 epoch 63 - iter 6/25 - loss 0.20308324 - samples/sec: 45.48 - lr: 0.000195\n",
            "2022-12-08 10:33:52,080 epoch 63 - iter 8/25 - loss 0.20761847 - samples/sec: 21.82 - lr: 0.000195\n",
            "2022-12-08 10:33:53,113 epoch 63 - iter 10/25 - loss 0.20954216 - samples/sec: 62.08 - lr: 0.000195\n",
            "2022-12-08 10:33:54,671 epoch 63 - iter 12/25 - loss 0.20850667 - samples/sec: 41.12 - lr: 0.000195\n",
            "2022-12-08 10:33:56,259 epoch 63 - iter 14/25 - loss 0.20783144 - samples/sec: 40.32 - lr: 0.000195\n",
            "2022-12-08 10:33:57,367 epoch 63 - iter 16/25 - loss 0.20490820 - samples/sec: 57.85 - lr: 0.000195\n",
            "2022-12-08 10:33:59,092 epoch 63 - iter 18/25 - loss 0.20158053 - samples/sec: 37.12 - lr: 0.000195\n",
            "2022-12-08 10:34:00,069 epoch 63 - iter 20/25 - loss 0.19971040 - samples/sec: 65.61 - lr: 0.000195\n",
            "2022-12-08 10:34:01,522 epoch 63 - iter 22/25 - loss 0.20119185 - samples/sec: 44.06 - lr: 0.000195\n",
            "2022-12-08 10:34:02,559 epoch 63 - iter 24/25 - loss 0.20137889 - samples/sec: 61.83 - lr: 0.000195\n",
            "2022-12-08 10:34:02,659 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:34:02,660 EPOCH 63 done: loss 0.2014 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:34:03,423 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:34:03,431 DEV : loss 0.29142987728118896 - f1-score (micro avg)  0.6742\n",
            "2022-12-08 10:34:03,441 BAD EPOCHS (no improvement): 2\n",
            "2022-12-08 10:34:03,442 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:34:04,932 epoch 64 - iter 2/25 - loss 0.13945054 - samples/sec: 43.00 - lr: 0.000195\n",
            "2022-12-08 10:34:06,546 epoch 64 - iter 4/25 - loss 0.18035741 - samples/sec: 39.68 - lr: 0.000195\n",
            "2022-12-08 10:34:09,287 epoch 64 - iter 6/25 - loss 0.17527649 - samples/sec: 23.36 - lr: 0.000195\n",
            "2022-12-08 10:34:10,518 epoch 64 - iter 8/25 - loss 0.18608038 - samples/sec: 52.06 - lr: 0.000195\n",
            "2022-12-08 10:34:12,240 epoch 64 - iter 10/25 - loss 0.18926045 - samples/sec: 37.20 - lr: 0.000195\n",
            "2022-12-08 10:34:13,689 epoch 64 - iter 12/25 - loss 0.20294486 - samples/sec: 44.20 - lr: 0.000195\n",
            "2022-12-08 10:34:14,930 epoch 64 - iter 14/25 - loss 0.20845057 - samples/sec: 51.60 - lr: 0.000195\n",
            "2022-12-08 10:34:16,223 epoch 64 - iter 16/25 - loss 0.20320586 - samples/sec: 49.57 - lr: 0.000195\n",
            "2022-12-08 10:34:17,493 epoch 64 - iter 18/25 - loss 0.19997768 - samples/sec: 50.44 - lr: 0.000195\n",
            "2022-12-08 10:34:18,983 epoch 64 - iter 20/25 - loss 0.20197360 - samples/sec: 42.98 - lr: 0.000195\n",
            "2022-12-08 10:34:20,244 epoch 64 - iter 22/25 - loss 0.20229040 - samples/sec: 50.79 - lr: 0.000195\n",
            "2022-12-08 10:34:21,597 epoch 64 - iter 24/25 - loss 0.20086200 - samples/sec: 47.35 - lr: 0.000195\n",
            "2022-12-08 10:34:21,694 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:34:21,695 EPOCH 64 done: loss 0.2009 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:34:22,451 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:34:22,459 DEV : loss 0.2916939854621887 - f1-score (micro avg)  0.6742\n",
            "2022-12-08 10:34:22,468 BAD EPOCHS (no improvement): 3\n",
            "2022-12-08 10:34:22,470 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:34:25,603 epoch 65 - iter 2/25 - loss 0.18851838 - samples/sec: 20.44 - lr: 0.000195\n",
            "2022-12-08 10:34:26,724 epoch 65 - iter 4/25 - loss 0.20992760 - samples/sec: 57.15 - lr: 0.000195\n",
            "2022-12-08 10:34:28,285 epoch 65 - iter 6/25 - loss 0.20342629 - samples/sec: 41.04 - lr: 0.000195\n",
            "2022-12-08 10:34:29,660 epoch 65 - iter 8/25 - loss 0.19739045 - samples/sec: 46.60 - lr: 0.000195\n",
            "2022-12-08 10:34:31,344 epoch 65 - iter 10/25 - loss 0.20461451 - samples/sec: 38.03 - lr: 0.000195\n",
            "2022-12-08 10:34:32,813 epoch 65 - iter 12/25 - loss 0.20175233 - samples/sec: 43.60 - lr: 0.000195\n",
            "2022-12-08 10:34:33,902 epoch 65 - iter 14/25 - loss 0.20147082 - samples/sec: 58.83 - lr: 0.000195\n",
            "2022-12-08 10:34:35,065 epoch 65 - iter 16/25 - loss 0.20424295 - samples/sec: 55.12 - lr: 0.000195\n",
            "2022-12-08 10:34:36,315 epoch 65 - iter 18/25 - loss 0.20043114 - samples/sec: 51.25 - lr: 0.000195\n",
            "2022-12-08 10:34:37,799 epoch 65 - iter 20/25 - loss 0.19856763 - samples/sec: 43.15 - lr: 0.000195\n",
            "2022-12-08 10:34:39,065 epoch 65 - iter 22/25 - loss 0.19665290 - samples/sec: 50.62 - lr: 0.000195\n",
            "2022-12-08 10:34:40,290 epoch 65 - iter 24/25 - loss 0.19680643 - samples/sec: 52.31 - lr: 0.000195\n",
            "2022-12-08 10:34:40,421 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:34:40,422 EPOCH 65 done: loss 0.1973 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  5.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:34:41,173 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:34:41,182 DEV : loss 0.29154881834983826 - f1-score (micro avg)  0.6742\n",
            "2022-12-08 10:34:41,193 Epoch    65: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2022-12-08 10:34:41,194 BAD EPOCHS (no improvement): 4\n",
            "2022-12-08 10:34:41,195 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:34:41,195 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:34:41,195 learning rate too small - quitting training!\n",
            "2022-12-08 10:34:41,196 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:34:41,846 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-08 10:34:41,847 loading file resources/taggers/re3d-ner/best-model.pt\n",
            "2022-12-08 10:34:42,448 SequenceTagger predicts: Dictionary with 43 tags: O, S-Organisation, B-Organisation, E-Organisation, I-Organisation, S-Location, B-Location, E-Location, I-Location, S-Person, B-Person, E-Person, I-Person, S-Temporal, B-Temporal, E-Temporal, I-Temporal, S-Quantity, B-Quantity, E-Quantity, I-Quantity, S-Weapon, B-Weapon, E-Weapon, I-Weapon, S-DocumentReference, B-DocumentReference, E-DocumentReference, I-DocumentReference, S-MilitaryPlatform, B-MilitaryPlatform, E-MilitaryPlatform, I-MilitaryPlatform, S-Nationality, B-Nationality, E-Nationality, I-Nationality, S-Money, B-Money, E-Money, I-Money, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:13<00:00,  4.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 10:34:56,107 Evaluating as a multi-label problem: False\n",
            "2022-12-08 10:34:56,113 0.6744\t0.7335\t0.7027\t0.5519\n",
            "2022-12-08 10:34:56,114 \n",
            "Results:\n",
            "- F-score (micro) 0.7027\n",
            "- F-score (macro) 0.4017\n",
            "- Accuracy 0.5519\n",
            "\n",
            "By class:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Organisation     0.6561    0.7357    0.6936       140\n",
            "         Location     0.6712    0.7206    0.6950        68\n",
            "           Person     0.7910    0.8548    0.8217        62\n",
            "         Temporal     0.9474    0.9474    0.9474        19\n",
            "         Quantity     0.4545    0.6250    0.5263        16\n",
            "           Weapon     0.0000    0.0000    0.0000         4\n",
            "DocumentReference     0.5000    0.2500    0.3333         4\n",
            "            Money     0.0000    0.0000    0.0000         1\n",
            "      Nationality     0.0000    0.0000    0.0000         2\n",
            " MilitaryPlatform     0.0000    0.0000    0.0000         3\n",
            "\n",
            "        micro avg     0.6744    0.7335    0.7027       319\n",
            "        macro avg     0.4020    0.4134    0.4017       319\n",
            "     weighted avg     0.6702    0.7335    0.6993       319\n",
            "\n",
            "2022-12-08 10:34:56,115 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_score': 0.7027027027027027,\n",
              " 'dev_score_history': [0.0,\n",
              "  0.10352941176470588,\n",
              "  0.2033271719038817,\n",
              "  0.3082437275985663,\n",
              "  0.3926940639269407,\n",
              "  0.5240174672489083,\n",
              "  0.5384615384615385,\n",
              "  0.5873715124816447,\n",
              "  0.5794655414908579,\n",
              "  0.6298507462686567,\n",
              "  0.6127527216174184,\n",
              "  0.6171428571428571,\n",
              "  0.6490455212922173,\n",
              "  0.6500000000000001,\n",
              "  0.6296809986130374,\n",
              "  0.64756446991404,\n",
              "  0.6568483063328424,\n",
              "  0.6334716459197788,\n",
              "  0.6452554744525547,\n",
              "  0.6666666666666666,\n",
              "  0.6273458445040215,\n",
              "  0.6820276497695852,\n",
              "  0.6277173913043478,\n",
              "  0.6785185185185185,\n",
              "  0.6666666666666667,\n",
              "  0.663768115942029,\n",
              "  0.674863387978142,\n",
              "  0.6805970149253732,\n",
              "  0.6806136680613668,\n",
              "  0.6737967914438503,\n",
              "  0.662937062937063,\n",
              "  0.6827880512091038,\n",
              "  0.7075606276747504,\n",
              "  0.6853932584269663,\n",
              "  0.6914285714285714,\n",
              "  0.6749654218533887,\n",
              "  0.6733238231098431,\n",
              "  0.6835443037974684,\n",
              "  0.6751054852320675,\n",
              "  0.6816901408450704,\n",
              "  0.6779661016949153,\n",
              "  0.6797752808988764,\n",
              "  0.6779184247538679,\n",
              "  0.6704225352112676,\n",
              "  0.669432918395574,\n",
              "  0.6722454672245467,\n",
              "  0.680672268907563,\n",
              "  0.6797752808988764,\n",
              "  0.6750348675034867,\n",
              "  0.6777777777777778,\n",
              "  0.6732117812061712,\n",
              "  0.676923076923077,\n",
              "  0.6741258741258742,\n",
              "  0.6741258741258742,\n",
              "  0.6741573033707865,\n",
              "  0.6741258741258742,\n",
              "  0.6751054852320675,\n",
              "  0.6741573033707865,\n",
              "  0.6741573033707865,\n",
              "  0.6741573033707865,\n",
              "  0.6741573033707865,\n",
              "  0.6741573033707865,\n",
              "  0.6741573033707865,\n",
              "  0.6741573033707865,\n",
              "  0.6741573033707865],\n",
              " 'train_loss_history': [1.9991526563596664,\n",
              "  1.5554193511990067,\n",
              "  1.282428986407935,\n",
              "  1.047680492557757,\n",
              "  0.8778229122099589,\n",
              "  0.7856393528937633,\n",
              "  0.6990808396543701,\n",
              "  0.643320505020113,\n",
              "  0.5956248835096305,\n",
              "  0.5564526929409034,\n",
              "  0.5366495369661806,\n",
              "  0.48684487966067763,\n",
              "  0.4651850172635225,\n",
              "  0.4449211151554828,\n",
              "  0.42738757761435064,\n",
              "  0.40868200972253144,\n",
              "  0.38689305679232217,\n",
              "  0.37518120623488826,\n",
              "  0.3617481002588707,\n",
              "  0.3475415984754146,\n",
              "  0.3318887787755972,\n",
              "  0.32606734618053623,\n",
              "  0.3216368638526748,\n",
              "  0.30824641288771665,\n",
              "  0.2952778439641152,\n",
              "  0.2949705273930274,\n",
              "  0.26797421641173813,\n",
              "  0.2579648704902465,\n",
              "  0.2532620609744291,\n",
              "  0.24042929255597914,\n",
              "  0.2381283269504582,\n",
              "  0.2356679615757875,\n",
              "  0.22854989273465326,\n",
              "  0.2198584611212758,\n",
              "  0.21868715015447987,\n",
              "  0.2230665524517545,\n",
              "  0.2151961227995217,\n",
              "  0.21194563990496995,\n",
              "  0.21571680274481023,\n",
              "  0.20721635132500216,\n",
              "  0.2068636222304158,\n",
              "  0.21080875368421176,\n",
              "  0.20345969694097377,\n",
              "  0.20977672993210925,\n",
              "  0.20396385747694976,\n",
              "  0.20704701756633706,\n",
              "  0.1999052430256026,\n",
              "  0.20360436783448352,\n",
              "  0.20103615073595343,\n",
              "  0.20628483297563724,\n",
              "  0.1991044487315799,\n",
              "  0.20110032008099274,\n",
              "  0.20353476800915749,\n",
              "  0.20204340896161077,\n",
              "  0.19861902690044647,\n",
              "  0.20301259192654225,\n",
              "  0.20132584277913823,\n",
              "  0.20277258341845766,\n",
              "  0.20040192438466997,\n",
              "  0.20113110639014112,\n",
              "  0.20208569258035697,\n",
              "  0.20607047016358557,\n",
              "  0.20139185096904527,\n",
              "  0.20088861287495285,\n",
              "  0.1973099082493105],\n",
              " 'dev_loss_history': [1.4683295488357544,\n",
              "  1.1850744485855103,\n",
              "  0.9740524888038635,\n",
              "  0.773407518863678,\n",
              "  0.7003260254859924,\n",
              "  0.6193915009498596,\n",
              "  0.5624843239784241,\n",
              "  0.5259146690368652,\n",
              "  0.5068708062171936,\n",
              "  0.457415372133255,\n",
              "  0.44067618250846863,\n",
              "  0.44053924083709717,\n",
              "  0.39791473746299744,\n",
              "  0.39402130246162415,\n",
              "  0.410897821187973,\n",
              "  0.3874638080596924,\n",
              "  0.3701637089252472,\n",
              "  0.366158127784729,\n",
              "  0.3435453474521637,\n",
              "  0.35169848799705505,\n",
              "  0.3639715611934662,\n",
              "  0.3197213113307953,\n",
              "  0.39436376094818115,\n",
              "  0.309669554233551,\n",
              "  0.30700013041496277,\n",
              "  0.32519131898880005,\n",
              "  0.3340665102005005,\n",
              "  0.2929023206233978,\n",
              "  0.3028087615966797,\n",
              "  0.3168567419052124,\n",
              "  0.2997512221336365,\n",
              "  0.29447850584983826,\n",
              "  0.2914526164531708,\n",
              "  0.3013288378715515,\n",
              "  0.29402536153793335,\n",
              "  0.3000977337360382,\n",
              "  0.28405314683914185,\n",
              "  0.29184046387672424,\n",
              "  0.292938768863678,\n",
              "  0.2921699285507202,\n",
              "  0.28613659739494324,\n",
              "  0.2914345860481262,\n",
              "  0.290463924407959,\n",
              "  0.2919396162033081,\n",
              "  0.2971685230731964,\n",
              "  0.2950187623500824,\n",
              "  0.2933584749698639,\n",
              "  0.29252463579177856,\n",
              "  0.29397445917129517,\n",
              "  0.29537585377693176,\n",
              "  0.29333987832069397,\n",
              "  0.29332539439201355,\n",
              "  0.2931651473045349,\n",
              "  0.2931874990463257,\n",
              "  0.29278016090393066,\n",
              "  0.29318180680274963,\n",
              "  0.2916466295719147,\n",
              "  0.2919526696205139,\n",
              "  0.29184234142303467,\n",
              "  0.29172247648239136,\n",
              "  0.2916070818901062,\n",
              "  0.29170531034469604,\n",
              "  0.29142987728118896,\n",
              "  0.2916939854621887,\n",
              "  0.29154881834983826]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from flair.models import SequenceTagger\n",
        "\n",
        "# initialize a BiLSTM-CRF sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                                       embeddings=embeddings,\n",
        "                                       tag_dictionary=tag_dictionary,\n",
        "                                       tag_type=tag_type,\n",
        "                                       use_crf=True)\n",
        "print(tagger)\n",
        "\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# start training\n",
        "trainer.train('resources/taggers/re3d-ner',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-08 11:35:14,711 loading file resources/taggers/re3d-ner/best-model.pt\n",
            "2022-12-08 11:35:15,643 SequenceTagger predicts: Dictionary with 43 tags: O, S-Organisation, B-Organisation, E-Organisation, I-Organisation, S-Location, B-Location, E-Location, I-Location, S-Person, B-Person, E-Person, I-Person, S-Temporal, B-Temporal, E-Temporal, I-Temporal, S-Quantity, B-Quantity, E-Quantity, I-Quantity, S-Weapon, B-Weapon, E-Weapon, I-Weapon, S-DocumentReference, B-DocumentReference, E-DocumentReference, I-DocumentReference, S-MilitaryPlatform, B-MilitaryPlatform, E-MilitaryPlatform, I-MilitaryPlatform, S-Nationality, B-Nationality, E-Nationality, I-Nationality, S-Money, B-Money, E-Money, I-Money, <START>, <STOP>\n",
            "Sentence: \"Ammonium nitrate was also used in the IRA 's bombing of London 's Canary Wharf in 1996 .\" → [\"IRA\"/Organisation, \"London 's Canary Wharf\"/Location, \"1996\"/Temporal]\n"
          ]
        }
      ],
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "input_sentence = 'My name is Clara, I live in Singapore, I work for DSTA.'\n",
        "input_sentence = 'Missiles and other explosives or ammonium nitrate are dangerous.'\n",
        "input_sentence = 'Ammonium nitrate was also used in the IRA\\'s bombing of London\\'s Canary Wharf in 1996.'\n",
        "#input_sentence = 'These have included such naval craft as the ship of the line, battleship, submarine, and aircraft carrier; aircraft such as the fighter, bomber, and helicopter; and ground vehicles such as the chariot and tank.'\n",
        "tagger: SequenceTagger = SequenceTagger.load(\"resources/taggers/re3d-ner/best-model.pt\")\n",
        "sentence: Sentence = Sentence(input_sentence)\n",
        "tagger.predict(sentence)\n",
        "print(sentence.to_tagged_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## On general (docred) data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:16:58,545 Reading data from docred_preprocessed\n",
            "2022-12-09 11:16:58,547 Train: docred_preprocessed/train.txt\n",
            "2022-12-09 11:16:58,549 Dev: docred_preprocessed/dev.txt\n",
            "2022-12-09 11:16:58,549 Test: docred_preprocessed/test.txt\n"
          ]
        }
      ],
      "source": [
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = 'docred_preprocessed'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')\n",
        "\n",
        "downsampled_corpus = corpus.downsample(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"Del ia ĠBuckley ĠGallagher Ġ( Ġborn Ġ11 ĠMarch Ġ1970 Ġ) Ġis Ġan ĠAmerican Ġjournalist Ġbased Ġin ĠRome Ġwho Ġcurrently Ġserves Ġas Ġthe ĠSenior ĠEditor Ġfor ĠInside Ġthe ĠVatican Ġmagazine Ġ. She Ġformerly Ġserved Ġas ĠCNN ĠâĢ Ļ s ĠFaith Ġand ĠValues ĠCorrespond ent Ġ. Based Ġin ĠNew ĠYork Ġ, ĠGallagher Ġwas Ġa Ġlong Ġtime ĠCNN ĠVatican ĠAnalyst Ġ, ĠVatican ologist Ġ, Ġand Ġreligious Ġjournalist Ġ. Prior Ġto Ġjoining ĠCNN Ġfull Ġtime Ġ, Ġshe Ġlived Ġin ĠRome Ġfor Ġ7 Ġyears Ġ. In ĠRome Ġ, Ġshe Ġwrote Ġa Ġweekly Ġcolumn Ġfor ĠZen it ĠNews ĠAgency Ġand Ġwas Ġa Ġcontributing Ġeditor Ġfor Ġthe Ġmagazine Ġ. The ĠHistory ĠChannel ĠDocument ary Ġ, Ġ\" ĠAngels Ġand ĠDemons ĠDec oded Ġ\" Ġreleased Ġby ĠA Ġ& ĠE ĠTelevision ĠNetworks Ġprof iled ĠGallagher Ġcommenting Ġon ĠDan ĠBrown Ġ' s Ġbest seller Ġbook Ġwhich Ġwas Ġmade Ġinto Ġa Ġmovie Ġ. Sub sequently Ġ, ĠGallagher Ġmoder ated Ġthe ĠAngels Ġand ĠDemons Ġmovie Ġpress Ġconference Ġfilm Ġdebut Ġin ĠRome Ġon Ġstage Ġwith ĠTom ĠH anks Ġ, ĠRon ĠHoward Ġand ĠDan ĠBrown Ġoften Ġspeaking Ġin ĠItalian Ġand ĠEnglish Ġ. She Ġknows ĠPope ĠBenedict ĠXVI Ġpersonally Ġand Ġtravelled Ġextensively Ġwith ĠJohn ĠPaul ĠII Ġ, Ġincluding Ġhis Ġlast Ġtrip Ġto ĠPoland Ġ. Upon Ġthe Ġdeath Ġof ĠPope ĠJohn ĠPaul ĠII Ġ, Ġshe Ġbroadcast Ġand Ġcommented Ġfor ĠCNN ĠWorldwide Ġcovering Ġthe Ġunfolding Ġevent Ġ.\" → [\"Del ia ĠBuckley ĠGallagher\"/PER, \"Ġ11 ĠMarch Ġ1970\"/TIME, \"ĠCNN\"/ORG, \"ĠAngels Ġand ĠDemons ĠDec oded\"/MISC, \"ĠTom ĠH anks\"/PER, \"ĠDan ĠBrown\"/PER, \"ĠCNN ĠWorldwide\"/ORG]\n",
            "301\n"
          ]
        }
      ],
      "source": [
        "print(downsampled_corpus.train[0].to_tagged_string('ner'))\n",
        "print(len(downsampled_corpus.train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 10:56:58,844 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3008it [00:00, 25790.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 10:56:59,000 Dictionary created for label 'ner' with 7 values: LOC (seen 10903 times), PER (seen 5336 times), MISC (seen 4419 times), ORG (seen 4334 times), TIME (seen 3340 times), NUM (seen 8 times)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Define tags to predict\n",
        "tag_type = 'ner'# make tag dictionary from the corpus\n",
        "tag_dictionary = downsampled_corpus.make_label_dictionary(label_type=tag_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Embeddings\n",
        "\n",
        "from typing import List\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_types = [\n",
        "    # init standard GloVe embedding\n",
        "    WordEmbeddings('glove'),\n",
        "\n",
        "    # init Flair forward and backwards embeddings\n",
        "    FlairEmbeddings('news-forward'),\n",
        "    FlairEmbeddings('news-backward'),\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:18:12,896 SequenceTagger predicts: Dictionary with 25 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, S-TIME, B-TIME, E-TIME, I-TIME, S-NUM, B-NUM, E-NUM, I-NUM\n",
            "SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
            "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=27, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\n",
            "2022-12-09 11:18:13,012 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:18:13,012 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
            "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=27, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-12-09 11:18:13,013 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:18:13,014 Corpus: \"Corpus: 301 train + 30 dev + 70 test sentences\"\n",
            "2022-12-09 11:18:13,015 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:18:13,016 Parameters:\n",
            "2022-12-09 11:18:13,016  - learning_rate: \"0.100000\"\n",
            "2022-12-09 11:18:13,017  - mini_batch_size: \"64\"\n",
            "2022-12-09 11:18:13,017  - patience: \"3\"\n",
            "2022-12-09 11:18:13,018  - anneal_factor: \"0.5\"\n",
            "2022-12-09 11:18:13,018  - max_epochs: \"150\"\n",
            "2022-12-09 11:18:13,018  - shuffle: \"True\"\n",
            "2022-12-09 11:18:13,019  - train_with_dev: \"False\"\n",
            "2022-12-09 11:18:13,020  - batch_growth_annealing: \"False\"\n",
            "2022-12-09 11:18:13,020 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:18:13,021 Model training base path: \"resources/taggers/docred-ner\"\n",
            "2022-12-09 11:18:13,022 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:18:13,023 Device: cpu\n",
            "2022-12-09 11:18:13,023 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:18:13,023 Embeddings storage mode: cpu\n",
            "2022-12-09 11:18:13,024 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:19:21,612 epoch 1 - iter 1/5 - loss 3.56210742 - samples/sec: 0.93 - lr: 0.100000\n",
            "2022-12-09 11:20:41,340 epoch 1 - iter 2/5 - loss 2.96705841 - samples/sec: 0.80 - lr: 0.100000\n",
            "2022-12-09 11:21:58,301 epoch 1 - iter 3/5 - loss 2.38906567 - samples/sec: 0.83 - lr: 0.100000\n",
            "2022-12-09 11:23:08,269 epoch 1 - iter 4/5 - loss 2.01742559 - samples/sec: 0.91 - lr: 0.100000\n",
            "2022-12-09 11:24:21,215 epoch 1 - iter 5/5 - loss 1.87108151 - samples/sec: 0.88 - lr: 0.100000\n",
            "2022-12-09 11:24:21,216 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:24:21,217 EPOCH 1 done: loss 1.8711 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:29<00:00, 29.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:24:50,576 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:24:50,581 DEV : loss 0.9319246411323547 - f1-score (micro avg)  0.0\n",
            "2022-12-09 11:24:50,600 BAD EPOCHS (no improvement): 0\n",
            "2022-12-09 11:24:50,601 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:25:20,274 epoch 2 - iter 1/5 - loss 0.90134813 - samples/sec: 2.16 - lr: 0.100000\n",
            "2022-12-09 11:25:48,091 epoch 2 - iter 2/5 - loss 0.93840038 - samples/sec: 2.30 - lr: 0.100000\n",
            "2022-12-09 11:26:19,322 epoch 2 - iter 3/5 - loss 0.91924218 - samples/sec: 2.05 - lr: 0.100000\n",
            "2022-12-09 11:26:45,252 epoch 2 - iter 4/5 - loss 0.93913768 - samples/sec: 2.47 - lr: 0.100000\n",
            "2022-12-09 11:27:10,925 epoch 2 - iter 5/5 - loss 0.93488603 - samples/sec: 2.49 - lr: 0.100000\n",
            "2022-12-09 11:27:10,926 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:27:10,926 EPOCH 2 done: loss 0.9349 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:27:12,570 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:27:12,576 DEV : loss 0.8952202200889587 - f1-score (micro avg)  0.0\n",
            "2022-12-09 11:27:12,610 BAD EPOCHS (no improvement): 0\n",
            "2022-12-09 11:27:12,612 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:27:51,803 epoch 3 - iter 1/5 - loss 0.93787773 - samples/sec: 1.63 - lr: 0.100000\n",
            "2022-12-09 11:28:17,708 epoch 3 - iter 2/5 - loss 0.87763922 - samples/sec: 2.47 - lr: 0.100000\n",
            "2022-12-09 11:28:48,144 epoch 3 - iter 3/5 - loss 0.87597248 - samples/sec: 2.10 - lr: 0.100000\n",
            "2022-12-09 11:29:24,463 epoch 3 - iter 4/5 - loss 0.87139243 - samples/sec: 1.76 - lr: 0.100000\n",
            "2022-12-09 11:29:49,401 epoch 3 - iter 5/5 - loss 0.88037029 - samples/sec: 2.57 - lr: 0.100000\n",
            "2022-12-09 11:29:49,403 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:29:49,403 EPOCH 3 done: loss 0.8804 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:29:51,446 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:29:51,455 DEV : loss 0.8871385455131531 - f1-score (micro avg)  0.0\n",
            "2022-12-09 11:29:51,505 BAD EPOCHS (no improvement): 0\n",
            "2022-12-09 11:29:51,506 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:30:33,282 epoch 4 - iter 1/5 - loss 0.84545739 - samples/sec: 1.53 - lr: 0.100000\n",
            "2022-12-09 11:31:07,296 epoch 4 - iter 2/5 - loss 0.85193636 - samples/sec: 1.88 - lr: 0.100000\n",
            "2022-12-09 11:31:39,928 epoch 4 - iter 3/5 - loss 0.85269189 - samples/sec: 1.96 - lr: 0.100000\n",
            "2022-12-09 11:32:14,196 epoch 4 - iter 4/5 - loss 0.83863095 - samples/sec: 1.87 - lr: 0.100000\n",
            "2022-12-09 11:32:33,063 epoch 4 - iter 5/5 - loss 0.83809332 - samples/sec: 3.39 - lr: 0.100000\n",
            "2022-12-09 11:32:33,065 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:32:33,066 EPOCH 4 done: loss 0.8381 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:32:35,037 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:32:35,046 DEV : loss 0.7917019724845886 - f1-score (micro avg)  0.0\n",
            "2022-12-09 11:32:35,079 BAD EPOCHS (no improvement): 0\n",
            "2022-12-09 11:32:35,080 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:33:01,560 epoch 5 - iter 1/5 - loss 0.83295365 - samples/sec: 2.42 - lr: 0.100000\n",
            "2022-12-09 11:33:34,764 epoch 5 - iter 2/5 - loss 0.82610632 - samples/sec: 1.93 - lr: 0.100000\n",
            "2022-12-09 11:34:09,123 epoch 5 - iter 3/5 - loss 0.82558673 - samples/sec: 1.86 - lr: 0.100000\n",
            "2022-12-09 11:34:50,750 epoch 5 - iter 4/5 - loss 0.81371176 - samples/sec: 1.54 - lr: 0.100000\n",
            "2022-12-09 11:35:08,915 epoch 5 - iter 5/5 - loss 0.80057598 - samples/sec: 3.52 - lr: 0.100000\n",
            "2022-12-09 11:35:08,916 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:35:08,917 EPOCH 5 done: loss 0.8006 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:35:11,142 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:35:11,151 DEV : loss 0.8529025316238403 - f1-score (micro avg)  0.0\n",
            "2022-12-09 11:35:11,187 BAD EPOCHS (no improvement): 1\n",
            "2022-12-09 11:35:11,188 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:35:44,379 epoch 6 - iter 1/5 - loss 0.77767155 - samples/sec: 1.93 - lr: 0.100000\n",
            "2022-12-09 11:36:19,566 epoch 6 - iter 2/5 - loss 0.77038829 - samples/sec: 1.82 - lr: 0.100000\n",
            "2022-12-09 11:36:58,086 epoch 6 - iter 3/5 - loss 0.79013852 - samples/sec: 1.66 - lr: 0.100000\n",
            "2022-12-09 11:37:28,000 epoch 6 - iter 4/5 - loss 0.79034168 - samples/sec: 2.14 - lr: 0.100000\n",
            "2022-12-09 11:49:35,057 epoch 6 - iter 5/5 - loss 0.78124586 - samples/sec: 0.09 - lr: 0.100000\n",
            "2022-12-09 11:49:35,062 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:49:35,062 EPOCH 6 done: loss 0.7812 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:49:36,713 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:49:36,727 DEV : loss 0.7337616086006165 - f1-score (micro avg)  0.0\n",
            "2022-12-09 11:49:36,749 BAD EPOCHS (no improvement): 0\n",
            "2022-12-09 11:49:36,750 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:50:04,201 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:50:04,202 Exiting from training early.\n",
            "2022-12-09 11:50:04,203 Saving model ...\n",
            "2022-12-09 11:50:05,187 Done.\n",
            "2022-12-09 11:50:05,188 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:50:05,188 Testing using last state of model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [01:00<00:00, 30.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:51:05,250 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:51:05,263 0.0\t0.0\t0.0\t0.0\n",
            "2022-12-09 11:51:05,264 \n",
            "Results:\n",
            "- F-score (micro) 0.0\n",
            "- F-score (macro) 0.0\n",
            "- Accuracy 0.0\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.0000    0.0000    0.0000     345.0\n",
            "         ORG     0.0000    0.0000    0.0000     112.0\n",
            "         PER     0.0000    0.0000    0.0000     106.0\n",
            "        MISC     0.0000    0.0000    0.0000      75.0\n",
            "        TIME     0.0000    0.0000    0.0000      65.0\n",
            "\n",
            "   micro avg     0.0000    0.0000    0.0000     703.0\n",
            "   macro avg     0.0000    0.0000    0.0000     703.0\n",
            "weighted avg     0.0000    0.0000    0.0000     703.0\n",
            "\n",
            "2022-12-09 11:51:05,265 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_score': 0.0,\n",
              " 'dev_score_history': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'train_loss_history': [1.8710815052353171,\n",
              "  0.934886026183842,\n",
              "  0.880370293021754,\n",
              "  0.8380933155376087,\n",
              "  0.8005759801253864,\n",
              "  0.781245861723047],\n",
              " 'dev_loss_history': [0.9319246411323547,\n",
              "  0.8952202200889587,\n",
              "  0.8871385455131531,\n",
              "  0.7917019724845886,\n",
              "  0.8529025316238403,\n",
              "  0.7337616086006165]}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from flair.models import SequenceTagger\n",
        "\n",
        "# initialize a BiLSTM-CRF sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                                       embeddings=embeddings,\n",
        "                                       tag_dictionary=tag_dictionary,\n",
        "                                       tag_type=tag_type,\n",
        "                                       use_crf=True)\n",
        "print(tagger)\n",
        "\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# initialize trainer\n",
        "trainer = ModelTrainer(tagger, downsampled_corpus)\n",
        "\n",
        "# start training\n",
        "trainer.train('resources/taggers/docred-ner',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=64,\n",
        "              max_epochs=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stacked (Word + Character)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orqxebPu3cBh"
      },
      "source": [
        "## On domain-specific (re3d) data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:26:11,206 Reading data from entity-recognition-datasets-master/data/re3d/CONLL-format/data/splits\n",
            "2022-12-12 11:26:11,207 Train: entity-recognition-datasets-master/data/re3d/CONLL-format/data/splits/train.conll\n",
            "2022-12-12 11:26:11,208 Dev: entity-recognition-datasets-master/data/re3d/CONLL-format/data/splits/val.conll\n",
            "2022-12-12 11:26:11,208 Test: entity-recognition-datasets-master/data/re3d/CONLL-format/data/splits/test.conll\n"
          ]
        }
      ],
      "source": [
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = 'entity-recognition-datasets-master/data/re3d/CONLL-format/data/splits'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.conll',\n",
        "                              test_file='test.conll',\n",
        "                              dev_file='val.conll')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:26:15,652 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "771it [00:00, 49790.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:26:15,673 Dictionary created for label 'ner' with 11 values: Organisation (seen 1113 times), Location (seen 647 times), Person (seen 415 times), Temporal (seen 179 times), Quantity (seen 151 times), Weapon (seen 81 times), DocumentReference (seen 50 times), MilitaryPlatform (seen 48 times), Nationality (seen 34 times), Money (seen 20 times)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Define tags to predict\n",
        "tag_type = 'ner'# make tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_label_dictionary(label_type=tag_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Embeddings\n",
        "\n",
        "from typing import List\n",
        "from flair import embeddings\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings, CharacterEmbeddings, ELMoEmbeddings, ELMoTransformerEmbeddings, DocumentEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:26:26,839 https://flair.informatik.hu-berlin.de/resources/characters/common_characters not found in cache, downloading to /tmp/tmp22vpeed7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2887/2887 [00:00<00:00, 2234949.36B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:26:27,966 copying /tmp/tmp22vpeed7 to cache at /home/digitalhub/.flair/datasets/common_characters\n",
            "2022-12-12 11:26:27,967 removing temp file /tmp/tmp22vpeed7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "embedding_types = [\n",
        "    # init standard GloVe embedding\n",
        "    WordEmbeddings('glove'),\n",
        "\n",
        "    # init Flair forward and backwards embeddings\n",
        "    CharacterEmbeddings()\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:26:29,714 SequenceTagger predicts: Dictionary with 41 tags: O, S-Organisation, B-Organisation, E-Organisation, I-Organisation, S-Location, B-Location, E-Location, I-Location, S-Person, B-Person, E-Person, I-Person, S-Temporal, B-Temporal, E-Temporal, I-Temporal, S-Quantity, B-Quantity, E-Quantity, I-Quantity, S-Weapon, B-Weapon, E-Weapon, I-Weapon, S-DocumentReference, B-DocumentReference, E-DocumentReference, I-DocumentReference, S-MilitaryPlatform, B-MilitaryPlatform, E-MilitaryPlatform, I-MilitaryPlatform, S-Nationality, B-Nationality, E-Nationality, I-Nationality, S-Money, B-Money, E-Money, I-Money\n",
            "SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): CharacterEmbeddings(\n",
            "      (char_embedding): Embedding(275, 25)\n",
            "      (char_rnn): LSTM(25, 25, bidirectional=True)\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=150, out_features=150, bias=True)\n",
            "  (rnn): LSTM(150, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=43, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\n",
            "2022-12-12 11:26:29,730 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:26:29,731 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): CharacterEmbeddings(\n",
            "      (char_embedding): Embedding(275, 25)\n",
            "      (char_rnn): LSTM(25, 25, bidirectional=True)\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=150, out_features=150, bias=True)\n",
            "  (rnn): LSTM(150, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=43, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-12-12 11:26:29,731 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:26:29,732 Corpus: \"Corpus: 771 train + 98 dev + 96 test sentences\"\n",
            "2022-12-12 11:26:29,732 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:26:29,733 Parameters:\n",
            "2022-12-12 11:26:29,733  - learning_rate: \"0.100000\"\n",
            "2022-12-12 11:26:29,733  - mini_batch_size: \"32\"\n",
            "2022-12-12 11:26:29,734  - patience: \"3\"\n",
            "2022-12-12 11:26:29,734  - anneal_factor: \"0.5\"\n",
            "2022-12-12 11:26:29,735  - max_epochs: \"150\"\n",
            "2022-12-12 11:26:29,736  - shuffle: \"True\"\n",
            "2022-12-12 11:26:29,736  - train_with_dev: \"False\"\n",
            "2022-12-12 11:26:29,737  - batch_growth_annealing: \"False\"\n",
            "2022-12-12 11:26:29,737 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:26:29,737 Model training base path: \"resources/taggers/re3d-ner\"\n",
            "2022-12-12 11:26:29,738 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:26:29,738 Device: cpu\n",
            "2022-12-12 11:26:29,738 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:26:29,739 Embeddings storage mode: cpu\n",
            "2022-12-12 11:26:29,739 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/digitalhub/.pyenv/versions/3.8.12/lib/python3.8/site-packages/flair/trainers/trainer.py:64: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:26:30,617 epoch 1 - iter 2/25 - loss 3.21932688 - samples/sec: 72.98 - lr: 0.100000\n",
            "2022-12-12 11:26:31,638 epoch 1 - iter 4/25 - loss 2.70893033 - samples/sec: 62.78 - lr: 0.100000\n",
            "2022-12-12 11:26:32,660 epoch 1 - iter 6/25 - loss 2.40723167 - samples/sec: 62.74 - lr: 0.100000\n",
            "2022-12-12 11:26:33,748 epoch 1 - iter 8/25 - loss 2.19683027 - samples/sec: 58.89 - lr: 0.100000\n",
            "2022-12-12 11:26:34,642 epoch 1 - iter 10/25 - loss 2.09225777 - samples/sec: 71.65 - lr: 0.100000\n",
            "2022-12-12 11:26:35,581 epoch 1 - iter 12/25 - loss 2.00498739 - samples/sec: 68.26 - lr: 0.100000\n",
            "2022-12-12 11:26:38,066 epoch 1 - iter 14/25 - loss 1.99741056 - samples/sec: 25.77 - lr: 0.100000\n",
            "2022-12-12 11:26:39,296 epoch 1 - iter 16/25 - loss 1.92919313 - samples/sec: 52.10 - lr: 0.100000\n",
            "2022-12-12 11:26:40,217 epoch 1 - iter 18/25 - loss 1.90051307 - samples/sec: 69.58 - lr: 0.100000\n",
            "2022-12-12 11:26:41,362 epoch 1 - iter 20/25 - loss 1.90873228 - samples/sec: 55.97 - lr: 0.100000\n",
            "2022-12-12 11:26:42,655 epoch 1 - iter 22/25 - loss 1.89321590 - samples/sec: 49.55 - lr: 0.100000\n",
            "2022-12-12 11:26:43,719 epoch 1 - iter 24/25 - loss 1.88876852 - samples/sec: 60.22 - lr: 0.100000\n",
            "2022-12-12 11:26:43,791 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:26:43,792 EPOCH 1 done: loss 1.8870 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:26:44,284 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:26:44,296 DEV : loss 1.450675368309021 - f1-score (micro avg)  0.0\n",
            "2022-12-12 11:26:44,304 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:26:44,305 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:26:45,635 epoch 2 - iter 2/25 - loss 1.51519415 - samples/sec: 48.18 - lr: 0.100000\n",
            "2022-12-12 11:26:46,523 epoch 2 - iter 4/25 - loss 1.57102817 - samples/sec: 72.20 - lr: 0.100000\n",
            "2022-12-12 11:26:47,434 epoch 2 - iter 6/25 - loss 1.61182591 - samples/sec: 70.33 - lr: 0.100000\n",
            "2022-12-12 11:26:48,481 epoch 2 - iter 8/25 - loss 1.64265891 - samples/sec: 61.24 - lr: 0.100000\n",
            "2022-12-12 11:26:49,378 epoch 2 - iter 10/25 - loss 1.62115468 - samples/sec: 71.47 - lr: 0.100000\n",
            "2022-12-12 11:26:50,670 epoch 2 - iter 12/25 - loss 1.62759253 - samples/sec: 49.55 - lr: 0.100000\n",
            "2022-12-12 11:26:51,644 epoch 2 - iter 14/25 - loss 1.63627362 - samples/sec: 65.82 - lr: 0.100000\n",
            "2022-12-12 11:26:52,559 epoch 2 - iter 16/25 - loss 1.61450134 - samples/sec: 70.07 - lr: 0.100000\n",
            "2022-12-12 11:26:55,147 epoch 2 - iter 18/25 - loss 1.58326992 - samples/sec: 24.74 - lr: 0.100000\n",
            "2022-12-12 11:26:55,898 epoch 2 - iter 20/25 - loss 1.58309377 - samples/sec: 85.39 - lr: 0.100000\n",
            "2022-12-12 11:26:56,771 epoch 2 - iter 22/25 - loss 1.58725284 - samples/sec: 73.47 - lr: 0.100000\n",
            "2022-12-12 11:26:57,714 epoch 2 - iter 24/25 - loss 1.56219111 - samples/sec: 67.98 - lr: 0.100000\n",
            "2022-12-12 11:26:57,770 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:26:57,771 EPOCH 2 done: loss 1.5632 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:26:58,217 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:26:58,225 DEV : loss 1.3440138101577759 - f1-score (micro avg)  0.0\n",
            "2022-12-12 11:26:58,234 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:26:58,236 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:26:59,499 epoch 3 - iter 2/25 - loss 1.41557930 - samples/sec: 50.78 - lr: 0.100000\n",
            "2022-12-12 11:27:00,654 epoch 3 - iter 4/25 - loss 1.49949505 - samples/sec: 55.45 - lr: 0.100000\n",
            "2022-12-12 11:27:01,538 epoch 3 - iter 6/25 - loss 1.41454264 - samples/sec: 72.55 - lr: 0.100000\n",
            "2022-12-12 11:27:02,349 epoch 3 - iter 8/25 - loss 1.46455902 - samples/sec: 79.01 - lr: 0.100000\n",
            "2022-12-12 11:27:03,641 epoch 3 - iter 10/25 - loss 1.46250795 - samples/sec: 49.58 - lr: 0.100000\n",
            "2022-12-12 11:27:04,536 epoch 3 - iter 12/25 - loss 1.43920508 - samples/sec: 71.63 - lr: 0.100000\n",
            "2022-12-12 11:27:05,677 epoch 3 - iter 14/25 - loss 1.41019728 - samples/sec: 56.17 - lr: 0.100000\n",
            "2022-12-12 11:27:07,253 epoch 3 - iter 16/25 - loss 1.41646657 - samples/sec: 40.65 - lr: 0.100000\n",
            "2022-12-12 11:27:08,427 epoch 3 - iter 18/25 - loss 1.42233190 - samples/sec: 54.58 - lr: 0.100000\n",
            "2022-12-12 11:27:09,638 epoch 3 - iter 20/25 - loss 1.43520053 - samples/sec: 52.93 - lr: 0.100000\n",
            "2022-12-12 11:27:11,893 epoch 3 - iter 22/25 - loss 1.42708210 - samples/sec: 28.39 - lr: 0.100000\n",
            "2022-12-12 11:27:12,791 epoch 3 - iter 24/25 - loss 1.42434372 - samples/sec: 71.44 - lr: 0.100000\n",
            "2022-12-12 11:27:12,864 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:27:12,865 EPOCH 3 done: loss 1.4218 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:27:13,331 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:27:13,342 DEV : loss 1.1883928775787354 - f1-score (micro avg)  0.0229\n",
            "2022-12-12 11:27:13,356 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:27:13,358 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:27:13,831 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:27:15,084 epoch 4 - iter 2/25 - loss 1.50043860 - samples/sec: 51.15 - lr: 0.100000\n",
            "2022-12-12 11:27:16,040 epoch 4 - iter 4/25 - loss 1.43467150 - samples/sec: 67.01 - lr: 0.100000\n",
            "2022-12-12 11:27:18,379 epoch 4 - iter 6/25 - loss 1.38494202 - samples/sec: 27.38 - lr: 0.100000\n",
            "2022-12-12 11:27:19,463 epoch 4 - iter 8/25 - loss 1.36489707 - samples/sec: 59.14 - lr: 0.100000\n",
            "2022-12-12 11:27:21,050 epoch 4 - iter 10/25 - loss 1.35078045 - samples/sec: 40.36 - lr: 0.100000\n",
            "2022-12-12 11:27:22,108 epoch 4 - iter 12/25 - loss 1.36166018 - samples/sec: 60.62 - lr: 0.100000\n",
            "2022-12-12 11:27:23,345 epoch 4 - iter 14/25 - loss 1.33934000 - samples/sec: 51.80 - lr: 0.100000\n",
            "2022-12-12 11:27:24,632 epoch 4 - iter 16/25 - loss 1.31272902 - samples/sec: 49.77 - lr: 0.100000\n",
            "2022-12-12 11:27:26,044 epoch 4 - iter 18/25 - loss 1.32249189 - samples/sec: 45.36 - lr: 0.100000\n",
            "2022-12-12 11:27:27,319 epoch 4 - iter 20/25 - loss 1.31127244 - samples/sec: 50.27 - lr: 0.100000\n",
            "2022-12-12 11:27:28,252 epoch 4 - iter 22/25 - loss 1.29088264 - samples/sec: 68.71 - lr: 0.100000\n",
            "2022-12-12 11:27:29,384 epoch 4 - iter 24/25 - loss 1.28353421 - samples/sec: 56.59 - lr: 0.100000\n",
            "2022-12-12 11:27:29,470 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:27:29,470 EPOCH 4 done: loss 1.2834 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:27:29,928 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:27:29,937 DEV : loss 1.036251425743103 - f1-score (micro avg)  0.0703\n",
            "2022-12-12 11:27:29,946 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:27:29,948 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:27:30,415 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:27:31,424 epoch 5 - iter 2/25 - loss 1.08857482 - samples/sec: 63.55 - lr: 0.100000\n",
            "2022-12-12 11:27:32,510 epoch 5 - iter 4/25 - loss 1.17847653 - samples/sec: 59.02 - lr: 0.100000\n",
            "2022-12-12 11:27:33,613 epoch 5 - iter 6/25 - loss 1.24248350 - samples/sec: 58.09 - lr: 0.100000\n",
            "2022-12-12 11:27:34,737 epoch 5 - iter 8/25 - loss 1.20772568 - samples/sec: 56.99 - lr: 0.100000\n",
            "2022-12-12 11:27:36,025 epoch 5 - iter 10/25 - loss 1.21029254 - samples/sec: 49.75 - lr: 0.100000\n",
            "2022-12-12 11:27:38,681 epoch 5 - iter 12/25 - loss 1.18506435 - samples/sec: 24.11 - lr: 0.100000\n",
            "2022-12-12 11:27:39,566 epoch 5 - iter 14/25 - loss 1.19672435 - samples/sec: 72.47 - lr: 0.100000\n",
            "2022-12-12 11:27:40,630 epoch 5 - iter 16/25 - loss 1.17624244 - samples/sec: 60.18 - lr: 0.100000\n",
            "2022-12-12 11:27:41,364 epoch 5 - iter 18/25 - loss 1.16207064 - samples/sec: 87.46 - lr: 0.100000\n",
            "2022-12-12 11:27:42,374 epoch 5 - iter 20/25 - loss 1.16342375 - samples/sec: 63.45 - lr: 0.100000\n",
            "2022-12-12 11:27:43,534 epoch 5 - iter 22/25 - loss 1.15300446 - samples/sec: 55.23 - lr: 0.100000\n",
            "2022-12-12 11:27:44,809 epoch 5 - iter 24/25 - loss 1.14518772 - samples/sec: 50.27 - lr: 0.100000\n",
            "2022-12-12 11:27:44,882 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:27:44,884 EPOCH 5 done: loss 1.1450 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:27:45,335 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:27:45,342 DEV : loss 0.9149270057678223 - f1-score (micro avg)  0.1117\n",
            "2022-12-12 11:27:45,352 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:27:45,354 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:27:45,801 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:27:46,876 epoch 6 - iter 2/25 - loss 1.02511181 - samples/sec: 59.66 - lr: 0.100000\n",
            "2022-12-12 11:27:47,844 epoch 6 - iter 4/25 - loss 1.05351785 - samples/sec: 66.21 - lr: 0.100000\n",
            "2022-12-12 11:27:48,886 epoch 6 - iter 6/25 - loss 1.06383183 - samples/sec: 61.48 - lr: 0.100000\n",
            "2022-12-12 11:27:50,078 epoch 6 - iter 8/25 - loss 1.05913981 - samples/sec: 53.73 - lr: 0.100000\n",
            "2022-12-12 11:27:51,218 epoch 6 - iter 10/25 - loss 1.03909573 - samples/sec: 56.24 - lr: 0.100000\n",
            "2022-12-12 11:27:52,259 epoch 6 - iter 12/25 - loss 1.02201084 - samples/sec: 61.55 - lr: 0.100000\n",
            "2022-12-12 11:27:53,489 epoch 6 - iter 14/25 - loss 1.03249568 - samples/sec: 52.07 - lr: 0.100000\n",
            "2022-12-12 11:27:55,697 epoch 6 - iter 16/25 - loss 1.03351550 - samples/sec: 29.01 - lr: 0.100000\n",
            "2022-12-12 11:27:56,697 epoch 6 - iter 18/25 - loss 1.02370746 - samples/sec: 64.09 - lr: 0.100000\n",
            "2022-12-12 11:27:57,725 epoch 6 - iter 20/25 - loss 1.02976577 - samples/sec: 62.29 - lr: 0.100000\n",
            "2022-12-12 11:27:58,797 epoch 6 - iter 22/25 - loss 1.04316193 - samples/sec: 59.80 - lr: 0.100000\n",
            "2022-12-12 11:27:59,844 epoch 6 - iter 24/25 - loss 1.03056144 - samples/sec: 61.23 - lr: 0.100000\n",
            "2022-12-12 11:27:59,902 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:27:59,903 EPOCH 6 done: loss 1.0302 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:28:00,355 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:28:00,365 DEV : loss 0.8102611899375916 - f1-score (micro avg)  0.2018\n",
            "2022-12-12 11:28:00,374 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:28:00,375 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:28:00,829 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:28:01,909 epoch 7 - iter 2/25 - loss 0.90090076 - samples/sec: 59.38 - lr: 0.100000\n",
            "2022-12-12 11:28:02,969 epoch 7 - iter 4/25 - loss 0.95044629 - samples/sec: 60.44 - lr: 0.100000\n",
            "2022-12-12 11:28:05,257 epoch 7 - iter 6/25 - loss 0.92990327 - samples/sec: 27.99 - lr: 0.100000\n",
            "2022-12-12 11:28:06,357 epoch 7 - iter 8/25 - loss 0.95927918 - samples/sec: 58.26 - lr: 0.100000\n",
            "2022-12-12 11:28:07,430 epoch 7 - iter 10/25 - loss 0.98187611 - samples/sec: 59.75 - lr: 0.100000\n",
            "2022-12-12 11:28:08,386 epoch 7 - iter 12/25 - loss 0.94196812 - samples/sec: 67.03 - lr: 0.100000\n",
            "2022-12-12 11:28:09,612 epoch 7 - iter 14/25 - loss 0.92804417 - samples/sec: 52.23 - lr: 0.100000\n",
            "2022-12-12 11:28:10,461 epoch 7 - iter 16/25 - loss 0.93226169 - samples/sec: 75.48 - lr: 0.100000\n",
            "2022-12-12 11:28:11,294 epoch 7 - iter 18/25 - loss 0.91865665 - samples/sec: 77.03 - lr: 0.100000\n",
            "2022-12-12 11:28:12,500 epoch 7 - iter 20/25 - loss 0.92598027 - samples/sec: 53.12 - lr: 0.100000\n",
            "2022-12-12 11:28:13,450 epoch 7 - iter 22/25 - loss 0.92725687 - samples/sec: 67.43 - lr: 0.100000\n",
            "2022-12-12 11:28:14,406 epoch 7 - iter 24/25 - loss 0.91181481 - samples/sec: 67.10 - lr: 0.100000\n",
            "2022-12-12 11:28:14,477 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:28:14,478 EPOCH 7 done: loss 0.9117 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:28:14,909 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:28:14,916 DEV : loss 0.7067591547966003 - f1-score (micro avg)  0.2571\n",
            "2022-12-12 11:28:14,924 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:28:14,926 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:28:15,377 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:28:16,499 epoch 8 - iter 2/25 - loss 0.84237104 - samples/sec: 57.11 - lr: 0.100000\n",
            "2022-12-12 11:28:17,555 epoch 8 - iter 4/25 - loss 0.89550105 - samples/sec: 60.66 - lr: 0.100000\n",
            "2022-12-12 11:28:19,658 epoch 8 - iter 6/25 - loss 0.87820296 - samples/sec: 30.46 - lr: 0.100000\n",
            "2022-12-12 11:28:20,570 epoch 8 - iter 8/25 - loss 0.86183796 - samples/sec: 70.24 - lr: 0.100000\n",
            "2022-12-12 11:28:21,595 epoch 8 - iter 10/25 - loss 0.83699315 - samples/sec: 62.53 - lr: 0.100000\n",
            "2022-12-12 11:28:22,812 epoch 8 - iter 12/25 - loss 0.84916669 - samples/sec: 52.65 - lr: 0.100000\n",
            "2022-12-12 11:28:24,059 epoch 8 - iter 14/25 - loss 0.84855435 - samples/sec: 51.39 - lr: 0.100000\n",
            "2022-12-12 11:28:24,920 epoch 8 - iter 16/25 - loss 0.84199068 - samples/sec: 74.40 - lr: 0.100000\n",
            "2022-12-12 11:28:25,838 epoch 8 - iter 18/25 - loss 0.84162188 - samples/sec: 69.87 - lr: 0.100000\n",
            "2022-12-12 11:28:26,658 epoch 8 - iter 20/25 - loss 0.84374562 - samples/sec: 78.18 - lr: 0.100000\n",
            "2022-12-12 11:28:27,794 epoch 8 - iter 22/25 - loss 0.84141593 - samples/sec: 56.36 - lr: 0.100000\n",
            "2022-12-12 11:28:28,756 epoch 8 - iter 24/25 - loss 0.84112266 - samples/sec: 66.66 - lr: 0.100000\n",
            "2022-12-12 11:28:28,817 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:28:28,818 EPOCH 8 done: loss 0.8413 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  6.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:28:29,416 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:28:29,425 DEV : loss 0.6560428738594055 - f1-score (micro avg)  0.3064\n",
            "2022-12-12 11:28:29,435 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:28:29,437 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:28:29,872 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:28:30,802 epoch 9 - iter 2/25 - loss 0.68271537 - samples/sec: 69.00 - lr: 0.100000\n",
            "2022-12-12 11:28:31,912 epoch 9 - iter 4/25 - loss 0.75052870 - samples/sec: 57.74 - lr: 0.100000\n",
            "2022-12-12 11:28:34,025 epoch 9 - iter 6/25 - loss 0.77950411 - samples/sec: 30.30 - lr: 0.100000\n",
            "2022-12-12 11:28:34,895 epoch 9 - iter 8/25 - loss 0.81042954 - samples/sec: 73.66 - lr: 0.100000\n",
            "2022-12-12 11:28:35,977 epoch 9 - iter 10/25 - loss 0.81697401 - samples/sec: 59.25 - lr: 0.100000\n",
            "2022-12-12 11:28:37,123 epoch 9 - iter 12/25 - loss 0.80676599 - samples/sec: 55.93 - lr: 0.100000\n",
            "2022-12-12 11:28:38,210 epoch 9 - iter 14/25 - loss 0.81527845 - samples/sec: 58.90 - lr: 0.100000\n",
            "2022-12-12 11:28:39,286 epoch 9 - iter 16/25 - loss 0.80725247 - samples/sec: 59.59 - lr: 0.100000\n",
            "2022-12-12 11:28:40,471 epoch 9 - iter 18/25 - loss 0.79264566 - samples/sec: 54.06 - lr: 0.100000\n",
            "2022-12-12 11:28:41,745 epoch 9 - iter 20/25 - loss 0.78853839 - samples/sec: 50.29 - lr: 0.100000\n",
            "2022-12-12 11:28:43,165 epoch 9 - iter 22/25 - loss 0.78828026 - samples/sec: 45.13 - lr: 0.100000\n",
            "2022-12-12 11:28:44,092 epoch 9 - iter 24/25 - loss 0.78969180 - samples/sec: 69.12 - lr: 0.100000\n",
            "2022-12-12 11:28:44,168 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:28:44,168 EPOCH 9 done: loss 0.7889 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:28:44,624 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:28:44,632 DEV : loss 0.6681855916976929 - f1-score (micro avg)  0.2108\n",
            "2022-12-12 11:28:44,642 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:28:44,644 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:28:45,865 epoch 10 - iter 2/25 - loss 0.85775051 - samples/sec: 52.51 - lr: 0.100000\n",
            "2022-12-12 11:28:46,737 epoch 10 - iter 4/25 - loss 0.82711466 - samples/sec: 73.45 - lr: 0.100000\n",
            "2022-12-12 11:28:47,865 epoch 10 - iter 6/25 - loss 0.81599831 - samples/sec: 56.82 - lr: 0.100000\n",
            "2022-12-12 11:28:49,174 epoch 10 - iter 8/25 - loss 0.80462673 - samples/sec: 48.94 - lr: 0.100000\n",
            "2022-12-12 11:28:50,343 epoch 10 - iter 10/25 - loss 0.79173585 - samples/sec: 54.81 - lr: 0.100000\n",
            "2022-12-12 11:28:52,453 epoch 10 - iter 12/25 - loss 0.78180852 - samples/sec: 30.36 - lr: 0.100000\n",
            "2022-12-12 11:28:53,699 epoch 10 - iter 14/25 - loss 0.77965792 - samples/sec: 51.41 - lr: 0.100000\n",
            "2022-12-12 11:28:54,980 epoch 10 - iter 16/25 - loss 0.76773810 - samples/sec: 50.03 - lr: 0.100000\n",
            "2022-12-12 11:28:56,011 epoch 10 - iter 18/25 - loss 0.76140906 - samples/sec: 62.14 - lr: 0.100000\n",
            "2022-12-12 11:28:57,103 epoch 10 - iter 20/25 - loss 0.74963452 - samples/sec: 58.68 - lr: 0.100000\n",
            "2022-12-12 11:28:57,976 epoch 10 - iter 22/25 - loss 0.75664654 - samples/sec: 73.39 - lr: 0.100000\n",
            "2022-12-12 11:28:58,980 epoch 10 - iter 24/25 - loss 0.75410909 - samples/sec: 63.86 - lr: 0.100000\n",
            "2022-12-12 11:28:59,049 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:28:59,050 EPOCH 10 done: loss 0.7539 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:28:59,613 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:28:59,622 DEV : loss 0.6133589148521423 - f1-score (micro avg)  0.3596\n",
            "2022-12-12 11:28:59,631 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:28:59,633 saving best model\n",
            "2022-12-12 11:29:00,101 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:29:01,487 epoch 11 - iter 2/25 - loss 0.72546280 - samples/sec: 46.24 - lr: 0.100000\n",
            "2022-12-12 11:29:02,666 epoch 11 - iter 4/25 - loss 0.68828043 - samples/sec: 54.36 - lr: 0.100000\n",
            "2022-12-12 11:29:03,566 epoch 11 - iter 6/25 - loss 0.69265142 - samples/sec: 71.23 - lr: 0.100000\n",
            "2022-12-12 11:29:04,433 epoch 11 - iter 8/25 - loss 0.68268645 - samples/sec: 73.88 - lr: 0.100000\n",
            "2022-12-12 11:29:05,488 epoch 11 - iter 10/25 - loss 0.67937951 - samples/sec: 60.77 - lr: 0.100000\n",
            "2022-12-12 11:29:06,601 epoch 11 - iter 12/25 - loss 0.69788879 - samples/sec: 57.55 - lr: 0.100000\n",
            "2022-12-12 11:29:07,705 epoch 11 - iter 14/25 - loss 0.69084552 - samples/sec: 58.05 - lr: 0.100000\n",
            "2022-12-12 11:29:08,622 epoch 11 - iter 16/25 - loss 0.71029704 - samples/sec: 69.87 - lr: 0.100000\n",
            "2022-12-12 11:29:10,964 epoch 11 - iter 18/25 - loss 0.71086430 - samples/sec: 27.34 - lr: 0.100000\n",
            "2022-12-12 11:29:12,106 epoch 11 - iter 20/25 - loss 0.70737509 - samples/sec: 56.10 - lr: 0.100000\n",
            "2022-12-12 11:29:13,066 epoch 11 - iter 22/25 - loss 0.70079074 - samples/sec: 66.82 - lr: 0.100000\n",
            "2022-12-12 11:29:14,384 epoch 11 - iter 24/25 - loss 0.70332252 - samples/sec: 48.60 - lr: 0.100000\n",
            "2022-12-12 11:29:14,486 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:29:14,487 EPOCH 11 done: loss 0.7040 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:29:14,988 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:29:14,995 DEV : loss 0.5548257827758789 - f1-score (micro avg)  0.3415\n",
            "2022-12-12 11:29:15,004 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:29:15,006 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:29:16,040 epoch 12 - iter 2/25 - loss 0.78344825 - samples/sec: 61.93 - lr: 0.100000\n",
            "2022-12-12 11:29:16,793 epoch 12 - iter 4/25 - loss 0.74692865 - samples/sec: 85.14 - lr: 0.100000\n",
            "2022-12-12 11:29:17,669 epoch 12 - iter 6/25 - loss 0.77014968 - samples/sec: 73.24 - lr: 0.100000\n",
            "2022-12-12 11:29:19,856 epoch 12 - iter 8/25 - loss 0.75035949 - samples/sec: 29.28 - lr: 0.100000\n",
            "2022-12-12 11:29:20,939 epoch 12 - iter 10/25 - loss 0.72046442 - samples/sec: 59.20 - lr: 0.100000\n",
            "2022-12-12 11:29:22,310 epoch 12 - iter 12/25 - loss 0.70474731 - samples/sec: 46.71 - lr: 0.100000\n",
            "2022-12-12 11:29:23,151 epoch 12 - iter 14/25 - loss 0.69362839 - samples/sec: 76.27 - lr: 0.100000\n",
            "2022-12-12 11:29:23,998 epoch 12 - iter 16/25 - loss 0.69000077 - samples/sec: 75.71 - lr: 0.100000\n",
            "2022-12-12 11:29:25,021 epoch 12 - iter 18/25 - loss 0.68068176 - samples/sec: 62.59 - lr: 0.100000\n",
            "2022-12-12 11:29:26,022 epoch 12 - iter 20/25 - loss 0.66715418 - samples/sec: 64.06 - lr: 0.100000\n",
            "2022-12-12 11:29:27,147 epoch 12 - iter 22/25 - loss 0.67560815 - samples/sec: 56.93 - lr: 0.100000\n",
            "2022-12-12 11:29:28,060 epoch 12 - iter 24/25 - loss 0.66597485 - samples/sec: 70.19 - lr: 0.100000\n",
            "2022-12-12 11:29:28,130 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:29:28,131 EPOCH 12 done: loss 0.6651 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:29:28,580 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:29:28,588 DEV : loss 0.5143325328826904 - f1-score (micro avg)  0.4213\n",
            "2022-12-12 11:29:28,596 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:29:28,597 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:29:29,056 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:29:31,290 epoch 13 - iter 2/25 - loss 0.60075172 - samples/sec: 28.67 - lr: 0.100000\n",
            "2022-12-12 11:29:32,173 epoch 13 - iter 4/25 - loss 0.61501798 - samples/sec: 72.61 - lr: 0.100000\n",
            "2022-12-12 11:29:33,244 epoch 13 - iter 6/25 - loss 0.64369036 - samples/sec: 59.86 - lr: 0.100000\n",
            "2022-12-12 11:29:34,200 epoch 13 - iter 8/25 - loss 0.63057407 - samples/sec: 66.98 - lr: 0.100000\n",
            "2022-12-12 11:29:35,027 epoch 13 - iter 10/25 - loss 0.65109930 - samples/sec: 77.52 - lr: 0.100000\n",
            "2022-12-12 11:29:36,130 epoch 13 - iter 12/25 - loss 0.65116447 - samples/sec: 58.10 - lr: 0.100000\n",
            "2022-12-12 11:29:37,377 epoch 13 - iter 14/25 - loss 0.65749505 - samples/sec: 51.38 - lr: 0.100000\n",
            "2022-12-12 11:29:38,456 epoch 13 - iter 16/25 - loss 0.64762062 - samples/sec: 59.39 - lr: 0.100000\n",
            "2022-12-12 11:29:39,661 epoch 13 - iter 18/25 - loss 0.64560836 - samples/sec: 53.18 - lr: 0.100000\n",
            "2022-12-12 11:29:40,854 epoch 13 - iter 20/25 - loss 0.65271639 - samples/sec: 53.71 - lr: 0.100000\n",
            "2022-12-12 11:29:41,877 epoch 13 - iter 22/25 - loss 0.65936067 - samples/sec: 62.67 - lr: 0.100000\n",
            "2022-12-12 11:29:42,867 epoch 13 - iter 24/25 - loss 0.65500772 - samples/sec: 64.74 - lr: 0.100000\n",
            "2022-12-12 11:29:42,946 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:29:42,947 EPOCH 13 done: loss 0.6548 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:29:43,381 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:29:43,388 DEV : loss 0.48121148347854614 - f1-score (micro avg)  0.4725\n",
            "2022-12-12 11:29:43,397 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:29:43,399 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:29:43,854 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:29:45,043 epoch 14 - iter 2/25 - loss 0.63045875 - samples/sec: 53.90 - lr: 0.100000\n",
            "2022-12-12 11:29:46,144 epoch 14 - iter 4/25 - loss 0.60989192 - samples/sec: 58.20 - lr: 0.100000\n",
            "2022-12-12 11:29:47,365 epoch 14 - iter 6/25 - loss 0.58684257 - samples/sec: 52.51 - lr: 0.100000\n",
            "2022-12-12 11:29:48,209 epoch 14 - iter 8/25 - loss 0.58533119 - samples/sec: 75.99 - lr: 0.100000\n",
            "2022-12-12 11:29:49,367 epoch 14 - iter 10/25 - loss 0.62303029 - samples/sec: 55.29 - lr: 0.100000\n",
            "2022-12-12 11:29:50,639 epoch 14 - iter 12/25 - loss 0.62299588 - samples/sec: 50.37 - lr: 0.100000\n",
            "2022-12-12 11:29:51,672 epoch 14 - iter 14/25 - loss 0.62534272 - samples/sec: 62.06 - lr: 0.100000\n",
            "2022-12-12 11:29:53,920 epoch 14 - iter 16/25 - loss 0.62444697 - samples/sec: 28.48 - lr: 0.100000\n",
            "2022-12-12 11:29:54,850 epoch 14 - iter 18/25 - loss 0.62432487 - samples/sec: 68.90 - lr: 0.100000\n",
            "2022-12-12 11:29:55,945 epoch 14 - iter 20/25 - loss 0.61456715 - samples/sec: 58.49 - lr: 0.100000\n",
            "2022-12-12 11:29:56,858 epoch 14 - iter 22/25 - loss 0.61366123 - samples/sec: 70.24 - lr: 0.100000\n",
            "2022-12-12 11:29:57,948 epoch 14 - iter 24/25 - loss 0.61789361 - samples/sec: 58.78 - lr: 0.100000\n",
            "2022-12-12 11:29:58,028 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:29:58,029 EPOCH 14 done: loss 0.6164 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:29:58,515 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:29:58,528 DEV : loss 0.4857262372970581 - f1-score (micro avg)  0.3922\n",
            "2022-12-12 11:29:58,537 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:29:58,539 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:29:59,477 epoch 15 - iter 2/25 - loss 0.64591258 - samples/sec: 68.35 - lr: 0.100000\n",
            "2022-12-12 11:30:01,822 epoch 15 - iter 4/25 - loss 0.61018118 - samples/sec: 27.30 - lr: 0.100000\n",
            "2022-12-12 11:30:02,778 epoch 15 - iter 6/25 - loss 0.61160936 - samples/sec: 67.03 - lr: 0.100000\n",
            "2022-12-12 11:30:03,775 epoch 15 - iter 8/25 - loss 0.58680660 - samples/sec: 64.30 - lr: 0.100000\n",
            "2022-12-12 11:30:04,828 epoch 15 - iter 10/25 - loss 0.58713569 - samples/sec: 60.82 - lr: 0.100000\n",
            "2022-12-12 11:30:05,910 epoch 15 - iter 12/25 - loss 0.58827400 - samples/sec: 59.23 - lr: 0.100000\n",
            "2022-12-12 11:30:06,894 epoch 15 - iter 14/25 - loss 0.58373513 - samples/sec: 65.15 - lr: 0.100000\n",
            "2022-12-12 11:30:07,822 epoch 15 - iter 16/25 - loss 0.58022922 - samples/sec: 69.07 - lr: 0.100000\n",
            "2022-12-12 11:30:08,936 epoch 15 - iter 18/25 - loss 0.58028117 - samples/sec: 57.53 - lr: 0.100000\n",
            "2022-12-12 11:30:10,073 epoch 15 - iter 20/25 - loss 0.58709833 - samples/sec: 56.33 - lr: 0.100000\n",
            "2022-12-12 11:30:11,126 epoch 15 - iter 22/25 - loss 0.58364508 - samples/sec: 60.89 - lr: 0.100000\n",
            "2022-12-12 11:30:12,203 epoch 15 - iter 24/25 - loss 0.58521541 - samples/sec: 59.48 - lr: 0.100000\n",
            "2022-12-12 11:30:12,271 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:30:12,272 EPOCH 15 done: loss 0.5840 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:30:12,728 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:30:12,736 DEV : loss 0.4894569218158722 - f1-score (micro avg)  0.4041\n",
            "2022-12-12 11:30:12,745 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:30:12,747 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:30:13,546 epoch 16 - iter 2/25 - loss 0.57669883 - samples/sec: 80.26 - lr: 0.100000\n",
            "2022-12-12 11:30:14,403 epoch 16 - iter 4/25 - loss 0.56427339 - samples/sec: 74.80 - lr: 0.100000\n",
            "2022-12-12 11:30:16,652 epoch 16 - iter 6/25 - loss 0.55796806 - samples/sec: 28.48 - lr: 0.100000\n",
            "2022-12-12 11:30:17,438 epoch 16 - iter 8/25 - loss 0.56282697 - samples/sec: 81.56 - lr: 0.100000\n",
            "2022-12-12 11:30:18,466 epoch 16 - iter 10/25 - loss 0.57308069 - samples/sec: 62.38 - lr: 0.100000\n",
            "2022-12-12 11:30:19,521 epoch 16 - iter 12/25 - loss 0.57826960 - samples/sec: 60.73 - lr: 0.100000\n",
            "2022-12-12 11:30:20,344 epoch 16 - iter 14/25 - loss 0.57594091 - samples/sec: 77.89 - lr: 0.100000\n",
            "2022-12-12 11:30:21,605 epoch 16 - iter 16/25 - loss 0.58647984 - samples/sec: 50.79 - lr: 0.100000\n",
            "2022-12-12 11:30:22,556 epoch 16 - iter 18/25 - loss 0.58390873 - samples/sec: 67.39 - lr: 0.100000\n",
            "2022-12-12 11:30:23,538 epoch 16 - iter 20/25 - loss 0.57368433 - samples/sec: 65.32 - lr: 0.100000\n",
            "2022-12-12 11:30:24,530 epoch 16 - iter 22/25 - loss 0.57345389 - samples/sec: 64.59 - lr: 0.100000\n",
            "2022-12-12 11:30:25,512 epoch 16 - iter 24/25 - loss 0.56690192 - samples/sec: 65.23 - lr: 0.100000\n",
            "2022-12-12 11:30:25,572 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:30:25,572 EPOCH 16 done: loss 0.5670 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:30:25,998 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:30:26,005 DEV : loss 0.436246782541275 - f1-score (micro avg)  0.5131\n",
            "2022-12-12 11:30:26,013 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:30:26,015 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:30:26,458 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:30:27,449 epoch 17 - iter 2/25 - loss 0.52516177 - samples/sec: 64.68 - lr: 0.100000\n",
            "2022-12-12 11:30:28,508 epoch 17 - iter 4/25 - loss 0.53073546 - samples/sec: 60.56 - lr: 0.100000\n",
            "2022-12-12 11:30:29,558 epoch 17 - iter 6/25 - loss 0.55956357 - samples/sec: 60.99 - lr: 0.100000\n",
            "2022-12-12 11:30:30,515 epoch 17 - iter 8/25 - loss 0.52749754 - samples/sec: 66.99 - lr: 0.100000\n",
            "2022-12-12 11:30:31,548 epoch 17 - iter 10/25 - loss 0.53136020 - samples/sec: 62.04 - lr: 0.100000\n",
            "2022-12-12 11:30:32,914 epoch 17 - iter 12/25 - loss 0.55624825 - samples/sec: 46.90 - lr: 0.100000\n",
            "2022-12-12 11:30:33,893 epoch 17 - iter 14/25 - loss 0.56515229 - samples/sec: 65.46 - lr: 0.100000\n",
            "2022-12-12 11:30:36,049 epoch 17 - iter 16/25 - loss 0.55727905 - samples/sec: 29.71 - lr: 0.100000\n",
            "2022-12-12 11:30:37,194 epoch 17 - iter 18/25 - loss 0.56731458 - samples/sec: 55.94 - lr: 0.100000\n",
            "2022-12-12 11:30:38,212 epoch 17 - iter 20/25 - loss 0.56171677 - samples/sec: 62.98 - lr: 0.100000\n",
            "2022-12-12 11:30:38,942 epoch 17 - iter 22/25 - loss 0.55781345 - samples/sec: 87.88 - lr: 0.100000\n",
            "2022-12-12 11:30:40,007 epoch 17 - iter 24/25 - loss 0.55530516 - samples/sec: 60.17 - lr: 0.100000\n",
            "2022-12-12 11:30:40,086 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:30:40,087 EPOCH 17 done: loss 0.5553 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:30:40,531 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:30:40,538 DEV : loss 0.44525179266929626 - f1-score (micro avg)  0.4631\n",
            "2022-12-12 11:30:40,546 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:30:40,549 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:30:41,547 epoch 18 - iter 2/25 - loss 0.58333333 - samples/sec: 64.23 - lr: 0.100000\n",
            "2022-12-12 11:30:42,545 epoch 18 - iter 4/25 - loss 0.56232880 - samples/sec: 64.21 - lr: 0.100000\n",
            "2022-12-12 11:30:43,596 epoch 18 - iter 6/25 - loss 0.58372979 - samples/sec: 60.95 - lr: 0.100000\n",
            "2022-12-12 11:30:44,498 epoch 18 - iter 8/25 - loss 0.56099452 - samples/sec: 71.28 - lr: 0.100000\n",
            "2022-12-12 11:30:45,588 epoch 18 - iter 10/25 - loss 0.55658885 - samples/sec: 58.81 - lr: 0.100000\n",
            "2022-12-12 11:30:46,319 epoch 18 - iter 12/25 - loss 0.55353858 - samples/sec: 87.71 - lr: 0.100000\n",
            "2022-12-12 11:30:47,483 epoch 18 - iter 14/25 - loss 0.55448822 - samples/sec: 55.05 - lr: 0.100000\n",
            "2022-12-12 11:30:48,622 epoch 18 - iter 16/25 - loss 0.54870113 - samples/sec: 56.28 - lr: 0.100000\n",
            "2022-12-12 11:30:49,728 epoch 18 - iter 18/25 - loss 0.54377167 - samples/sec: 57.92 - lr: 0.100000\n",
            "2022-12-12 11:30:50,948 epoch 18 - iter 20/25 - loss 0.54307119 - samples/sec: 52.51 - lr: 0.100000\n",
            "2022-12-12 11:30:53,141 epoch 18 - iter 22/25 - loss 0.54129469 - samples/sec: 29.20 - lr: 0.100000\n",
            "2022-12-12 11:30:54,292 epoch 18 - iter 24/25 - loss 0.54602226 - samples/sec: 55.67 - lr: 0.100000\n",
            "2022-12-12 11:30:54,396 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:30:54,397 EPOCH 18 done: loss 0.5452 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:30:54,831 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:30:54,838 DEV : loss 0.4129801094532013 - f1-score (micro avg)  0.5135\n",
            "2022-12-12 11:30:54,849 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:30:54,851 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:30:55,325 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:30:56,457 epoch 19 - iter 2/25 - loss 0.54454840 - samples/sec: 56.64 - lr: 0.100000\n",
            "2022-12-12 11:30:57,579 epoch 19 - iter 4/25 - loss 0.51739820 - samples/sec: 57.10 - lr: 0.100000\n",
            "2022-12-12 11:30:59,813 epoch 19 - iter 6/25 - loss 0.51097119 - samples/sec: 28.66 - lr: 0.100000\n",
            "2022-12-12 11:31:00,771 epoch 19 - iter 8/25 - loss 0.50100201 - samples/sec: 66.88 - lr: 0.100000\n",
            "2022-12-12 11:31:01,705 epoch 19 - iter 10/25 - loss 0.50653146 - samples/sec: 68.66 - lr: 0.100000\n",
            "2022-12-12 11:31:02,792 epoch 19 - iter 12/25 - loss 0.50154531 - samples/sec: 58.98 - lr: 0.100000\n",
            "2022-12-12 11:31:03,613 epoch 19 - iter 14/25 - loss 0.51573086 - samples/sec: 78.00 - lr: 0.100000\n",
            "2022-12-12 11:31:04,531 epoch 19 - iter 16/25 - loss 0.51766705 - samples/sec: 69.83 - lr: 0.100000\n",
            "2022-12-12 11:31:05,760 epoch 19 - iter 18/25 - loss 0.51502561 - samples/sec: 52.16 - lr: 0.100000\n",
            "2022-12-12 11:31:06,796 epoch 19 - iter 20/25 - loss 0.51840920 - samples/sec: 61.83 - lr: 0.100000\n",
            "2022-12-12 11:31:07,863 epoch 19 - iter 22/25 - loss 0.51611352 - samples/sec: 60.03 - lr: 0.100000\n",
            "2022-12-12 11:31:09,150 epoch 19 - iter 24/25 - loss 0.51394107 - samples/sec: 49.78 - lr: 0.100000\n",
            "2022-12-12 11:31:09,239 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:31:09,240 EPOCH 19 done: loss 0.5132 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:31:09,705 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:31:09,714 DEV : loss 0.3978044092655182 - f1-score (micro avg)  0.5103\n",
            "2022-12-12 11:31:09,722 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:31:09,724 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:31:10,500 epoch 20 - iter 2/25 - loss 0.54999469 - samples/sec: 82.62 - lr: 0.100000\n",
            "2022-12-12 11:31:11,432 epoch 20 - iter 4/25 - loss 0.52595474 - samples/sec: 68.77 - lr: 0.100000\n",
            "2022-12-12 11:31:12,327 epoch 20 - iter 6/25 - loss 0.52679124 - samples/sec: 71.59 - lr: 0.100000\n",
            "2022-12-12 11:31:13,443 epoch 20 - iter 8/25 - loss 0.51050216 - samples/sec: 57.43 - lr: 0.100000\n",
            "2022-12-12 11:31:14,725 epoch 20 - iter 10/25 - loss 0.49688356 - samples/sec: 50.01 - lr: 0.100000\n",
            "2022-12-12 11:31:15,982 epoch 20 - iter 12/25 - loss 0.49482137 - samples/sec: 50.96 - lr: 0.100000\n",
            "2022-12-12 11:31:17,096 epoch 20 - iter 14/25 - loss 0.48833948 - samples/sec: 57.52 - lr: 0.100000\n",
            "2022-12-12 11:31:18,159 epoch 20 - iter 16/25 - loss 0.49233212 - samples/sec: 60.30 - lr: 0.100000\n",
            "2022-12-12 11:31:19,179 epoch 20 - iter 18/25 - loss 0.49206788 - samples/sec: 62.82 - lr: 0.100000\n",
            "2022-12-12 11:31:20,224 epoch 20 - iter 20/25 - loss 0.50191162 - samples/sec: 61.31 - lr: 0.100000\n",
            "2022-12-12 11:31:22,490 epoch 20 - iter 22/25 - loss 0.50675037 - samples/sec: 28.26 - lr: 0.100000\n",
            "2022-12-12 11:31:23,655 epoch 20 - iter 24/25 - loss 0.50521465 - samples/sec: 54.98 - lr: 0.100000\n",
            "2022-12-12 11:31:23,721 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:31:23,721 EPOCH 20 done: loss 0.5051 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:31:24,163 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:31:24,171 DEV : loss 0.375402569770813 - f1-score (micro avg)  0.543\n",
            "2022-12-12 11:31:24,179 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:31:24,180 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:31:24,619 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:31:25,829 epoch 21 - iter 2/25 - loss 0.47292129 - samples/sec: 52.96 - lr: 0.100000\n",
            "2022-12-12 11:31:26,681 epoch 21 - iter 4/25 - loss 0.45983854 - samples/sec: 75.27 - lr: 0.100000\n",
            "2022-12-12 11:31:27,797 epoch 21 - iter 6/25 - loss 0.49443567 - samples/sec: 57.42 - lr: 0.100000\n",
            "2022-12-12 11:31:29,121 epoch 21 - iter 8/25 - loss 0.48847165 - samples/sec: 48.39 - lr: 0.100000\n",
            "2022-12-12 11:31:30,329 epoch 21 - iter 10/25 - loss 0.48394998 - samples/sec: 53.02 - lr: 0.100000\n",
            "2022-12-12 11:31:31,458 epoch 21 - iter 12/25 - loss 0.48824172 - samples/sec: 56.76 - lr: 0.100000\n",
            "2022-12-12 11:31:33,957 epoch 21 - iter 14/25 - loss 0.48462431 - samples/sec: 25.62 - lr: 0.100000\n",
            "2022-12-12 11:31:34,959 epoch 21 - iter 16/25 - loss 0.48496165 - samples/sec: 63.97 - lr: 0.100000\n",
            "2022-12-12 11:31:35,949 epoch 21 - iter 18/25 - loss 0.47824540 - samples/sec: 64.69 - lr: 0.100000\n",
            "2022-12-12 11:31:37,196 epoch 21 - iter 20/25 - loss 0.47780450 - samples/sec: 51.40 - lr: 0.100000\n",
            "2022-12-12 11:31:38,106 epoch 21 - iter 22/25 - loss 0.48287783 - samples/sec: 70.48 - lr: 0.100000\n",
            "2022-12-12 11:31:39,143 epoch 21 - iter 24/25 - loss 0.48321084 - samples/sec: 61.78 - lr: 0.100000\n",
            "2022-12-12 11:31:39,249 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:31:39,250 EPOCH 21 done: loss 0.4835 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:31:39,757 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:31:39,764 DEV : loss 0.37522342801094055 - f1-score (micro avg)  0.56\n",
            "2022-12-12 11:31:39,772 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:31:39,774 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:31:40,227 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:31:41,377 epoch 22 - iter 2/25 - loss 0.45009080 - samples/sec: 55.71 - lr: 0.100000\n",
            "2022-12-12 11:31:42,664 epoch 22 - iter 4/25 - loss 0.47734617 - samples/sec: 49.79 - lr: 0.100000\n",
            "2022-12-12 11:31:43,925 epoch 22 - iter 6/25 - loss 0.46067117 - samples/sec: 50.82 - lr: 0.100000\n",
            "2022-12-12 11:31:45,140 epoch 22 - iter 8/25 - loss 0.47352130 - samples/sec: 52.75 - lr: 0.100000\n",
            "2022-12-12 11:31:46,063 epoch 22 - iter 10/25 - loss 0.47950739 - samples/sec: 69.43 - lr: 0.100000\n",
            "2022-12-12 11:31:48,314 epoch 22 - iter 12/25 - loss 0.47904717 - samples/sec: 28.45 - lr: 0.100000\n",
            "2022-12-12 11:31:49,187 epoch 22 - iter 14/25 - loss 0.48020601 - samples/sec: 73.41 - lr: 0.100000\n",
            "2022-12-12 11:31:50,040 epoch 22 - iter 16/25 - loss 0.48332298 - samples/sec: 75.15 - lr: 0.100000\n",
            "2022-12-12 11:31:51,137 epoch 22 - iter 18/25 - loss 0.48151631 - samples/sec: 58.41 - lr: 0.100000\n",
            "2022-12-12 11:31:52,212 epoch 22 - iter 20/25 - loss 0.48071907 - samples/sec: 59.64 - lr: 0.100000\n",
            "2022-12-12 11:31:53,219 epoch 22 - iter 22/25 - loss 0.47631663 - samples/sec: 63.62 - lr: 0.100000\n",
            "2022-12-12 11:31:54,271 epoch 22 - iter 24/25 - loss 0.47319587 - samples/sec: 60.90 - lr: 0.100000\n",
            "2022-12-12 11:31:54,350 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:31:54,351 EPOCH 22 done: loss 0.4745 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:31:54,799 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:31:54,806 DEV : loss 0.38068726658821106 - f1-score (micro avg)  0.5538\n",
            "2022-12-12 11:31:54,814 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:31:54,816 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:31:55,820 epoch 23 - iter 2/25 - loss 0.45742467 - samples/sec: 63.84 - lr: 0.100000\n",
            "2022-12-12 11:31:57,006 epoch 23 - iter 4/25 - loss 0.47960560 - samples/sec: 53.99 - lr: 0.100000\n",
            "2022-12-12 11:31:58,023 epoch 23 - iter 6/25 - loss 0.45911250 - samples/sec: 63.01 - lr: 0.100000\n",
            "2022-12-12 11:31:58,962 epoch 23 - iter 8/25 - loss 0.45739116 - samples/sec: 68.26 - lr: 0.100000\n",
            "2022-12-12 11:32:00,140 epoch 23 - iter 10/25 - loss 0.45350781 - samples/sec: 54.41 - lr: 0.100000\n",
            "2022-12-12 11:32:01,284 epoch 23 - iter 12/25 - loss 0.46919913 - samples/sec: 55.99 - lr: 0.100000\n",
            "2022-12-12 11:32:02,444 epoch 23 - iter 14/25 - loss 0.47421205 - samples/sec: 55.25 - lr: 0.100000\n",
            "2022-12-12 11:32:04,615 epoch 23 - iter 16/25 - loss 0.46037494 - samples/sec: 29.49 - lr: 0.100000\n",
            "2022-12-12 11:32:05,970 epoch 23 - iter 18/25 - loss 0.46545249 - samples/sec: 47.25 - lr: 0.100000\n",
            "2022-12-12 11:32:06,824 epoch 23 - iter 20/25 - loss 0.46102964 - samples/sec: 75.03 - lr: 0.100000\n",
            "2022-12-12 11:32:07,859 epoch 23 - iter 22/25 - loss 0.46355384 - samples/sec: 61.92 - lr: 0.100000\n",
            "2022-12-12 11:32:08,720 epoch 23 - iter 24/25 - loss 0.46882382 - samples/sec: 74.47 - lr: 0.100000\n",
            "2022-12-12 11:32:08,795 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:32:08,796 EPOCH 23 done: loss 0.4676 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:32:09,235 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:32:09,242 DEV : loss 0.366337388753891 - f1-score (micro avg)  0.5531\n",
            "2022-12-12 11:32:09,251 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:32:09,252 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:32:10,318 epoch 24 - iter 2/25 - loss 0.44184214 - samples/sec: 60.14 - lr: 0.100000\n",
            "2022-12-12 11:32:11,660 epoch 24 - iter 4/25 - loss 0.42610658 - samples/sec: 47.71 - lr: 0.100000\n",
            "2022-12-12 11:32:12,469 epoch 24 - iter 6/25 - loss 0.45100892 - samples/sec: 79.27 - lr: 0.100000\n",
            "2022-12-12 11:32:13,249 epoch 24 - iter 8/25 - loss 0.45765306 - samples/sec: 82.14 - lr: 0.100000\n",
            "2022-12-12 11:32:14,240 epoch 24 - iter 10/25 - loss 0.45952202 - samples/sec: 64.67 - lr: 0.100000\n",
            "2022-12-12 11:32:15,117 epoch 24 - iter 12/25 - loss 0.44996998 - samples/sec: 73.05 - lr: 0.100000\n",
            "2022-12-12 11:32:17,545 epoch 24 - iter 14/25 - loss 0.44927013 - samples/sec: 26.37 - lr: 0.100000\n",
            "2022-12-12 11:32:18,555 epoch 24 - iter 16/25 - loss 0.45055898 - samples/sec: 63.50 - lr: 0.100000\n",
            "2022-12-12 11:32:19,700 epoch 24 - iter 18/25 - loss 0.44862226 - samples/sec: 55.96 - lr: 0.100000\n",
            "2022-12-12 11:32:21,197 epoch 24 - iter 20/25 - loss 0.45474871 - samples/sec: 42.77 - lr: 0.100000\n",
            "2022-12-12 11:32:22,135 epoch 24 - iter 22/25 - loss 0.45514040 - samples/sec: 68.39 - lr: 0.100000\n",
            "2022-12-12 11:32:23,266 epoch 24 - iter 24/25 - loss 0.45818735 - samples/sec: 56.61 - lr: 0.100000\n",
            "2022-12-12 11:32:23,338 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:32:23,339 EPOCH 24 done: loss 0.4585 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:32:23,790 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:32:23,800 DEV : loss 0.3842059373855591 - f1-score (micro avg)  0.4951\n",
            "2022-12-12 11:32:23,809 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 11:32:23,811 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:32:24,804 epoch 25 - iter 2/25 - loss 0.40276326 - samples/sec: 64.51 - lr: 0.100000\n",
            "2022-12-12 11:32:26,134 epoch 25 - iter 4/25 - loss 0.44005719 - samples/sec: 48.19 - lr: 0.100000\n",
            "2022-12-12 11:32:26,996 epoch 25 - iter 6/25 - loss 0.45125496 - samples/sec: 74.34 - lr: 0.100000\n",
            "2022-12-12 11:32:28,160 epoch 25 - iter 8/25 - loss 0.46664220 - samples/sec: 55.08 - lr: 0.100000\n",
            "2022-12-12 11:32:30,446 epoch 25 - iter 10/25 - loss 0.45604464 - samples/sec: 28.01 - lr: 0.100000\n",
            "2022-12-12 11:32:31,388 epoch 25 - iter 12/25 - loss 0.45826218 - samples/sec: 68.02 - lr: 0.100000\n",
            "2022-12-12 11:32:32,401 epoch 25 - iter 14/25 - loss 0.45764807 - samples/sec: 63.26 - lr: 0.100000\n",
            "2022-12-12 11:32:33,620 epoch 25 - iter 16/25 - loss 0.45296603 - samples/sec: 52.56 - lr: 0.100000\n",
            "2022-12-12 11:32:34,855 epoch 25 - iter 18/25 - loss 0.44713282 - samples/sec: 52.40 - lr: 0.100000\n",
            "2022-12-12 11:32:35,915 epoch 25 - iter 20/25 - loss 0.44424391 - samples/sec: 60.47 - lr: 0.100000\n",
            "2022-12-12 11:32:37,074 epoch 25 - iter 22/25 - loss 0.43902518 - samples/sec: 55.32 - lr: 0.100000\n",
            "2022-12-12 11:32:38,113 epoch 25 - iter 24/25 - loss 0.44253128 - samples/sec: 61.62 - lr: 0.100000\n",
            "2022-12-12 11:32:38,193 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:32:38,194 EPOCH 25 done: loss 0.4421 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:32:38,706 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:32:38,715 DEV : loss 0.3569372892379761 - f1-score (micro avg)  0.5605\n",
            "2022-12-12 11:32:38,723 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:32:38,725 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:32:39,174 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:32:40,142 epoch 26 - iter 2/25 - loss 0.42947545 - samples/sec: 66.22 - lr: 0.100000\n",
            "2022-12-12 11:32:41,062 epoch 26 - iter 4/25 - loss 0.46318314 - samples/sec: 69.71 - lr: 0.100000\n",
            "2022-12-12 11:32:42,067 epoch 26 - iter 6/25 - loss 0.44832607 - samples/sec: 63.80 - lr: 0.100000\n",
            "2022-12-12 11:32:43,118 epoch 26 - iter 8/25 - loss 0.44614313 - samples/sec: 60.94 - lr: 0.100000\n",
            "2022-12-12 11:32:44,127 epoch 26 - iter 10/25 - loss 0.45007305 - samples/sec: 63.57 - lr: 0.100000\n",
            "2022-12-12 11:32:45,226 epoch 26 - iter 12/25 - loss 0.44121109 - samples/sec: 58.28 - lr: 0.100000\n",
            "2022-12-12 11:32:46,548 epoch 26 - iter 14/25 - loss 0.44581411 - samples/sec: 48.48 - lr: 0.100000\n",
            "2022-12-12 11:32:48,661 epoch 26 - iter 16/25 - loss 0.43800719 - samples/sec: 30.31 - lr: 0.100000\n",
            "2022-12-12 11:32:49,843 epoch 26 - iter 18/25 - loss 0.43767265 - samples/sec: 54.17 - lr: 0.100000\n",
            "2022-12-12 11:32:50,937 epoch 26 - iter 20/25 - loss 0.43314229 - samples/sec: 58.56 - lr: 0.100000\n",
            "2022-12-12 11:32:52,195 epoch 26 - iter 22/25 - loss 0.42479105 - samples/sec: 50.93 - lr: 0.100000\n",
            "2022-12-12 11:32:53,389 epoch 26 - iter 24/25 - loss 0.43013484 - samples/sec: 53.68 - lr: 0.100000\n",
            "2022-12-12 11:32:53,457 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:32:53,458 EPOCH 26 done: loss 0.4302 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:32:53,923 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:32:53,930 DEV : loss 0.34899047017097473 - f1-score (micro avg)  0.5552\n",
            "2022-12-12 11:32:53,939 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:32:53,941 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:32:54,810 epoch 27 - iter 2/25 - loss 0.43671945 - samples/sec: 73.75 - lr: 0.100000\n",
            "2022-12-12 11:32:55,849 epoch 27 - iter 4/25 - loss 0.46405884 - samples/sec: 61.69 - lr: 0.100000\n",
            "2022-12-12 11:32:56,956 epoch 27 - iter 6/25 - loss 0.45329106 - samples/sec: 57.91 - lr: 0.100000\n",
            "2022-12-12 11:32:57,901 epoch 27 - iter 8/25 - loss 0.44074862 - samples/sec: 67.85 - lr: 0.100000\n",
            "2022-12-12 11:32:58,728 epoch 27 - iter 10/25 - loss 0.43913890 - samples/sec: 77.46 - lr: 0.100000\n",
            "2022-12-12 11:32:59,972 epoch 27 - iter 12/25 - loss 0.44359388 - samples/sec: 51.53 - lr: 0.100000\n",
            "2022-12-12 11:33:01,475 epoch 27 - iter 14/25 - loss 0.44027196 - samples/sec: 42.62 - lr: 0.100000\n",
            "2022-12-12 11:33:02,407 epoch 27 - iter 16/25 - loss 0.43671881 - samples/sec: 68.71 - lr: 0.100000\n",
            "2022-12-12 11:33:03,480 epoch 27 - iter 18/25 - loss 0.43317140 - samples/sec: 59.74 - lr: 0.100000\n",
            "2022-12-12 11:33:04,434 epoch 27 - iter 20/25 - loss 0.43651885 - samples/sec: 67.15 - lr: 0.100000\n",
            "2022-12-12 11:33:05,407 epoch 27 - iter 22/25 - loss 0.43927745 - samples/sec: 65.84 - lr: 0.100000\n",
            "2022-12-12 11:33:07,974 epoch 27 - iter 24/25 - loss 0.44261356 - samples/sec: 24.94 - lr: 0.100000\n",
            "2022-12-12 11:33:08,042 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:33:08,043 EPOCH 27 done: loss 0.4418 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:33:08,486 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:33:08,494 DEV : loss 0.3372529149055481 - f1-score (micro avg)  0.5736\n",
            "2022-12-12 11:33:08,502 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:33:08,505 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:33:08,922 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:33:09,871 epoch 28 - iter 2/25 - loss 0.35495834 - samples/sec: 67.56 - lr: 0.100000\n",
            "2022-12-12 11:33:10,876 epoch 28 - iter 4/25 - loss 0.36684311 - samples/sec: 63.81 - lr: 0.100000\n",
            "2022-12-12 11:33:11,877 epoch 28 - iter 6/25 - loss 0.38145744 - samples/sec: 63.99 - lr: 0.100000\n",
            "2022-12-12 11:33:12,626 epoch 28 - iter 8/25 - loss 0.38562831 - samples/sec: 85.59 - lr: 0.100000\n",
            "2022-12-12 11:33:14,791 epoch 28 - iter 10/25 - loss 0.39188321 - samples/sec: 29.58 - lr: 0.100000\n",
            "2022-12-12 11:33:15,813 epoch 28 - iter 12/25 - loss 0.39801591 - samples/sec: 62.71 - lr: 0.100000\n",
            "2022-12-12 11:33:17,036 epoch 28 - iter 14/25 - loss 0.40681190 - samples/sec: 52.38 - lr: 0.100000\n",
            "2022-12-12 11:33:17,813 epoch 28 - iter 16/25 - loss 0.40525963 - samples/sec: 82.52 - lr: 0.100000\n",
            "2022-12-12 11:33:18,803 epoch 28 - iter 18/25 - loss 0.41168658 - samples/sec: 64.70 - lr: 0.100000\n",
            "2022-12-12 11:33:19,959 epoch 28 - iter 20/25 - loss 0.40873385 - samples/sec: 55.43 - lr: 0.100000\n",
            "2022-12-12 11:33:20,826 epoch 28 - iter 22/25 - loss 0.41100766 - samples/sec: 73.95 - lr: 0.100000\n",
            "2022-12-12 11:33:22,000 epoch 28 - iter 24/25 - loss 0.41090777 - samples/sec: 54.56 - lr: 0.100000\n",
            "2022-12-12 11:33:22,085 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:33:22,086 EPOCH 28 done: loss 0.4105 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:33:22,544 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:33:22,553 DEV : loss 0.3261798620223999 - f1-score (micro avg)  0.5781\n",
            "2022-12-12 11:33:22,562 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:33:22,564 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:33:23,112 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:33:24,170 epoch 29 - iter 2/25 - loss 0.40067398 - samples/sec: 60.63 - lr: 0.100000\n",
            "2022-12-12 11:33:25,090 epoch 29 - iter 4/25 - loss 0.42488294 - samples/sec: 69.67 - lr: 0.100000\n",
            "2022-12-12 11:33:25,930 epoch 29 - iter 6/25 - loss 0.40488731 - samples/sec: 76.22 - lr: 0.100000\n",
            "2022-12-12 11:33:26,790 epoch 29 - iter 8/25 - loss 0.41027640 - samples/sec: 74.58 - lr: 0.100000\n",
            "2022-12-12 11:33:27,759 epoch 29 - iter 10/25 - loss 0.40215397 - samples/sec: 66.13 - lr: 0.100000\n",
            "2022-12-12 11:33:30,196 epoch 29 - iter 12/25 - loss 0.39878665 - samples/sec: 26.28 - lr: 0.100000\n",
            "2022-12-12 11:33:31,337 epoch 29 - iter 14/25 - loss 0.39393484 - samples/sec: 56.15 - lr: 0.100000\n",
            "2022-12-12 11:33:32,733 epoch 29 - iter 16/25 - loss 0.39843245 - samples/sec: 45.90 - lr: 0.100000\n",
            "2022-12-12 11:33:33,461 epoch 29 - iter 18/25 - loss 0.40068844 - samples/sec: 88.14 - lr: 0.100000\n",
            "2022-12-12 11:33:34,345 epoch 29 - iter 20/25 - loss 0.40320740 - samples/sec: 72.45 - lr: 0.100000\n",
            "2022-12-12 11:33:35,394 epoch 29 - iter 22/25 - loss 0.40360326 - samples/sec: 61.12 - lr: 0.100000\n",
            "2022-12-12 11:33:36,540 epoch 29 - iter 24/25 - loss 0.40428078 - samples/sec: 55.93 - lr: 0.100000\n",
            "2022-12-12 11:33:36,601 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:33:36,602 EPOCH 29 done: loss 0.4041 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:33:37,038 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:33:37,045 DEV : loss 0.38586798310279846 - f1-score (micro avg)  0.5321\n",
            "2022-12-12 11:33:37,054 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:33:37,055 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:33:37,973 epoch 30 - iter 2/25 - loss 0.47367811 - samples/sec: 69.85 - lr: 0.100000\n",
            "2022-12-12 11:33:38,878 epoch 30 - iter 4/25 - loss 0.40876809 - samples/sec: 70.83 - lr: 0.100000\n",
            "2022-12-12 11:33:40,045 epoch 30 - iter 6/25 - loss 0.41779087 - samples/sec: 54.89 - lr: 0.100000\n",
            "2022-12-12 11:33:42,323 epoch 30 - iter 8/25 - loss 0.41223543 - samples/sec: 28.11 - lr: 0.100000\n",
            "2022-12-12 11:33:43,418 epoch 30 - iter 10/25 - loss 0.41497179 - samples/sec: 58.55 - lr: 0.100000\n",
            "2022-12-12 11:33:44,655 epoch 30 - iter 12/25 - loss 0.40967462 - samples/sec: 51.84 - lr: 0.100000\n",
            "2022-12-12 11:33:45,642 epoch 30 - iter 14/25 - loss 0.41441093 - samples/sec: 64.91 - lr: 0.100000\n",
            "2022-12-12 11:33:46,887 epoch 30 - iter 16/25 - loss 0.40949759 - samples/sec: 51.47 - lr: 0.100000\n",
            "2022-12-12 11:33:48,020 epoch 30 - iter 18/25 - loss 0.40468049 - samples/sec: 56.53 - lr: 0.100000\n",
            "2022-12-12 11:33:49,044 epoch 30 - iter 20/25 - loss 0.40408767 - samples/sec: 62.56 - lr: 0.100000\n",
            "2022-12-12 11:33:50,082 epoch 30 - iter 22/25 - loss 0.40240102 - samples/sec: 61.76 - lr: 0.100000\n",
            "2022-12-12 11:33:51,439 epoch 30 - iter 24/25 - loss 0.40211125 - samples/sec: 47.21 - lr: 0.100000\n",
            "2022-12-12 11:33:51,500 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:33:51,501 EPOCH 30 done: loss 0.4018 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:33:51,944 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:33:51,951 DEV : loss 0.32165244221687317 - f1-score (micro avg)  0.5844\n",
            "2022-12-12 11:33:51,960 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:33:51,962 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:33:52,436 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:33:53,290 epoch 31 - iter 2/25 - loss 0.37943778 - samples/sec: 75.22 - lr: 0.100000\n",
            "2022-12-12 11:33:54,122 epoch 31 - iter 4/25 - loss 0.39473122 - samples/sec: 77.05 - lr: 0.100000\n",
            "2022-12-12 11:33:55,034 epoch 31 - iter 6/25 - loss 0.40952967 - samples/sec: 70.25 - lr: 0.100000\n",
            "2022-12-12 11:33:55,864 epoch 31 - iter 8/25 - loss 0.40540754 - samples/sec: 77.26 - lr: 0.100000\n",
            "2022-12-12 11:33:57,028 epoch 31 - iter 10/25 - loss 0.42086796 - samples/sec: 55.07 - lr: 0.100000\n",
            "2022-12-12 11:33:59,100 epoch 31 - iter 12/25 - loss 0.40925268 - samples/sec: 30.89 - lr: 0.100000\n",
            "2022-12-12 11:34:00,284 epoch 31 - iter 14/25 - loss 0.41727290 - samples/sec: 54.16 - lr: 0.100000\n",
            "2022-12-12 11:34:01,433 epoch 31 - iter 16/25 - loss 0.41270581 - samples/sec: 55.75 - lr: 0.100000\n",
            "2022-12-12 11:34:02,626 epoch 31 - iter 18/25 - loss 0.41326295 - samples/sec: 53.70 - lr: 0.100000\n",
            "2022-12-12 11:34:04,179 epoch 31 - iter 20/25 - loss 0.40787888 - samples/sec: 41.26 - lr: 0.100000\n",
            "2022-12-12 11:34:05,636 epoch 31 - iter 22/25 - loss 0.41301342 - samples/sec: 43.96 - lr: 0.100000\n",
            "2022-12-12 11:34:06,833 epoch 31 - iter 24/25 - loss 0.40506967 - samples/sec: 53.52 - lr: 0.100000\n",
            "2022-12-12 11:34:06,907 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:34:06,908 EPOCH 31 done: loss 0.4052 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:34:07,434 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:34:07,441 DEV : loss 0.3821359872817993 - f1-score (micro avg)  0.5388\n",
            "2022-12-12 11:34:07,449 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:34:07,451 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:34:08,386 epoch 32 - iter 2/25 - loss 0.44633669 - samples/sec: 68.57 - lr: 0.100000\n",
            "2022-12-12 11:34:09,272 epoch 32 - iter 4/25 - loss 0.41765897 - samples/sec: 72.28 - lr: 0.100000\n",
            "2022-12-12 11:34:11,796 epoch 32 - iter 6/25 - loss 0.42019119 - samples/sec: 25.37 - lr: 0.100000\n",
            "2022-12-12 11:34:12,936 epoch 32 - iter 8/25 - loss 0.41510868 - samples/sec: 56.23 - lr: 0.100000\n",
            "2022-12-12 11:34:14,030 epoch 32 - iter 10/25 - loss 0.41037564 - samples/sec: 58.57 - lr: 0.100000\n",
            "2022-12-12 11:34:15,255 epoch 32 - iter 12/25 - loss 0.41040095 - samples/sec: 52.28 - lr: 0.100000\n",
            "2022-12-12 11:34:16,262 epoch 32 - iter 14/25 - loss 0.41213721 - samples/sec: 63.68 - lr: 0.100000\n",
            "2022-12-12 11:34:17,187 epoch 32 - iter 16/25 - loss 0.40687308 - samples/sec: 69.29 - lr: 0.100000\n",
            "2022-12-12 11:34:18,109 epoch 32 - iter 18/25 - loss 0.41118507 - samples/sec: 69.49 - lr: 0.100000\n",
            "2022-12-12 11:34:19,550 epoch 32 - iter 20/25 - loss 0.40378058 - samples/sec: 44.46 - lr: 0.100000\n",
            "2022-12-12 11:34:20,437 epoch 32 - iter 22/25 - loss 0.40147941 - samples/sec: 72.23 - lr: 0.100000\n",
            "2022-12-12 11:34:21,537 epoch 32 - iter 24/25 - loss 0.40076683 - samples/sec: 58.23 - lr: 0.100000\n",
            "2022-12-12 11:34:21,625 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:34:21,626 EPOCH 32 done: loss 0.4003 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:34:22,077 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:34:22,086 DEV : loss 0.3108314871788025 - f1-score (micro avg)  0.5965\n",
            "2022-12-12 11:34:22,094 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:34:22,095 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:34:22,575 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:34:23,605 epoch 33 - iter 2/25 - loss 0.36760130 - samples/sec: 62.27 - lr: 0.100000\n",
            "2022-12-12 11:34:24,817 epoch 33 - iter 4/25 - loss 0.39577489 - samples/sec: 52.86 - lr: 0.100000\n",
            "2022-12-12 11:34:25,962 epoch 33 - iter 6/25 - loss 0.40163149 - samples/sec: 55.97 - lr: 0.100000\n",
            "2022-12-12 11:34:26,943 epoch 33 - iter 8/25 - loss 0.39076258 - samples/sec: 65.33 - lr: 0.100000\n",
            "2022-12-12 11:34:27,994 epoch 33 - iter 10/25 - loss 0.39639807 - samples/sec: 60.98 - lr: 0.100000\n",
            "2022-12-12 11:34:30,288 epoch 33 - iter 12/25 - loss 0.39137025 - samples/sec: 27.91 - lr: 0.100000\n",
            "2022-12-12 11:34:31,550 epoch 33 - iter 14/25 - loss 0.39550428 - samples/sec: 50.77 - lr: 0.100000\n",
            "2022-12-12 11:34:32,407 epoch 33 - iter 16/25 - loss 0.39055534 - samples/sec: 74.85 - lr: 0.100000\n",
            "2022-12-12 11:34:33,228 epoch 33 - iter 18/25 - loss 0.38908714 - samples/sec: 78.07 - lr: 0.100000\n",
            "2022-12-12 11:34:34,377 epoch 33 - iter 20/25 - loss 0.38100734 - samples/sec: 55.77 - lr: 0.100000\n",
            "2022-12-12 11:34:35,524 epoch 33 - iter 22/25 - loss 0.38680694 - samples/sec: 55.85 - lr: 0.100000\n",
            "2022-12-12 11:34:36,833 epoch 33 - iter 24/25 - loss 0.38530313 - samples/sec: 48.94 - lr: 0.100000\n",
            "2022-12-12 11:34:36,915 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:34:36,916 EPOCH 33 done: loss 0.3845 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:34:37,356 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:34:37,364 DEV : loss 0.317490816116333 - f1-score (micro avg)  0.5832\n",
            "2022-12-12 11:34:37,373 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:34:37,374 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:34:38,373 epoch 34 - iter 2/25 - loss 0.40280087 - samples/sec: 64.16 - lr: 0.100000\n",
            "2022-12-12 11:34:39,543 epoch 34 - iter 4/25 - loss 0.34890010 - samples/sec: 54.76 - lr: 0.100000\n",
            "2022-12-12 11:34:40,380 epoch 34 - iter 6/25 - loss 0.35392980 - samples/sec: 76.62 - lr: 0.100000\n",
            "2022-12-12 11:34:41,651 epoch 34 - iter 8/25 - loss 0.35147374 - samples/sec: 50.41 - lr: 0.100000\n",
            "2022-12-12 11:34:42,939 epoch 34 - iter 10/25 - loss 0.36000627 - samples/sec: 49.72 - lr: 0.100000\n",
            "2022-12-12 11:34:44,061 epoch 34 - iter 12/25 - loss 0.36886692 - samples/sec: 57.19 - lr: 0.100000\n",
            "2022-12-12 11:34:45,121 epoch 34 - iter 14/25 - loss 0.37576679 - samples/sec: 60.48 - lr: 0.100000\n",
            "2022-12-12 11:34:46,351 epoch 34 - iter 16/25 - loss 0.37232563 - samples/sec: 52.06 - lr: 0.100000\n",
            "2022-12-12 11:34:47,275 epoch 34 - iter 18/25 - loss 0.37171578 - samples/sec: 69.39 - lr: 0.100000\n",
            "2022-12-12 11:34:48,640 epoch 34 - iter 20/25 - loss 0.37007192 - samples/sec: 46.95 - lr: 0.100000\n",
            "2022-12-12 11:34:50,852 epoch 34 - iter 22/25 - loss 0.37002062 - samples/sec: 28.94 - lr: 0.100000\n",
            "2022-12-12 11:34:51,824 epoch 34 - iter 24/25 - loss 0.37348107 - samples/sec: 65.95 - lr: 0.100000\n",
            "2022-12-12 11:34:51,898 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:34:51,899 EPOCH 34 done: loss 0.3734 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:34:52,349 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:34:52,357 DEV : loss 0.33128082752227783 - f1-score (micro avg)  0.5976\n",
            "2022-12-12 11:34:52,366 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:34:52,368 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:34:52,878 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:34:54,085 epoch 35 - iter 2/25 - loss 0.34041374 - samples/sec: 53.08 - lr: 0.100000\n",
            "2022-12-12 11:34:55,072 epoch 35 - iter 4/25 - loss 0.34421829 - samples/sec: 64.92 - lr: 0.100000\n",
            "2022-12-12 11:34:56,126 epoch 35 - iter 6/25 - loss 0.35773450 - samples/sec: 60.84 - lr: 0.100000\n",
            "2022-12-12 11:34:57,184 epoch 35 - iter 8/25 - loss 0.36702830 - samples/sec: 60.59 - lr: 0.100000\n",
            "2022-12-12 11:34:58,143 epoch 35 - iter 10/25 - loss 0.37641591 - samples/sec: 66.78 - lr: 0.100000\n",
            "2022-12-12 11:34:59,457 epoch 35 - iter 12/25 - loss 0.37865729 - samples/sec: 48.76 - lr: 0.100000\n",
            "2022-12-12 11:35:00,559 epoch 35 - iter 14/25 - loss 0.37057689 - samples/sec: 58.18 - lr: 0.100000\n",
            "2022-12-12 11:35:01,659 epoch 35 - iter 16/25 - loss 0.37067197 - samples/sec: 58.23 - lr: 0.100000\n",
            "2022-12-12 11:35:02,759 epoch 35 - iter 18/25 - loss 0.37078436 - samples/sec: 58.25 - lr: 0.100000\n",
            "2022-12-12 11:35:04,901 epoch 35 - iter 20/25 - loss 0.36843950 - samples/sec: 29.90 - lr: 0.100000\n",
            "2022-12-12 11:35:05,910 epoch 35 - iter 22/25 - loss 0.37353631 - samples/sec: 63.51 - lr: 0.100000\n",
            "2022-12-12 11:35:06,951 epoch 35 - iter 24/25 - loss 0.37430493 - samples/sec: 61.56 - lr: 0.100000\n",
            "2022-12-12 11:35:07,034 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:35:07,035 EPOCH 35 done: loss 0.3741 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:35:07,550 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:35:07,557 DEV : loss 0.3163817226886749 - f1-score (micro avg)  0.6131\n",
            "2022-12-12 11:35:07,565 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:35:07,566 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:35:08,002 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:35:09,033 epoch 36 - iter 2/25 - loss 0.35699542 - samples/sec: 62.22 - lr: 0.100000\n",
            "2022-12-12 11:35:09,908 epoch 36 - iter 4/25 - loss 0.34357163 - samples/sec: 73.27 - lr: 0.100000\n",
            "2022-12-12 11:35:10,856 epoch 36 - iter 6/25 - loss 0.36338654 - samples/sec: 67.56 - lr: 0.100000\n",
            "2022-12-12 11:35:11,795 epoch 36 - iter 8/25 - loss 0.36698239 - samples/sec: 68.24 - lr: 0.100000\n",
            "2022-12-12 11:35:12,725 epoch 36 - iter 10/25 - loss 0.36773971 - samples/sec: 68.92 - lr: 0.100000\n",
            "2022-12-12 11:35:13,784 epoch 36 - iter 12/25 - loss 0.37457903 - samples/sec: 60.49 - lr: 0.100000\n",
            "2022-12-12 11:35:14,791 epoch 36 - iter 14/25 - loss 0.36465007 - samples/sec: 63.69 - lr: 0.100000\n",
            "2022-12-12 11:35:17,163 epoch 36 - iter 16/25 - loss 0.37061728 - samples/sec: 27.00 - lr: 0.100000\n",
            "2022-12-12 11:35:18,065 epoch 36 - iter 18/25 - loss 0.36886624 - samples/sec: 71.04 - lr: 0.100000\n",
            "2022-12-12 11:35:19,171 epoch 36 - iter 20/25 - loss 0.36541938 - samples/sec: 57.94 - lr: 0.100000\n",
            "2022-12-12 11:35:20,405 epoch 36 - iter 22/25 - loss 0.36754465 - samples/sec: 51.93 - lr: 0.100000\n",
            "2022-12-12 11:35:21,695 epoch 36 - iter 24/25 - loss 0.37111394 - samples/sec: 49.67 - lr: 0.100000\n",
            "2022-12-12 11:35:21,828 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:35:21,829 EPOCH 36 done: loss 0.3711 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  6.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:35:22,414 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:35:22,424 DEV : loss 0.2966867685317993 - f1-score (micro avg)  0.5994\n",
            "2022-12-12 11:35:22,432 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:35:22,434 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:35:23,513 epoch 37 - iter 2/25 - loss 0.35912048 - samples/sec: 59.36 - lr: 0.100000\n",
            "2022-12-12 11:35:24,522 epoch 37 - iter 4/25 - loss 0.36039891 - samples/sec: 63.53 - lr: 0.100000\n",
            "2022-12-12 11:35:25,886 epoch 37 - iter 6/25 - loss 0.37418766 - samples/sec: 46.97 - lr: 0.100000\n",
            "2022-12-12 11:35:27,149 epoch 37 - iter 8/25 - loss 0.37123851 - samples/sec: 50.75 - lr: 0.100000\n",
            "2022-12-12 11:35:28,210 epoch 37 - iter 10/25 - loss 0.36781087 - samples/sec: 60.43 - lr: 0.100000\n",
            "2022-12-12 11:35:29,343 epoch 37 - iter 12/25 - loss 0.36487833 - samples/sec: 56.55 - lr: 0.100000\n",
            "2022-12-12 11:35:30,407 epoch 37 - iter 14/25 - loss 0.36591990 - samples/sec: 60.26 - lr: 0.100000\n",
            "2022-12-12 11:35:31,653 epoch 37 - iter 16/25 - loss 0.36299050 - samples/sec: 51.41 - lr: 0.100000\n",
            "2022-12-12 11:35:32,714 epoch 37 - iter 18/25 - loss 0.36671340 - samples/sec: 60.42 - lr: 0.100000\n",
            "2022-12-12 11:35:33,783 epoch 37 - iter 20/25 - loss 0.36434240 - samples/sec: 59.98 - lr: 0.100000\n",
            "2022-12-12 11:35:35,911 epoch 37 - iter 22/25 - loss 0.36355920 - samples/sec: 30.09 - lr: 0.100000\n",
            "2022-12-12 11:35:36,796 epoch 37 - iter 24/25 - loss 0.36446908 - samples/sec: 72.41 - lr: 0.100000\n",
            "2022-12-12 11:35:36,867 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:35:36,868 EPOCH 37 done: loss 0.3649 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:35:37,325 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:35:37,335 DEV : loss 0.30230945348739624 - f1-score (micro avg)  0.5857\n",
            "2022-12-12 11:35:37,343 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:35:37,345 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:35:38,118 epoch 38 - iter 2/25 - loss 0.37470740 - samples/sec: 82.95 - lr: 0.100000\n",
            "2022-12-12 11:35:39,097 epoch 38 - iter 4/25 - loss 0.35720657 - samples/sec: 65.49 - lr: 0.100000\n",
            "2022-12-12 11:35:40,306 epoch 38 - iter 6/25 - loss 0.36046124 - samples/sec: 52.98 - lr: 0.100000\n",
            "2022-12-12 11:35:41,227 epoch 38 - iter 8/25 - loss 0.36492979 - samples/sec: 69.59 - lr: 0.100000\n",
            "2022-12-12 11:35:42,284 epoch 38 - iter 10/25 - loss 0.36766712 - samples/sec: 60.61 - lr: 0.100000\n",
            "2022-12-12 11:35:44,778 epoch 38 - iter 12/25 - loss 0.36333344 - samples/sec: 25.68 - lr: 0.100000\n",
            "2022-12-12 11:35:45,711 epoch 38 - iter 14/25 - loss 0.36496376 - samples/sec: 68.67 - lr: 0.100000\n",
            "2022-12-12 11:35:47,133 epoch 38 - iter 16/25 - loss 0.36299318 - samples/sec: 45.04 - lr: 0.100000\n",
            "2022-12-12 11:35:47,964 epoch 38 - iter 18/25 - loss 0.36382262 - samples/sec: 77.14 - lr: 0.100000\n",
            "2022-12-12 11:35:48,876 epoch 38 - iter 20/25 - loss 0.36209962 - samples/sec: 70.37 - lr: 0.100000\n",
            "2022-12-12 11:35:49,814 epoch 38 - iter 22/25 - loss 0.35972441 - samples/sec: 68.33 - lr: 0.100000\n",
            "2022-12-12 11:35:50,987 epoch 38 - iter 24/25 - loss 0.36232605 - samples/sec: 54.60 - lr: 0.100000\n",
            "2022-12-12 11:35:51,061 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:35:51,062 EPOCH 38 done: loss 0.3625 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:35:51,544 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:35:51,552 DEV : loss 0.31106799840927124 - f1-score (micro avg)  0.609\n",
            "2022-12-12 11:35:51,560 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 11:35:51,561 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:35:53,922 epoch 39 - iter 2/25 - loss 0.34211013 - samples/sec: 27.11 - lr: 0.100000\n",
            "2022-12-12 11:35:54,723 epoch 39 - iter 4/25 - loss 0.34698024 - samples/sec: 80.04 - lr: 0.100000\n",
            "2022-12-12 11:35:55,755 epoch 39 - iter 6/25 - loss 0.36631662 - samples/sec: 62.07 - lr: 0.100000\n",
            "2022-12-12 11:35:56,917 epoch 39 - iter 8/25 - loss 0.36645677 - samples/sec: 55.15 - lr: 0.100000\n",
            "2022-12-12 11:35:57,961 epoch 39 - iter 10/25 - loss 0.34991072 - samples/sec: 61.39 - lr: 0.100000\n",
            "2022-12-12 11:35:58,957 epoch 39 - iter 12/25 - loss 0.35655218 - samples/sec: 64.40 - lr: 0.100000\n",
            "2022-12-12 11:35:59,916 epoch 39 - iter 14/25 - loss 0.35632387 - samples/sec: 66.81 - lr: 0.100000\n",
            "2022-12-12 11:36:00,898 epoch 39 - iter 16/25 - loss 0.35238938 - samples/sec: 65.27 - lr: 0.100000\n",
            "2022-12-12 11:36:02,035 epoch 39 - iter 18/25 - loss 0.35487819 - samples/sec: 56.37 - lr: 0.100000\n",
            "2022-12-12 11:36:03,167 epoch 39 - iter 20/25 - loss 0.35244468 - samples/sec: 56.60 - lr: 0.100000\n",
            "2022-12-12 11:36:04,038 epoch 39 - iter 22/25 - loss 0.34893890 - samples/sec: 73.56 - lr: 0.100000\n",
            "2022-12-12 11:36:04,973 epoch 39 - iter 24/25 - loss 0.34926232 - samples/sec: 68.56 - lr: 0.100000\n",
            "2022-12-12 11:36:05,029 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:36:05,030 EPOCH 39 done: loss 0.3497 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:36:05,450 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:36:05,461 DEV : loss 0.32281503081321716 - f1-score (micro avg)  0.5946\n",
            "2022-12-12 11:36:05,469 Epoch    39: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2022-12-12 11:36:05,471 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 11:36:05,472 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:36:06,367 epoch 40 - iter 2/25 - loss 0.34998604 - samples/sec: 71.66 - lr: 0.050000\n",
            "2022-12-12 11:36:07,227 epoch 40 - iter 4/25 - loss 0.36194138 - samples/sec: 74.47 - lr: 0.050000\n",
            "2022-12-12 11:36:08,493 epoch 40 - iter 6/25 - loss 0.35963316 - samples/sec: 50.62 - lr: 0.050000\n",
            "2022-12-12 11:36:09,507 epoch 40 - iter 8/25 - loss 0.35603629 - samples/sec: 63.16 - lr: 0.050000\n",
            "2022-12-12 11:36:10,345 epoch 40 - iter 10/25 - loss 0.35350377 - samples/sec: 76.55 - lr: 0.050000\n",
            "2022-12-12 11:36:11,488 epoch 40 - iter 12/25 - loss 0.34352791 - samples/sec: 56.07 - lr: 0.050000\n",
            "2022-12-12 11:36:12,828 epoch 40 - iter 14/25 - loss 0.33843152 - samples/sec: 47.79 - lr: 0.050000\n",
            "2022-12-12 11:36:15,199 epoch 40 - iter 16/25 - loss 0.33616334 - samples/sec: 27.01 - lr: 0.050000\n",
            "2022-12-12 11:36:16,117 epoch 40 - iter 18/25 - loss 0.33581410 - samples/sec: 69.80 - lr: 0.050000\n",
            "2022-12-12 11:36:17,027 epoch 40 - iter 20/25 - loss 0.33429096 - samples/sec: 70.44 - lr: 0.050000\n",
            "2022-12-12 11:36:18,252 epoch 40 - iter 22/25 - loss 0.33045215 - samples/sec: 52.32 - lr: 0.050000\n",
            "2022-12-12 11:36:19,120 epoch 40 - iter 24/25 - loss 0.33164380 - samples/sec: 73.88 - lr: 0.050000\n",
            "2022-12-12 11:36:19,203 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:36:19,204 EPOCH 40 done: loss 0.3309 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:36:19,653 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:36:19,662 DEV : loss 0.28660207986831665 - f1-score (micro avg)  0.614\n",
            "2022-12-12 11:36:19,670 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:36:19,672 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:36:20,123 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:36:22,241 epoch 41 - iter 2/25 - loss 0.31392754 - samples/sec: 30.24 - lr: 0.050000\n",
            "2022-12-12 11:36:23,406 epoch 41 - iter 4/25 - loss 0.31053089 - samples/sec: 55.00 - lr: 0.050000\n",
            "2022-12-12 11:36:24,486 epoch 41 - iter 6/25 - loss 0.32119387 - samples/sec: 59.34 - lr: 0.050000\n",
            "2022-12-12 11:36:25,335 epoch 41 - iter 8/25 - loss 0.33297264 - samples/sec: 75.42 - lr: 0.050000\n",
            "2022-12-12 11:36:26,606 epoch 41 - iter 10/25 - loss 0.33726380 - samples/sec: 50.43 - lr: 0.050000\n",
            "2022-12-12 11:36:27,604 epoch 41 - iter 12/25 - loss 0.34121126 - samples/sec: 64.19 - lr: 0.050000\n",
            "2022-12-12 11:36:28,694 epoch 41 - iter 14/25 - loss 0.34324128 - samples/sec: 58.77 - lr: 0.050000\n",
            "2022-12-12 11:36:29,888 epoch 41 - iter 16/25 - loss 0.34057344 - samples/sec: 53.68 - lr: 0.050000\n",
            "2022-12-12 11:36:30,888 epoch 41 - iter 18/25 - loss 0.34118292 - samples/sec: 64.08 - lr: 0.050000\n",
            "2022-12-12 11:36:31,850 epoch 41 - iter 20/25 - loss 0.33779667 - samples/sec: 66.64 - lr: 0.050000\n",
            "2022-12-12 11:36:32,833 epoch 41 - iter 22/25 - loss 0.33576717 - samples/sec: 65.18 - lr: 0.050000\n",
            "2022-12-12 11:36:33,930 epoch 41 - iter 24/25 - loss 0.33860583 - samples/sec: 58.42 - lr: 0.050000\n",
            "2022-12-12 11:36:34,010 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:36:34,012 EPOCH 41 done: loss 0.3388 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:36:34,451 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:36:34,458 DEV : loss 0.298443466424942 - f1-score (micro avg)  0.6188\n",
            "2022-12-12 11:36:34,467 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:36:34,469 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:36:34,900 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:36:36,209 epoch 42 - iter 2/25 - loss 0.29969988 - samples/sec: 48.97 - lr: 0.050000\n",
            "2022-12-12 11:36:37,255 epoch 42 - iter 4/25 - loss 0.30842767 - samples/sec: 61.27 - lr: 0.050000\n",
            "2022-12-12 11:36:38,253 epoch 42 - iter 6/25 - loss 0.30705164 - samples/sec: 64.23 - lr: 0.050000\n",
            "2022-12-12 11:36:39,326 epoch 42 - iter 8/25 - loss 0.31140934 - samples/sec: 59.71 - lr: 0.050000\n",
            "2022-12-12 11:36:40,509 epoch 42 - iter 10/25 - loss 0.32474301 - samples/sec: 54.13 - lr: 0.050000\n",
            "2022-12-12 11:36:41,377 epoch 42 - iter 12/25 - loss 0.32585705 - samples/sec: 73.87 - lr: 0.050000\n",
            "2022-12-12 11:36:42,624 epoch 42 - iter 14/25 - loss 0.33282158 - samples/sec: 51.40 - lr: 0.050000\n",
            "2022-12-12 11:36:43,411 epoch 42 - iter 16/25 - loss 0.33155065 - samples/sec: 81.48 - lr: 0.050000\n",
            "2022-12-12 11:36:45,823 epoch 42 - iter 18/25 - loss 0.33150921 - samples/sec: 26.54 - lr: 0.050000\n",
            "2022-12-12 11:36:47,007 epoch 42 - iter 20/25 - loss 0.33168361 - samples/sec: 54.14 - lr: 0.050000\n",
            "2022-12-12 11:36:48,194 epoch 42 - iter 22/25 - loss 0.32907250 - samples/sec: 53.97 - lr: 0.050000\n",
            "2022-12-12 11:36:48,939 epoch 42 - iter 24/25 - loss 0.32320238 - samples/sec: 86.07 - lr: 0.050000\n",
            "2022-12-12 11:36:48,997 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:36:48,998 EPOCH 42 done: loss 0.3229 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:36:49,430 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:36:49,437 DEV : loss 0.30214735865592957 - f1-score (micro avg)  0.6174\n",
            "2022-12-12 11:36:49,446 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:36:49,447 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:36:50,649 epoch 43 - iter 2/25 - loss 0.36587240 - samples/sec: 53.29 - lr: 0.050000\n",
            "2022-12-12 11:36:51,894 epoch 43 - iter 4/25 - loss 0.32132716 - samples/sec: 51.46 - lr: 0.050000\n",
            "2022-12-12 11:36:53,139 epoch 43 - iter 6/25 - loss 0.32785332 - samples/sec: 51.48 - lr: 0.050000\n",
            "2022-12-12 11:36:54,116 epoch 43 - iter 8/25 - loss 0.33555291 - samples/sec: 65.63 - lr: 0.050000\n",
            "2022-12-12 11:36:55,092 epoch 43 - iter 10/25 - loss 0.33441474 - samples/sec: 65.63 - lr: 0.050000\n",
            "2022-12-12 11:36:56,204 epoch 43 - iter 12/25 - loss 0.33648683 - samples/sec: 57.65 - lr: 0.050000\n",
            "2022-12-12 11:36:57,200 epoch 43 - iter 14/25 - loss 0.32453930 - samples/sec: 64.28 - lr: 0.050000\n",
            "2022-12-12 11:36:58,238 epoch 43 - iter 16/25 - loss 0.32527576 - samples/sec: 61.75 - lr: 0.050000\n",
            "2022-12-12 11:36:59,440 epoch 43 - iter 18/25 - loss 0.32303484 - samples/sec: 53.35 - lr: 0.050000\n",
            "2022-12-12 11:37:00,369 epoch 43 - iter 20/25 - loss 0.32694170 - samples/sec: 68.95 - lr: 0.050000\n",
            "2022-12-12 11:37:02,623 epoch 43 - iter 22/25 - loss 0.32484044 - samples/sec: 28.42 - lr: 0.050000\n",
            "2022-12-12 11:37:03,687 epoch 43 - iter 24/25 - loss 0.32470068 - samples/sec: 60.21 - lr: 0.050000\n",
            "2022-12-12 11:37:03,781 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:37:03,782 EPOCH 43 done: loss 0.3240 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:37:04,232 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:37:04,239 DEV : loss 0.2766439914703369 - f1-score (micro avg)  0.6244\n",
            "2022-12-12 11:37:04,251 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:37:04,253 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:37:04,695 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:37:05,458 epoch 44 - iter 2/25 - loss 0.34966459 - samples/sec: 84.13 - lr: 0.050000\n",
            "2022-12-12 11:37:06,529 epoch 44 - iter 4/25 - loss 0.33821786 - samples/sec: 59.80 - lr: 0.050000\n",
            "2022-12-12 11:37:07,536 epoch 44 - iter 6/25 - loss 0.31786741 - samples/sec: 63.65 - lr: 0.050000\n",
            "2022-12-12 11:37:08,878 epoch 44 - iter 8/25 - loss 0.33905592 - samples/sec: 47.74 - lr: 0.050000\n",
            "2022-12-12 11:37:11,328 epoch 44 - iter 10/25 - loss 0.34123658 - samples/sec: 26.14 - lr: 0.050000\n",
            "2022-12-12 11:37:12,478 epoch 44 - iter 12/25 - loss 0.34192291 - samples/sec: 55.73 - lr: 0.050000\n",
            "2022-12-12 11:37:13,838 epoch 44 - iter 14/25 - loss 0.33733951 - samples/sec: 47.10 - lr: 0.050000\n",
            "2022-12-12 11:37:14,856 epoch 44 - iter 16/25 - loss 0.33221895 - samples/sec: 62.99 - lr: 0.050000\n",
            "2022-12-12 11:37:15,803 epoch 44 - iter 18/25 - loss 0.33320576 - samples/sec: 67.65 - lr: 0.050000\n",
            "2022-12-12 11:37:16,890 epoch 44 - iter 20/25 - loss 0.33242066 - samples/sec: 58.96 - lr: 0.050000\n",
            "2022-12-12 11:37:17,809 epoch 44 - iter 22/25 - loss 0.32630127 - samples/sec: 69.77 - lr: 0.050000\n",
            "2022-12-12 11:37:18,843 epoch 44 - iter 24/25 - loss 0.32932064 - samples/sec: 61.95 - lr: 0.050000\n",
            "2022-12-12 11:37:18,918 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:37:18,919 EPOCH 44 done: loss 0.3289 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:37:19,386 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:37:19,396 DEV : loss 0.28180190920829773 - f1-score (micro avg)  0.6212\n",
            "2022-12-12 11:37:19,404 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:37:19,406 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:37:20,395 epoch 45 - iter 2/25 - loss 0.34549603 - samples/sec: 64.79 - lr: 0.050000\n",
            "2022-12-12 11:37:21,341 epoch 45 - iter 4/25 - loss 0.32562048 - samples/sec: 67.73 - lr: 0.050000\n",
            "2022-12-12 11:37:22,274 epoch 45 - iter 6/25 - loss 0.30718237 - samples/sec: 68.71 - lr: 0.050000\n",
            "2022-12-12 11:37:23,475 epoch 45 - iter 8/25 - loss 0.31711641 - samples/sec: 53.32 - lr: 0.050000\n",
            "2022-12-12 11:37:24,804 epoch 45 - iter 10/25 - loss 0.31367892 - samples/sec: 48.22 - lr: 0.050000\n",
            "2022-12-12 11:37:27,202 epoch 45 - iter 12/25 - loss 0.30982038 - samples/sec: 26.70 - lr: 0.050000\n",
            "2022-12-12 11:37:28,240 epoch 45 - iter 14/25 - loss 0.32718569 - samples/sec: 61.79 - lr: 0.050000\n",
            "2022-12-12 11:37:29,177 epoch 45 - iter 16/25 - loss 0.32834500 - samples/sec: 68.40 - lr: 0.050000\n",
            "2022-12-12 11:37:30,062 epoch 45 - iter 18/25 - loss 0.33334750 - samples/sec: 72.43 - lr: 0.050000\n",
            "2022-12-12 11:37:31,385 epoch 45 - iter 20/25 - loss 0.32675927 - samples/sec: 48.42 - lr: 0.050000\n",
            "2022-12-12 11:37:32,310 epoch 45 - iter 22/25 - loss 0.32497273 - samples/sec: 69.28 - lr: 0.050000\n",
            "2022-12-12 11:37:33,120 epoch 45 - iter 24/25 - loss 0.32379624 - samples/sec: 79.14 - lr: 0.050000\n",
            "2022-12-12 11:37:33,191 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:37:33,193 EPOCH 45 done: loss 0.3235 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:37:33,750 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:37:33,760 DEV : loss 0.28439563512802124 - f1-score (micro avg)  0.6214\n",
            "2022-12-12 11:37:33,768 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:37:33,770 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:37:34,893 epoch 46 - iter 2/25 - loss 0.31166243 - samples/sec: 57.04 - lr: 0.050000\n",
            "2022-12-12 11:37:35,955 epoch 46 - iter 4/25 - loss 0.32108485 - samples/sec: 60.33 - lr: 0.050000\n",
            "2022-12-12 11:37:36,968 epoch 46 - iter 6/25 - loss 0.31338210 - samples/sec: 63.30 - lr: 0.050000\n",
            "2022-12-12 11:37:38,050 epoch 46 - iter 8/25 - loss 0.32098746 - samples/sec: 59.22 - lr: 0.050000\n",
            "2022-12-12 11:37:39,143 epoch 46 - iter 10/25 - loss 0.32241745 - samples/sec: 58.64 - lr: 0.050000\n",
            "2022-12-12 11:37:40,161 epoch 46 - iter 12/25 - loss 0.31117931 - samples/sec: 62.95 - lr: 0.050000\n",
            "2022-12-12 11:37:42,829 epoch 46 - iter 14/25 - loss 0.31617905 - samples/sec: 24.00 - lr: 0.050000\n",
            "2022-12-12 11:37:44,046 epoch 46 - iter 16/25 - loss 0.31546498 - samples/sec: 52.69 - lr: 0.050000\n",
            "2022-12-12 11:37:45,364 epoch 46 - iter 18/25 - loss 0.31416824 - samples/sec: 48.59 - lr: 0.050000\n",
            "2022-12-12 11:37:46,553 epoch 46 - iter 20/25 - loss 0.31762937 - samples/sec: 53.89 - lr: 0.050000\n",
            "2022-12-12 11:37:47,625 epoch 46 - iter 22/25 - loss 0.31591652 - samples/sec: 59.77 - lr: 0.050000\n",
            "2022-12-12 11:37:48,549 epoch 46 - iter 24/25 - loss 0.31557827 - samples/sec: 69.43 - lr: 0.050000\n",
            "2022-12-12 11:37:48,614 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:37:48,615 EPOCH 46 done: loss 0.3158 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:37:49,071 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:37:49,082 DEV : loss 0.2956168055534363 - f1-score (micro avg)  0.6228\n",
            "2022-12-12 11:37:49,092 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 11:37:49,093 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:37:50,096 epoch 47 - iter 2/25 - loss 0.32515551 - samples/sec: 63.94 - lr: 0.050000\n",
            "2022-12-12 11:37:51,138 epoch 47 - iter 4/25 - loss 0.30255136 - samples/sec: 61.46 - lr: 0.050000\n",
            "2022-12-12 11:37:52,273 epoch 47 - iter 6/25 - loss 0.30377296 - samples/sec: 56.48 - lr: 0.050000\n",
            "2022-12-12 11:37:54,896 epoch 47 - iter 8/25 - loss 0.30310136 - samples/sec: 24.41 - lr: 0.050000\n",
            "2022-12-12 11:37:55,954 epoch 47 - iter 10/25 - loss 0.30904680 - samples/sec: 60.59 - lr: 0.050000\n",
            "2022-12-12 11:37:57,251 epoch 47 - iter 12/25 - loss 0.31740238 - samples/sec: 49.37 - lr: 0.050000\n",
            "2022-12-12 11:37:58,394 epoch 47 - iter 14/25 - loss 0.31753747 - samples/sec: 56.09 - lr: 0.050000\n",
            "2022-12-12 11:37:59,412 epoch 47 - iter 16/25 - loss 0.31336924 - samples/sec: 62.94 - lr: 0.050000\n",
            "2022-12-12 11:38:00,676 epoch 47 - iter 18/25 - loss 0.31195592 - samples/sec: 50.69 - lr: 0.050000\n",
            "2022-12-12 11:38:01,880 epoch 47 - iter 20/25 - loss 0.31846112 - samples/sec: 53.22 - lr: 0.050000\n",
            "2022-12-12 11:38:02,985 epoch 47 - iter 22/25 - loss 0.32178057 - samples/sec: 58.00 - lr: 0.050000\n",
            "2022-12-12 11:38:03,883 epoch 47 - iter 24/25 - loss 0.31727687 - samples/sec: 71.32 - lr: 0.050000\n",
            "2022-12-12 11:38:03,931 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:38:03,932 EPOCH 47 done: loss 0.3172 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:38:04,499 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:38:04,507 DEV : loss 0.289211630821228 - f1-score (micro avg)  0.6305\n",
            "2022-12-12 11:38:04,515 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:38:04,517 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:38:04,969 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:38:06,002 epoch 48 - iter 2/25 - loss 0.30308706 - samples/sec: 62.07 - lr: 0.050000\n",
            "2022-12-12 11:38:07,140 epoch 48 - iter 4/25 - loss 0.29288453 - samples/sec: 56.31 - lr: 0.050000\n",
            "2022-12-12 11:38:08,104 epoch 48 - iter 6/25 - loss 0.30389625 - samples/sec: 66.50 - lr: 0.050000\n",
            "2022-12-12 11:38:09,283 epoch 48 - iter 8/25 - loss 0.30905873 - samples/sec: 54.32 - lr: 0.050000\n",
            "2022-12-12 11:38:10,503 epoch 48 - iter 10/25 - loss 0.30295997 - samples/sec: 52.55 - lr: 0.050000\n",
            "2022-12-12 11:38:11,430 epoch 48 - iter 12/25 - loss 0.29960157 - samples/sec: 69.14 - lr: 0.050000\n",
            "2022-12-12 11:38:12,528 epoch 48 - iter 14/25 - loss 0.30379546 - samples/sec: 58.35 - lr: 0.050000\n",
            "2022-12-12 11:38:13,535 epoch 48 - iter 16/25 - loss 0.31001249 - samples/sec: 63.67 - lr: 0.050000\n",
            "2022-12-12 11:38:14,451 epoch 48 - iter 18/25 - loss 0.30606564 - samples/sec: 69.91 - lr: 0.050000\n",
            "2022-12-12 11:38:15,585 epoch 48 - iter 20/25 - loss 0.30495710 - samples/sec: 56.49 - lr: 0.050000\n",
            "2022-12-12 11:38:16,469 epoch 48 - iter 22/25 - loss 0.30472027 - samples/sec: 72.57 - lr: 0.050000\n",
            "2022-12-12 11:38:18,867 epoch 48 - iter 24/25 - loss 0.30436276 - samples/sec: 26.70 - lr: 0.050000\n",
            "2022-12-12 11:38:18,935 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:38:18,936 EPOCH 48 done: loss 0.3041 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:38:19,370 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:38:19,379 DEV : loss 0.28374603390693665 - f1-score (micro avg)  0.6322\n",
            "2022-12-12 11:38:19,388 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:38:19,389 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:38:19,834 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:38:21,041 epoch 49 - iter 2/25 - loss 0.28014169 - samples/sec: 53.10 - lr: 0.050000\n",
            "2022-12-12 11:38:22,102 epoch 49 - iter 4/25 - loss 0.28280439 - samples/sec: 60.44 - lr: 0.050000\n",
            "2022-12-12 11:38:23,147 epoch 49 - iter 6/25 - loss 0.29634222 - samples/sec: 61.30 - lr: 0.050000\n",
            "2022-12-12 11:38:24,419 epoch 49 - iter 8/25 - loss 0.29971193 - samples/sec: 50.35 - lr: 0.050000\n",
            "2022-12-12 11:38:25,527 epoch 49 - iter 10/25 - loss 0.31141061 - samples/sec: 57.86 - lr: 0.050000\n",
            "2022-12-12 11:38:26,436 epoch 49 - iter 12/25 - loss 0.30936090 - samples/sec: 70.49 - lr: 0.050000\n",
            "2022-12-12 11:38:27,315 epoch 49 - iter 14/25 - loss 0.30178677 - samples/sec: 72.91 - lr: 0.050000\n",
            "2022-12-12 11:38:28,443 epoch 49 - iter 16/25 - loss 0.30373382 - samples/sec: 56.83 - lr: 0.050000\n",
            "2022-12-12 11:38:31,010 epoch 49 - iter 18/25 - loss 0.30740579 - samples/sec: 24.95 - lr: 0.050000\n",
            "2022-12-12 11:38:32,150 epoch 49 - iter 20/25 - loss 0.31338495 - samples/sec: 56.23 - lr: 0.050000\n",
            "2022-12-12 11:38:33,279 epoch 49 - iter 22/25 - loss 0.31289705 - samples/sec: 56.72 - lr: 0.050000\n",
            "2022-12-12 11:38:34,218 epoch 49 - iter 24/25 - loss 0.31606707 - samples/sec: 68.27 - lr: 0.050000\n",
            "2022-12-12 11:38:34,288 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:38:34,289 EPOCH 49 done: loss 0.3165 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:38:34,799 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:38:34,808 DEV : loss 0.29108917713165283 - f1-score (micro avg)  0.6254\n",
            "2022-12-12 11:38:34,816 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:38:34,818 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:38:35,879 epoch 50 - iter 2/25 - loss 0.32964863 - samples/sec: 60.45 - lr: 0.050000\n",
            "2022-12-12 11:38:36,704 epoch 50 - iter 4/25 - loss 0.32449678 - samples/sec: 77.66 - lr: 0.050000\n",
            "2022-12-12 11:38:37,788 epoch 50 - iter 6/25 - loss 0.31550919 - samples/sec: 59.13 - lr: 0.050000\n",
            "2022-12-12 11:38:39,916 epoch 50 - iter 8/25 - loss 0.30280761 - samples/sec: 30.09 - lr: 0.050000\n",
            "2022-12-12 11:38:40,859 epoch 50 - iter 10/25 - loss 0.30796363 - samples/sec: 67.98 - lr: 0.050000\n",
            "2022-12-12 11:38:42,271 epoch 50 - iter 12/25 - loss 0.31805912 - samples/sec: 45.36 - lr: 0.050000\n",
            "2022-12-12 11:38:43,143 epoch 50 - iter 14/25 - loss 0.31811795 - samples/sec: 73.62 - lr: 0.050000\n",
            "2022-12-12 11:38:44,310 epoch 50 - iter 16/25 - loss 0.31887665 - samples/sec: 54.89 - lr: 0.050000\n",
            "2022-12-12 11:38:45,298 epoch 50 - iter 18/25 - loss 0.31377152 - samples/sec: 64.90 - lr: 0.050000\n",
            "2022-12-12 11:38:46,019 epoch 50 - iter 20/25 - loss 0.31466677 - samples/sec: 88.89 - lr: 0.050000\n",
            "2022-12-12 11:38:47,285 epoch 50 - iter 22/25 - loss 0.31560862 - samples/sec: 50.62 - lr: 0.050000\n",
            "2022-12-12 11:38:48,176 epoch 50 - iter 24/25 - loss 0.31639273 - samples/sec: 71.94 - lr: 0.050000\n",
            "2022-12-12 11:38:48,251 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:38:48,252 EPOCH 50 done: loss 0.3158 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:38:48,689 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:38:48,697 DEV : loss 0.2750115990638733 - f1-score (micro avg)  0.64\n",
            "2022-12-12 11:38:48,705 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:38:48,707 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:38:49,138 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:38:50,047 epoch 51 - iter 2/25 - loss 0.31414216 - samples/sec: 70.60 - lr: 0.050000\n",
            "2022-12-12 11:38:50,899 epoch 51 - iter 4/25 - loss 0.30201860 - samples/sec: 75.24 - lr: 0.050000\n",
            "2022-12-12 11:38:52,095 epoch 51 - iter 6/25 - loss 0.30738584 - samples/sec: 53.57 - lr: 0.050000\n",
            "2022-12-12 11:38:53,073 epoch 51 - iter 8/25 - loss 0.29903939 - samples/sec: 65.51 - lr: 0.050000\n",
            "2022-12-12 11:38:54,247 epoch 51 - iter 10/25 - loss 0.28802402 - samples/sec: 54.61 - lr: 0.050000\n",
            "2022-12-12 11:38:56,384 epoch 51 - iter 12/25 - loss 0.28676859 - samples/sec: 29.95 - lr: 0.050000\n",
            "2022-12-12 11:38:57,549 epoch 51 - iter 14/25 - loss 0.29159871 - samples/sec: 55.03 - lr: 0.050000\n",
            "2022-12-12 11:38:58,413 epoch 51 - iter 16/25 - loss 0.28664003 - samples/sec: 74.17 - lr: 0.050000\n",
            "2022-12-12 11:38:59,373 epoch 51 - iter 18/25 - loss 0.28882621 - samples/sec: 66.75 - lr: 0.050000\n",
            "2022-12-12 11:39:00,437 epoch 51 - iter 20/25 - loss 0.29343058 - samples/sec: 60.21 - lr: 0.050000\n",
            "2022-12-12 11:39:01,575 epoch 51 - iter 22/25 - loss 0.29538721 - samples/sec: 56.36 - lr: 0.050000\n",
            "2022-12-12 11:39:02,459 epoch 51 - iter 24/25 - loss 0.29949448 - samples/sec: 72.50 - lr: 0.050000\n",
            "2022-12-12 11:39:02,527 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:39:02,528 EPOCH 51 done: loss 0.2987 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:39:02,942 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:39:02,950 DEV : loss 0.2766735255718231 - f1-score (micro avg)  0.6394\n",
            "2022-12-12 11:39:02,958 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:39:02,959 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:39:04,149 epoch 52 - iter 2/25 - loss 0.29012338 - samples/sec: 53.85 - lr: 0.050000\n",
            "2022-12-12 11:39:04,982 epoch 52 - iter 4/25 - loss 0.30472821 - samples/sec: 76.96 - lr: 0.050000\n",
            "2022-12-12 11:39:05,963 epoch 52 - iter 6/25 - loss 0.31039803 - samples/sec: 65.30 - lr: 0.050000\n",
            "2022-12-12 11:39:06,809 epoch 52 - iter 8/25 - loss 0.30859389 - samples/sec: 75.80 - lr: 0.050000\n",
            "2022-12-12 11:39:07,570 epoch 52 - iter 10/25 - loss 0.29863535 - samples/sec: 84.27 - lr: 0.050000\n",
            "2022-12-12 11:39:08,406 epoch 52 - iter 12/25 - loss 0.30706520 - samples/sec: 76.61 - lr: 0.050000\n",
            "2022-12-12 11:39:09,455 epoch 52 - iter 14/25 - loss 0.30667881 - samples/sec: 61.11 - lr: 0.050000\n",
            "2022-12-12 11:39:10,332 epoch 52 - iter 16/25 - loss 0.30922046 - samples/sec: 73.08 - lr: 0.050000\n",
            "2022-12-12 11:39:11,229 epoch 52 - iter 18/25 - loss 0.30793445 - samples/sec: 71.46 - lr: 0.050000\n",
            "2022-12-12 11:39:12,496 epoch 52 - iter 20/25 - loss 0.30609821 - samples/sec: 50.54 - lr: 0.050000\n",
            "2022-12-12 11:39:13,591 epoch 52 - iter 22/25 - loss 0.30884162 - samples/sec: 58.53 - lr: 0.050000\n",
            "2022-12-12 11:39:15,760 epoch 52 - iter 24/25 - loss 0.30515891 - samples/sec: 29.53 - lr: 0.050000\n",
            "2022-12-12 11:39:15,855 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:39:15,856 EPOCH 52 done: loss 0.3055 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  6.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:39:16,483 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:39:16,490 DEV : loss 0.28717613220214844 - f1-score (micro avg)  0.6357\n",
            "2022-12-12 11:39:16,498 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:39:16,500 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:39:17,645 epoch 53 - iter 2/25 - loss 0.28085677 - samples/sec: 55.91 - lr: 0.050000\n",
            "2022-12-12 11:39:18,490 epoch 53 - iter 4/25 - loss 0.28397508 - samples/sec: 75.92 - lr: 0.050000\n",
            "2022-12-12 11:39:19,697 epoch 53 - iter 6/25 - loss 0.29717684 - samples/sec: 53.06 - lr: 0.050000\n",
            "2022-12-12 11:39:22,093 epoch 53 - iter 8/25 - loss 0.30682858 - samples/sec: 26.73 - lr: 0.050000\n",
            "2022-12-12 11:39:23,014 epoch 53 - iter 10/25 - loss 0.30194109 - samples/sec: 69.59 - lr: 0.050000\n",
            "2022-12-12 11:39:23,921 epoch 53 - iter 12/25 - loss 0.29386767 - samples/sec: 70.69 - lr: 0.050000\n",
            "2022-12-12 11:39:24,696 epoch 53 - iter 14/25 - loss 0.29304527 - samples/sec: 82.70 - lr: 0.050000\n",
            "2022-12-12 11:39:25,459 epoch 53 - iter 16/25 - loss 0.30023151 - samples/sec: 84.02 - lr: 0.050000\n",
            "2022-12-12 11:39:26,500 epoch 53 - iter 18/25 - loss 0.29670089 - samples/sec: 61.54 - lr: 0.050000\n",
            "2022-12-12 11:39:27,732 epoch 53 - iter 20/25 - loss 0.29832503 - samples/sec: 52.01 - lr: 0.050000\n",
            "2022-12-12 11:39:28,715 epoch 53 - iter 22/25 - loss 0.29691338 - samples/sec: 65.24 - lr: 0.050000\n",
            "2022-12-12 11:39:29,691 epoch 53 - iter 24/25 - loss 0.29682448 - samples/sec: 65.67 - lr: 0.050000\n",
            "2022-12-12 11:39:29,745 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:39:29,746 EPOCH 53 done: loss 0.2966 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:39:30,198 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:39:30,206 DEV : loss 0.27533185482025146 - f1-score (micro avg)  0.652\n",
            "2022-12-12 11:39:30,217 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:39:30,218 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:39:30,654 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:39:31,570 epoch 54 - iter 2/25 - loss 0.26779253 - samples/sec: 69.98 - lr: 0.050000\n",
            "2022-12-12 11:39:32,381 epoch 54 - iter 4/25 - loss 0.27405037 - samples/sec: 79.11 - lr: 0.050000\n",
            "2022-12-12 11:39:33,277 epoch 54 - iter 6/25 - loss 0.27028982 - samples/sec: 71.49 - lr: 0.050000\n",
            "2022-12-12 11:39:34,229 epoch 54 - iter 8/25 - loss 0.28126008 - samples/sec: 67.35 - lr: 0.050000\n",
            "2022-12-12 11:39:35,057 epoch 54 - iter 10/25 - loss 0.28471744 - samples/sec: 77.41 - lr: 0.050000\n",
            "2022-12-12 11:39:36,028 epoch 54 - iter 12/25 - loss 0.29373880 - samples/sec: 66.03 - lr: 0.050000\n",
            "2022-12-12 11:39:36,943 epoch 54 - iter 14/25 - loss 0.29456905 - samples/sec: 69.99 - lr: 0.050000\n",
            "2022-12-12 11:39:38,206 epoch 54 - iter 16/25 - loss 0.29292851 - samples/sec: 50.74 - lr: 0.050000\n",
            "2022-12-12 11:39:39,503 epoch 54 - iter 18/25 - loss 0.29587522 - samples/sec: 49.42 - lr: 0.050000\n",
            "2022-12-12 11:39:40,486 epoch 54 - iter 20/25 - loss 0.29664609 - samples/sec: 65.19 - lr: 0.050000\n",
            "2022-12-12 11:39:41,430 epoch 54 - iter 22/25 - loss 0.29638581 - samples/sec: 67.86 - lr: 0.050000\n",
            "2022-12-12 11:39:43,687 epoch 54 - iter 24/25 - loss 0.29910299 - samples/sec: 28.38 - lr: 0.050000\n",
            "2022-12-12 11:39:43,765 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:39:43,766 EPOCH 54 done: loss 0.2985 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:39:44,186 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:39:44,194 DEV : loss 0.26894286274909973 - f1-score (micro avg)  0.6422\n",
            "2022-12-12 11:39:44,201 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:39:44,204 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:39:45,200 epoch 55 - iter 2/25 - loss 0.36452680 - samples/sec: 64.32 - lr: 0.050000\n",
            "2022-12-12 11:39:45,987 epoch 55 - iter 4/25 - loss 0.32472296 - samples/sec: 81.41 - lr: 0.050000\n",
            "2022-12-12 11:39:46,851 epoch 55 - iter 6/25 - loss 0.31376096 - samples/sec: 74.18 - lr: 0.050000\n",
            "2022-12-12 11:39:49,217 epoch 55 - iter 8/25 - loss 0.32657255 - samples/sec: 27.06 - lr: 0.050000\n",
            "2022-12-12 11:39:50,071 epoch 55 - iter 10/25 - loss 0.31977012 - samples/sec: 75.10 - lr: 0.050000\n",
            "2022-12-12 11:39:50,822 epoch 55 - iter 12/25 - loss 0.31470061 - samples/sec: 85.42 - lr: 0.050000\n",
            "2022-12-12 11:39:52,122 epoch 55 - iter 14/25 - loss 0.31662888 - samples/sec: 49.26 - lr: 0.050000\n",
            "2022-12-12 11:39:53,368 epoch 55 - iter 16/25 - loss 0.31456003 - samples/sec: 51.45 - lr: 0.050000\n",
            "2022-12-12 11:39:54,453 epoch 55 - iter 18/25 - loss 0.30955857 - samples/sec: 59.07 - lr: 0.050000\n",
            "2022-12-12 11:39:55,819 epoch 55 - iter 20/25 - loss 0.30176318 - samples/sec: 46.87 - lr: 0.050000\n",
            "2022-12-12 11:39:56,862 epoch 55 - iter 22/25 - loss 0.29676356 - samples/sec: 61.45 - lr: 0.050000\n",
            "2022-12-12 11:39:57,833 epoch 55 - iter 24/25 - loss 0.29763244 - samples/sec: 66.05 - lr: 0.050000\n",
            "2022-12-12 11:39:57,901 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:39:57,902 EPOCH 55 done: loss 0.2974 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:39:58,367 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:39:58,374 DEV : loss 0.2734452188014984 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:39:58,382 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:39:58,384 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:39:58,822 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:39:59,683 epoch 56 - iter 2/25 - loss 0.30616652 - samples/sec: 74.46 - lr: 0.050000\n",
            "2022-12-12 11:40:00,781 epoch 56 - iter 4/25 - loss 0.31255132 - samples/sec: 58.38 - lr: 0.050000\n",
            "2022-12-12 11:40:02,877 epoch 56 - iter 6/25 - loss 0.29433957 - samples/sec: 30.55 - lr: 0.050000\n",
            "2022-12-12 11:40:04,027 epoch 56 - iter 8/25 - loss 0.28339520 - samples/sec: 55.71 - lr: 0.050000\n",
            "2022-12-12 11:40:05,065 epoch 56 - iter 10/25 - loss 0.29831270 - samples/sec: 61.76 - lr: 0.050000\n",
            "2022-12-12 11:40:05,874 epoch 56 - iter 12/25 - loss 0.29559252 - samples/sec: 79.22 - lr: 0.050000\n",
            "2022-12-12 11:40:07,010 epoch 56 - iter 14/25 - loss 0.29491560 - samples/sec: 56.42 - lr: 0.050000\n",
            "2022-12-12 11:40:08,053 epoch 56 - iter 16/25 - loss 0.29318321 - samples/sec: 61.44 - lr: 0.050000\n",
            "2022-12-12 11:40:09,098 epoch 56 - iter 18/25 - loss 0.29227980 - samples/sec: 61.30 - lr: 0.050000\n",
            "2022-12-12 11:40:10,236 epoch 56 - iter 20/25 - loss 0.29544458 - samples/sec: 56.34 - lr: 0.050000\n",
            "2022-12-12 11:40:11,175 epoch 56 - iter 22/25 - loss 0.29234654 - samples/sec: 68.23 - lr: 0.050000\n",
            "2022-12-12 11:40:12,192 epoch 56 - iter 24/25 - loss 0.29606108 - samples/sec: 63.03 - lr: 0.050000\n",
            "2022-12-12 11:40:12,275 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:40:12,276 EPOCH 56 done: loss 0.2964 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:40:12,785 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:40:12,794 DEV : loss 0.2727002501487732 - f1-score (micro avg)  0.6547\n",
            "2022-12-12 11:40:12,802 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:40:12,803 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:40:13,925 epoch 57 - iter 2/25 - loss 0.31121464 - samples/sec: 57.14 - lr: 0.050000\n",
            "2022-12-12 11:40:14,956 epoch 57 - iter 4/25 - loss 0.28675588 - samples/sec: 62.16 - lr: 0.050000\n",
            "2022-12-12 11:40:16,267 epoch 57 - iter 6/25 - loss 0.29295363 - samples/sec: 48.87 - lr: 0.050000\n",
            "2022-12-12 11:40:17,238 epoch 57 - iter 8/25 - loss 0.29214406 - samples/sec: 66.04 - lr: 0.050000\n",
            "2022-12-12 11:40:18,166 epoch 57 - iter 10/25 - loss 0.28917889 - samples/sec: 69.08 - lr: 0.050000\n",
            "2022-12-12 11:40:19,040 epoch 57 - iter 12/25 - loss 0.29505990 - samples/sec: 73.33 - lr: 0.050000\n",
            "2022-12-12 11:40:20,240 epoch 57 - iter 14/25 - loss 0.29269380 - samples/sec: 53.38 - lr: 0.050000\n",
            "2022-12-12 11:40:21,044 epoch 57 - iter 16/25 - loss 0.29546819 - samples/sec: 79.73 - lr: 0.050000\n",
            "2022-12-12 11:40:22,061 epoch 57 - iter 18/25 - loss 0.29834019 - samples/sec: 62.99 - lr: 0.050000\n",
            "2022-12-12 11:40:22,960 epoch 57 - iter 20/25 - loss 0.29650882 - samples/sec: 71.30 - lr: 0.050000\n",
            "2022-12-12 11:40:23,659 epoch 57 - iter 22/25 - loss 0.29479469 - samples/sec: 91.72 - lr: 0.050000\n",
            "2022-12-12 11:40:26,056 epoch 57 - iter 24/25 - loss 0.29440457 - samples/sec: 26.72 - lr: 0.050000\n",
            "2022-12-12 11:40:26,131 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:40:26,132 EPOCH 57 done: loss 0.2940 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  6.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:40:26,732 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:40:26,740 DEV : loss 0.25879597663879395 - f1-score (micro avg)  0.6667\n",
            "2022-12-12 11:40:26,748 BAD EPOCHS (no improvement): 0\n",
            "2022-12-12 11:40:26,749 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:40:27,184 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:40:28,063 epoch 58 - iter 2/25 - loss 0.23046961 - samples/sec: 72.98 - lr: 0.050000\n",
            "2022-12-12 11:40:29,195 epoch 58 - iter 4/25 - loss 0.25989205 - samples/sec: 56.60 - lr: 0.050000\n",
            "2022-12-12 11:40:31,213 epoch 58 - iter 6/25 - loss 0.24983254 - samples/sec: 31.73 - lr: 0.050000\n",
            "2022-12-12 11:40:32,285 epoch 58 - iter 8/25 - loss 0.26759602 - samples/sec: 59.74 - lr: 0.050000\n",
            "2022-12-12 11:40:33,121 epoch 58 - iter 10/25 - loss 0.26636521 - samples/sec: 76.72 - lr: 0.050000\n",
            "2022-12-12 11:40:34,186 epoch 58 - iter 12/25 - loss 0.26894872 - samples/sec: 60.16 - lr: 0.050000\n",
            "2022-12-12 11:40:35,262 epoch 58 - iter 14/25 - loss 0.27093881 - samples/sec: 59.55 - lr: 0.050000\n",
            "2022-12-12 11:40:36,030 epoch 58 - iter 16/25 - loss 0.27405628 - samples/sec: 83.52 - lr: 0.050000\n",
            "2022-12-12 11:40:36,885 epoch 58 - iter 18/25 - loss 0.27988578 - samples/sec: 74.95 - lr: 0.050000\n",
            "2022-12-12 11:40:37,876 epoch 58 - iter 20/25 - loss 0.28282457 - samples/sec: 64.67 - lr: 0.050000\n",
            "2022-12-12 11:40:38,956 epoch 58 - iter 22/25 - loss 0.28168131 - samples/sec: 59.32 - lr: 0.050000\n",
            "2022-12-12 11:40:40,274 epoch 58 - iter 24/25 - loss 0.28635708 - samples/sec: 48.60 - lr: 0.050000\n",
            "2022-12-12 11:40:40,356 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:40:40,356 EPOCH 58 done: loss 0.2868 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:40:40,785 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:40:40,793 DEV : loss 0.2830386757850647 - f1-score (micro avg)  0.6345\n",
            "2022-12-12 11:40:40,801 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:40:40,803 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:40:41,838 epoch 59 - iter 2/25 - loss 0.25751844 - samples/sec: 61.91 - lr: 0.050000\n",
            "2022-12-12 11:40:43,024 epoch 59 - iter 4/25 - loss 0.26801500 - samples/sec: 54.01 - lr: 0.050000\n",
            "2022-12-12 11:40:43,904 epoch 59 - iter 6/25 - loss 0.28711148 - samples/sec: 72.89 - lr: 0.050000\n",
            "2022-12-12 11:40:44,940 epoch 59 - iter 8/25 - loss 0.28801392 - samples/sec: 61.83 - lr: 0.050000\n",
            "2022-12-12 11:40:45,728 epoch 59 - iter 10/25 - loss 0.29131830 - samples/sec: 81.38 - lr: 0.050000\n",
            "2022-12-12 11:40:46,753 epoch 59 - iter 12/25 - loss 0.29172116 - samples/sec: 62.51 - lr: 0.050000\n",
            "2022-12-12 11:40:47,742 epoch 59 - iter 14/25 - loss 0.30096015 - samples/sec: 64.84 - lr: 0.050000\n",
            "2022-12-12 11:40:48,707 epoch 59 - iter 16/25 - loss 0.29914280 - samples/sec: 66.36 - lr: 0.050000\n",
            "2022-12-12 11:40:50,833 epoch 59 - iter 18/25 - loss 0.29362725 - samples/sec: 30.13 - lr: 0.050000\n",
            "2022-12-12 11:40:51,896 epoch 59 - iter 20/25 - loss 0.29205310 - samples/sec: 60.31 - lr: 0.050000\n",
            "2022-12-12 11:40:52,973 epoch 59 - iter 22/25 - loss 0.28863978 - samples/sec: 59.50 - lr: 0.050000\n",
            "2022-12-12 11:40:54,146 epoch 59 - iter 24/25 - loss 0.28777270 - samples/sec: 54.60 - lr: 0.050000\n",
            "2022-12-12 11:40:54,230 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:40:54,231 EPOCH 59 done: loss 0.2873 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:40:54,705 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:40:54,713 DEV : loss 0.2663547396659851 - f1-score (micro avg)  0.6528\n",
            "2022-12-12 11:40:54,721 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:40:54,722 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:40:56,967 epoch 60 - iter 2/25 - loss 0.28485151 - samples/sec: 28.53 - lr: 0.050000\n",
            "2022-12-12 11:40:57,814 epoch 60 - iter 4/25 - loss 0.27255597 - samples/sec: 75.65 - lr: 0.050000\n",
            "2022-12-12 11:40:58,813 epoch 60 - iter 6/25 - loss 0.29084057 - samples/sec: 64.11 - lr: 0.050000\n",
            "2022-12-12 11:40:59,895 epoch 60 - iter 8/25 - loss 0.28441104 - samples/sec: 59.23 - lr: 0.050000\n",
            "2022-12-12 11:41:01,064 epoch 60 - iter 10/25 - loss 0.28802974 - samples/sec: 54.80 - lr: 0.050000\n",
            "2022-12-12 11:41:01,987 epoch 60 - iter 12/25 - loss 0.28641397 - samples/sec: 69.44 - lr: 0.050000\n",
            "2022-12-12 11:41:02,993 epoch 60 - iter 14/25 - loss 0.29187806 - samples/sec: 63.69 - lr: 0.050000\n",
            "2022-12-12 11:41:03,866 epoch 60 - iter 16/25 - loss 0.29115786 - samples/sec: 73.42 - lr: 0.050000\n",
            "2022-12-12 11:41:04,639 epoch 60 - iter 18/25 - loss 0.29292618 - samples/sec: 83.01 - lr: 0.050000\n",
            "2022-12-12 11:41:05,662 epoch 60 - iter 20/25 - loss 0.29169882 - samples/sec: 62.61 - lr: 0.050000\n",
            "2022-12-12 11:41:07,051 epoch 60 - iter 22/25 - loss 0.28832335 - samples/sec: 46.11 - lr: 0.050000\n",
            "2022-12-12 11:41:08,312 epoch 60 - iter 24/25 - loss 0.28801679 - samples/sec: 50.82 - lr: 0.050000\n",
            "2022-12-12 11:41:08,376 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:41:08,378 EPOCH 60 done: loss 0.2875 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:41:08,858 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:41:08,866 DEV : loss 0.2708333134651184 - f1-score (micro avg)  0.6344\n",
            "2022-12-12 11:41:08,874 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 11:41:08,876 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:41:09,820 epoch 61 - iter 2/25 - loss 0.29445850 - samples/sec: 67.92 - lr: 0.050000\n",
            "2022-12-12 11:41:10,839 epoch 61 - iter 4/25 - loss 0.29866606 - samples/sec: 62.86 - lr: 0.050000\n",
            "2022-12-12 11:41:11,636 epoch 61 - iter 6/25 - loss 0.28973894 - samples/sec: 80.39 - lr: 0.050000\n",
            "2022-12-12 11:41:12,712 epoch 61 - iter 8/25 - loss 0.29517480 - samples/sec: 59.60 - lr: 0.050000\n",
            "2022-12-12 11:41:13,405 epoch 61 - iter 10/25 - loss 0.29258414 - samples/sec: 92.47 - lr: 0.050000\n",
            "2022-12-12 11:41:14,231 epoch 61 - iter 12/25 - loss 0.28650289 - samples/sec: 77.66 - lr: 0.050000\n",
            "2022-12-12 11:41:15,237 epoch 61 - iter 14/25 - loss 0.28832641 - samples/sec: 63.69 - lr: 0.050000\n",
            "2022-12-12 11:41:16,379 epoch 61 - iter 16/25 - loss 0.28928184 - samples/sec: 56.08 - lr: 0.050000\n",
            "2022-12-12 11:41:17,491 epoch 61 - iter 18/25 - loss 0.29168515 - samples/sec: 57.61 - lr: 0.050000\n",
            "2022-12-12 11:41:18,512 epoch 61 - iter 20/25 - loss 0.28844592 - samples/sec: 62.78 - lr: 0.050000\n",
            "2022-12-12 11:41:21,101 epoch 61 - iter 22/25 - loss 0.28481337 - samples/sec: 24.74 - lr: 0.050000\n",
            "2022-12-12 11:41:22,302 epoch 61 - iter 24/25 - loss 0.28140979 - samples/sec: 53.36 - lr: 0.050000\n",
            "2022-12-12 11:41:22,414 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:41:22,415 EPOCH 61 done: loss 0.2810 - lr 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:41:22,857 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:41:22,864 DEV : loss 0.26524314284324646 - f1-score (micro avg)  0.6488\n",
            "2022-12-12 11:41:22,872 Epoch    61: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2022-12-12 11:41:22,874 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 11:41:22,874 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:41:24,113 epoch 62 - iter 2/25 - loss 0.29584779 - samples/sec: 51.70 - lr: 0.025000\n",
            "2022-12-12 11:41:25,151 epoch 62 - iter 4/25 - loss 0.27158745 - samples/sec: 61.74 - lr: 0.025000\n",
            "2022-12-12 11:41:26,508 epoch 62 - iter 6/25 - loss 0.28900846 - samples/sec: 47.21 - lr: 0.025000\n",
            "2022-12-12 11:41:27,470 epoch 62 - iter 8/25 - loss 0.28293183 - samples/sec: 66.64 - lr: 0.025000\n",
            "2022-12-12 11:41:29,687 epoch 62 - iter 10/25 - loss 0.28060583 - samples/sec: 28.87 - lr: 0.025000\n",
            "2022-12-12 11:41:30,607 epoch 62 - iter 12/25 - loss 0.28224682 - samples/sec: 69.68 - lr: 0.025000\n",
            "2022-12-12 11:41:31,747 epoch 62 - iter 14/25 - loss 0.28345843 - samples/sec: 56.20 - lr: 0.025000\n",
            "2022-12-12 11:41:32,652 epoch 62 - iter 16/25 - loss 0.27882025 - samples/sec: 70.88 - lr: 0.025000\n",
            "2022-12-12 11:41:33,762 epoch 62 - iter 18/25 - loss 0.27879843 - samples/sec: 57.72 - lr: 0.025000\n",
            "2022-12-12 11:41:34,695 epoch 62 - iter 20/25 - loss 0.27944208 - samples/sec: 68.71 - lr: 0.025000\n",
            "2022-12-12 11:41:35,628 epoch 62 - iter 22/25 - loss 0.27763205 - samples/sec: 68.66 - lr: 0.025000\n",
            "2022-12-12 11:41:36,557 epoch 62 - iter 24/25 - loss 0.27727618 - samples/sec: 68.96 - lr: 0.025000\n",
            "2022-12-12 11:41:36,630 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:41:36,632 EPOCH 62 done: loss 0.2767 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:41:37,075 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:41:37,082 DEV : loss 0.26385605335235596 - f1-score (micro avg)  0.6555\n",
            "2022-12-12 11:41:37,090 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:41:37,092 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:41:39,447 epoch 63 - iter 2/25 - loss 0.25115814 - samples/sec: 27.19 - lr: 0.025000\n",
            "2022-12-12 11:41:40,165 epoch 63 - iter 4/25 - loss 0.26738703 - samples/sec: 89.29 - lr: 0.025000\n",
            "2022-12-12 11:41:41,381 epoch 63 - iter 6/25 - loss 0.28750445 - samples/sec: 52.72 - lr: 0.025000\n",
            "2022-12-12 11:41:42,520 epoch 63 - iter 8/25 - loss 0.28127364 - samples/sec: 56.23 - lr: 0.025000\n",
            "2022-12-12 11:41:43,629 epoch 63 - iter 10/25 - loss 0.27716142 - samples/sec: 57.78 - lr: 0.025000\n",
            "2022-12-12 11:41:44,732 epoch 63 - iter 12/25 - loss 0.27404926 - samples/sec: 58.11 - lr: 0.025000\n",
            "2022-12-12 11:41:45,778 epoch 63 - iter 14/25 - loss 0.27184586 - samples/sec: 61.23 - lr: 0.025000\n",
            "2022-12-12 11:41:47,148 epoch 63 - iter 16/25 - loss 0.27202052 - samples/sec: 46.76 - lr: 0.025000\n",
            "2022-12-12 11:41:48,031 epoch 63 - iter 18/25 - loss 0.27666387 - samples/sec: 72.60 - lr: 0.025000\n",
            "2022-12-12 11:41:48,833 epoch 63 - iter 20/25 - loss 0.27493303 - samples/sec: 79.96 - lr: 0.025000\n",
            "2022-12-12 11:41:49,934 epoch 63 - iter 22/25 - loss 0.27506096 - samples/sec: 58.18 - lr: 0.025000\n",
            "2022-12-12 11:41:50,892 epoch 63 - iter 24/25 - loss 0.27937686 - samples/sec: 66.92 - lr: 0.025000\n",
            "2022-12-12 11:41:50,980 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:41:50,981 EPOCH 63 done: loss 0.2793 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:41:51,513 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:41:51,521 DEV : loss 0.26488929986953735 - f1-score (micro avg)  0.6524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:41:51,531 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:41:51,533 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:41:52,673 epoch 64 - iter 2/25 - loss 0.30272653 - samples/sec: 56.16 - lr: 0.025000\n",
            "2022-12-12 11:41:53,603 epoch 64 - iter 4/25 - loss 0.28128413 - samples/sec: 68.93 - lr: 0.025000\n",
            "2022-12-12 11:41:54,710 epoch 64 - iter 6/25 - loss 0.27270918 - samples/sec: 57.91 - lr: 0.025000\n",
            "2022-12-12 11:41:55,778 epoch 64 - iter 8/25 - loss 0.27605274 - samples/sec: 59.97 - lr: 0.025000\n",
            "2022-12-12 11:41:56,747 epoch 64 - iter 10/25 - loss 0.27698031 - samples/sec: 66.15 - lr: 0.025000\n",
            "2022-12-12 11:41:57,733 epoch 64 - iter 12/25 - loss 0.27627376 - samples/sec: 65.03 - lr: 0.025000\n",
            "2022-12-12 11:41:58,824 epoch 64 - iter 14/25 - loss 0.27388909 - samples/sec: 58.76 - lr: 0.025000\n",
            "2022-12-12 11:42:01,394 epoch 64 - iter 16/25 - loss 0.26907553 - samples/sec: 24.92 - lr: 0.025000\n",
            "2022-12-12 11:42:02,546 epoch 64 - iter 18/25 - loss 0.26594651 - samples/sec: 55.62 - lr: 0.025000\n",
            "2022-12-12 11:42:03,635 epoch 64 - iter 20/25 - loss 0.26659173 - samples/sec: 58.82 - lr: 0.025000\n",
            "2022-12-12 11:42:04,696 epoch 64 - iter 22/25 - loss 0.26831826 - samples/sec: 60.37 - lr: 0.025000\n",
            "2022-12-12 11:42:05,854 epoch 64 - iter 24/25 - loss 0.26872652 - samples/sec: 55.35 - lr: 0.025000\n",
            "2022-12-12 11:42:05,950 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:42:05,951 EPOCH 64 done: loss 0.2691 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:42:06,422 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:42:06,431 DEV : loss 0.2623550295829773 - f1-score (micro avg)  0.6462\n",
            "2022-12-12 11:42:06,439 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 11:42:06,441 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:42:07,392 epoch 65 - iter 2/25 - loss 0.25706527 - samples/sec: 67.42 - lr: 0.025000\n",
            "2022-12-12 11:42:08,579 epoch 65 - iter 4/25 - loss 0.27631515 - samples/sec: 53.96 - lr: 0.025000\n",
            "2022-12-12 11:42:09,444 epoch 65 - iter 6/25 - loss 0.26772948 - samples/sec: 74.13 - lr: 0.025000\n",
            "2022-12-12 11:42:10,517 epoch 65 - iter 8/25 - loss 0.26403840 - samples/sec: 59.70 - lr: 0.025000\n",
            "2022-12-12 11:42:11,549 epoch 65 - iter 10/25 - loss 0.27329179 - samples/sec: 62.15 - lr: 0.025000\n",
            "2022-12-12 11:42:12,871 epoch 65 - iter 12/25 - loss 0.26981728 - samples/sec: 48.47 - lr: 0.025000\n",
            "2022-12-12 11:42:13,522 epoch 65 - iter 14/25 - loss 0.26712667 - samples/sec: 98.45 - lr: 0.025000\n",
            "2022-12-12 11:42:16,029 epoch 65 - iter 16/25 - loss 0.26532266 - samples/sec: 25.54 - lr: 0.025000\n",
            "2022-12-12 11:42:17,121 epoch 65 - iter 18/25 - loss 0.26169510 - samples/sec: 58.67 - lr: 0.025000\n",
            "2022-12-12 11:42:18,280 epoch 65 - iter 20/25 - loss 0.26704628 - samples/sec: 55.33 - lr: 0.025000\n",
            "2022-12-12 11:42:19,142 epoch 65 - iter 22/25 - loss 0.26882505 - samples/sec: 74.38 - lr: 0.025000\n",
            "2022-12-12 11:42:20,141 epoch 65 - iter 24/25 - loss 0.26928941 - samples/sec: 64.13 - lr: 0.025000\n",
            "2022-12-12 11:42:20,197 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:42:20,198 EPOCH 65 done: loss 0.2689 - lr 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:42:20,669 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:42:20,679 DEV : loss 0.2628309726715088 - f1-score (micro avg)  0.6499\n",
            "2022-12-12 11:42:20,691 Epoch    65: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2022-12-12 11:42:20,693 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 11:42:20,693 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:42:21,642 epoch 66 - iter 2/25 - loss 0.26593177 - samples/sec: 67.66 - lr: 0.012500\n",
            "2022-12-12 11:42:22,664 epoch 66 - iter 4/25 - loss 0.27514026 - samples/sec: 62.68 - lr: 0.012500\n",
            "2022-12-12 11:42:23,555 epoch 66 - iter 6/25 - loss 0.26419938 - samples/sec: 71.91 - lr: 0.012500\n",
            "2022-12-12 11:42:24,597 epoch 66 - iter 8/25 - loss 0.26134290 - samples/sec: 61.51 - lr: 0.012500\n",
            "2022-12-12 11:42:25,643 epoch 66 - iter 10/25 - loss 0.26222691 - samples/sec: 61.29 - lr: 0.012500\n",
            "2022-12-12 11:42:26,919 epoch 66 - iter 12/25 - loss 0.26482018 - samples/sec: 50.20 - lr: 0.012500\n",
            "2022-12-12 11:42:27,975 epoch 66 - iter 14/25 - loss 0.26820549 - samples/sec: 60.70 - lr: 0.012500\n",
            "2022-12-12 11:42:28,869 epoch 66 - iter 16/25 - loss 0.27413272 - samples/sec: 71.76 - lr: 0.012500\n",
            "2022-12-12 11:42:29,786 epoch 66 - iter 18/25 - loss 0.27141289 - samples/sec: 69.87 - lr: 0.012500\n",
            "2022-12-12 11:42:30,990 epoch 66 - iter 20/25 - loss 0.27264276 - samples/sec: 53.20 - lr: 0.012500\n",
            "2022-12-12 11:42:32,203 epoch 66 - iter 22/25 - loss 0.27378073 - samples/sec: 52.85 - lr: 0.012500\n",
            "2022-12-12 11:42:34,487 epoch 66 - iter 24/25 - loss 0.27047591 - samples/sec: 28.04 - lr: 0.012500\n",
            "2022-12-12 11:42:34,596 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:42:34,597 EPOCH 66 done: loss 0.2703 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:42:35,063 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:42:35,070 DEV : loss 0.2661665678024292 - f1-score (micro avg)  0.6549\n",
            "2022-12-12 11:42:35,080 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:42:35,082 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:42:35,899 epoch 67 - iter 2/25 - loss 0.24408553 - samples/sec: 78.37 - lr: 0.012500\n",
            "2022-12-12 11:42:37,185 epoch 67 - iter 4/25 - loss 0.25899207 - samples/sec: 49.81 - lr: 0.012500\n",
            "2022-12-12 11:42:38,285 epoch 67 - iter 6/25 - loss 0.28240823 - samples/sec: 58.28 - lr: 0.012500\n",
            "2022-12-12 11:42:39,544 epoch 67 - iter 8/25 - loss 0.28063115 - samples/sec: 50.87 - lr: 0.012500\n",
            "2022-12-12 11:42:40,531 epoch 67 - iter 10/25 - loss 0.27163460 - samples/sec: 64.90 - lr: 0.012500\n",
            "2022-12-12 11:42:41,474 epoch 67 - iter 12/25 - loss 0.27323860 - samples/sec: 68.00 - lr: 0.012500\n",
            "2022-12-12 11:42:42,475 epoch 67 - iter 14/25 - loss 0.26899887 - samples/sec: 64.00 - lr: 0.012500\n",
            "2022-12-12 11:42:43,290 epoch 67 - iter 16/25 - loss 0.26176869 - samples/sec: 78.73 - lr: 0.012500\n",
            "2022-12-12 11:42:44,201 epoch 67 - iter 18/25 - loss 0.26400075 - samples/sec: 70.33 - lr: 0.012500\n",
            "2022-12-12 11:42:45,419 epoch 67 - iter 20/25 - loss 0.26776660 - samples/sec: 52.58 - lr: 0.012500\n",
            "2022-12-12 11:42:46,338 epoch 67 - iter 22/25 - loss 0.26990875 - samples/sec: 69.74 - lr: 0.012500\n",
            "2022-12-12 11:42:48,701 epoch 67 - iter 24/25 - loss 0.26929437 - samples/sec: 27.11 - lr: 0.012500\n",
            "2022-12-12 11:42:48,771 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:42:48,772 EPOCH 67 done: loss 0.2692 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:42:49,229 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:42:49,237 DEV : loss 0.2598554790019989 - f1-score (micro avg)  0.6586\n",
            "2022-12-12 11:42:49,245 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:42:49,247 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:42:50,236 epoch 68 - iter 2/25 - loss 0.25254615 - samples/sec: 64.79 - lr: 0.012500\n",
            "2022-12-12 11:42:52,629 epoch 68 - iter 4/25 - loss 0.27013030 - samples/sec: 26.76 - lr: 0.012500\n",
            "2022-12-12 11:42:53,870 epoch 68 - iter 6/25 - loss 0.27852030 - samples/sec: 51.61 - lr: 0.012500\n",
            "2022-12-12 11:42:55,035 epoch 68 - iter 8/25 - loss 0.28437455 - samples/sec: 55.02 - lr: 0.012500\n",
            "2022-12-12 11:42:55,992 epoch 68 - iter 10/25 - loss 0.27913735 - samples/sec: 66.97 - lr: 0.012500\n",
            "2022-12-12 11:42:57,240 epoch 68 - iter 12/25 - loss 0.27747003 - samples/sec: 51.33 - lr: 0.012500\n",
            "2022-12-12 11:42:58,173 epoch 68 - iter 14/25 - loss 0.27938291 - samples/sec: 68.71 - lr: 0.012500\n",
            "2022-12-12 11:42:59,104 epoch 68 - iter 16/25 - loss 0.27722620 - samples/sec: 68.82 - lr: 0.012500\n",
            "2022-12-12 11:43:00,066 epoch 68 - iter 18/25 - loss 0.27264547 - samples/sec: 66.67 - lr: 0.012500\n",
            "2022-12-12 11:43:01,444 epoch 68 - iter 20/25 - loss 0.26966155 - samples/sec: 46.48 - lr: 0.012500\n",
            "2022-12-12 11:43:02,588 epoch 68 - iter 22/25 - loss 0.27020740 - samples/sec: 56.05 - lr: 0.012500\n",
            "2022-12-12 11:43:03,402 epoch 68 - iter 24/25 - loss 0.26989191 - samples/sec: 78.76 - lr: 0.012500\n",
            "2022-12-12 11:43:03,459 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:43:03,460 EPOCH 68 done: loss 0.2699 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:43:03,913 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:43:03,921 DEV : loss 0.26272353529930115 - f1-score (micro avg)  0.6529\n",
            "2022-12-12 11:43:03,929 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 11:43:03,931 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:43:04,892 epoch 69 - iter 2/25 - loss 0.28442243 - samples/sec: 66.70 - lr: 0.012500\n",
            "2022-12-12 11:43:05,726 epoch 69 - iter 4/25 - loss 0.28172554 - samples/sec: 76.88 - lr: 0.012500\n",
            "2022-12-12 11:43:08,200 epoch 69 - iter 6/25 - loss 0.27693827 - samples/sec: 25.88 - lr: 0.012500\n",
            "2022-12-12 11:43:09,172 epoch 69 - iter 8/25 - loss 0.27438577 - samples/sec: 65.98 - lr: 0.012500\n",
            "2022-12-12 11:43:10,232 epoch 69 - iter 10/25 - loss 0.27145162 - samples/sec: 60.46 - lr: 0.012500\n",
            "2022-12-12 11:43:11,224 epoch 69 - iter 12/25 - loss 0.27680581 - samples/sec: 64.61 - lr: 0.012500\n",
            "2022-12-12 11:43:12,166 epoch 69 - iter 14/25 - loss 0.27856159 - samples/sec: 67.99 - lr: 0.012500\n",
            "2022-12-12 11:43:13,426 epoch 69 - iter 16/25 - loss 0.27226104 - samples/sec: 50.84 - lr: 0.012500\n",
            "2022-12-12 11:43:14,639 epoch 69 - iter 18/25 - loss 0.27405849 - samples/sec: 52.82 - lr: 0.012500\n",
            "2022-12-12 11:43:16,105 epoch 69 - iter 20/25 - loss 0.27295276 - samples/sec: 43.70 - lr: 0.012500\n",
            "2022-12-12 11:43:16,982 epoch 69 - iter 22/25 - loss 0.27302656 - samples/sec: 73.11 - lr: 0.012500\n",
            "2022-12-12 11:43:17,949 epoch 69 - iter 24/25 - loss 0.27090002 - samples/sec: 66.32 - lr: 0.012500\n",
            "2022-12-12 11:43:18,010 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:43:18,011 EPOCH 69 done: loss 0.2706 - lr 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:43:18,474 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:43:18,482 DEV : loss 0.2630848288536072 - f1-score (micro avg)  0.6559\n",
            "2022-12-12 11:43:18,491 Epoch    69: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2022-12-12 11:43:18,492 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 11:43:18,493 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:43:19,706 epoch 70 - iter 2/25 - loss 0.25942821 - samples/sec: 52.79 - lr: 0.006250\n",
            "2022-12-12 11:43:20,700 epoch 70 - iter 4/25 - loss 0.25838408 - samples/sec: 64.54 - lr: 0.006250\n",
            "2022-12-12 11:43:21,759 epoch 70 - iter 6/25 - loss 0.25965413 - samples/sec: 60.49 - lr: 0.006250\n",
            "2022-12-12 11:43:22,955 epoch 70 - iter 8/25 - loss 0.26538372 - samples/sec: 53.58 - lr: 0.006250\n",
            "2022-12-12 11:43:25,305 epoch 70 - iter 10/25 - loss 0.25727151 - samples/sec: 27.25 - lr: 0.006250\n",
            "2022-12-12 11:43:26,381 epoch 70 - iter 12/25 - loss 0.25296444 - samples/sec: 59.56 - lr: 0.006250\n",
            "2022-12-12 11:43:27,268 epoch 70 - iter 14/25 - loss 0.25211564 - samples/sec: 72.27 - lr: 0.006250\n",
            "2022-12-12 11:43:28,366 epoch 70 - iter 16/25 - loss 0.25634304 - samples/sec: 58.35 - lr: 0.006250\n",
            "2022-12-12 11:43:29,312 epoch 70 - iter 18/25 - loss 0.26189444 - samples/sec: 67.75 - lr: 0.006250\n",
            "2022-12-12 11:43:30,381 epoch 70 - iter 20/25 - loss 0.26923605 - samples/sec: 59.92 - lr: 0.006250\n",
            "2022-12-12 11:43:31,296 epoch 70 - iter 22/25 - loss 0.26726734 - samples/sec: 70.09 - lr: 0.006250\n",
            "2022-12-12 11:43:32,348 epoch 70 - iter 24/25 - loss 0.26997022 - samples/sec: 60.91 - lr: 0.006250\n",
            "2022-12-12 11:43:32,458 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:43:32,460 EPOCH 70 done: loss 0.2695 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:43:32,894 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:43:32,901 DEV : loss 0.26068106293678284 - f1-score (micro avg)  0.6567\n",
            "2022-12-12 11:43:32,910 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:43:32,912 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:43:33,931 epoch 71 - iter 2/25 - loss 0.26586521 - samples/sec: 62.88 - lr: 0.006250\n",
            "2022-12-12 11:43:35,088 epoch 71 - iter 4/25 - loss 0.26468426 - samples/sec: 55.40 - lr: 0.006250\n",
            "2022-12-12 11:43:36,077 epoch 71 - iter 6/25 - loss 0.26805647 - samples/sec: 64.80 - lr: 0.006250\n",
            "2022-12-12 11:43:37,404 epoch 71 - iter 8/25 - loss 0.26693887 - samples/sec: 48.28 - lr: 0.006250\n",
            "2022-12-12 11:43:38,518 epoch 71 - iter 10/25 - loss 0.26550010 - samples/sec: 57.53 - lr: 0.006250\n",
            "2022-12-12 11:43:41,017 epoch 71 - iter 12/25 - loss 0.26925583 - samples/sec: 25.62 - lr: 0.006250\n",
            "2022-12-12 11:43:42,186 epoch 71 - iter 14/25 - loss 0.26922076 - samples/sec: 54.81 - lr: 0.006250\n",
            "2022-12-12 11:43:43,232 epoch 71 - iter 16/25 - loss 0.26409777 - samples/sec: 61.29 - lr: 0.006250\n",
            "2022-12-12 11:43:44,259 epoch 71 - iter 18/25 - loss 0.26285638 - samples/sec: 62.39 - lr: 0.006250\n",
            "2022-12-12 11:43:45,451 epoch 71 - iter 20/25 - loss 0.26293691 - samples/sec: 53.76 - lr: 0.006250\n",
            "2022-12-12 11:43:46,304 epoch 71 - iter 22/25 - loss 0.26233103 - samples/sec: 75.08 - lr: 0.006250\n",
            "2022-12-12 11:43:47,232 epoch 71 - iter 24/25 - loss 0.26125733 - samples/sec: 69.06 - lr: 0.006250\n",
            "2022-12-12 11:43:47,301 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:43:47,302 EPOCH 71 done: loss 0.2616 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:43:47,758 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:43:47,767 DEV : loss 0.26059040427207947 - f1-score (micro avg)  0.6567\n",
            "2022-12-12 11:43:47,775 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:43:47,777 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:43:48,660 epoch 72 - iter 2/25 - loss 0.26555926 - samples/sec: 72.59 - lr: 0.006250\n",
            "2022-12-12 11:43:50,769 epoch 72 - iter 4/25 - loss 0.25344172 - samples/sec: 30.36 - lr: 0.006250\n",
            "2022-12-12 11:43:51,966 epoch 72 - iter 6/25 - loss 0.25657769 - samples/sec: 53.51 - lr: 0.006250\n",
            "2022-12-12 11:43:53,001 epoch 72 - iter 8/25 - loss 0.25660920 - samples/sec: 61.97 - lr: 0.006250\n",
            "2022-12-12 11:43:53,939 epoch 72 - iter 10/25 - loss 0.26105160 - samples/sec: 68.32 - lr: 0.006250\n",
            "2022-12-12 11:43:55,137 epoch 72 - iter 12/25 - loss 0.25944987 - samples/sec: 53.52 - lr: 0.006250\n",
            "2022-12-12 11:43:56,196 epoch 72 - iter 14/25 - loss 0.26584177 - samples/sec: 60.48 - lr: 0.006250\n",
            "2022-12-12 11:43:57,062 epoch 72 - iter 16/25 - loss 0.26442337 - samples/sec: 74.08 - lr: 0.006250\n",
            "2022-12-12 11:43:57,922 epoch 72 - iter 18/25 - loss 0.26697768 - samples/sec: 74.49 - lr: 0.006250\n",
            "2022-12-12 11:43:59,006 epoch 72 - iter 20/25 - loss 0.26397322 - samples/sec: 59.14 - lr: 0.006250\n",
            "2022-12-12 11:44:00,374 epoch 72 - iter 22/25 - loss 0.26387764 - samples/sec: 46.84 - lr: 0.006250\n",
            "2022-12-12 11:44:01,386 epoch 72 - iter 24/25 - loss 0.26693797 - samples/sec: 63.30 - lr: 0.006250\n",
            "2022-12-12 11:44:01,455 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:44:01,456 EPOCH 72 done: loss 0.2666 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:44:01,954 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:44:01,964 DEV : loss 0.2612302899360657 - f1-score (micro avg)  0.6558\n",
            "2022-12-12 11:44:01,973 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 11:44:01,975 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:44:02,675 epoch 73 - iter 2/25 - loss 0.27037626 - samples/sec: 91.61 - lr: 0.006250\n",
            "2022-12-12 11:44:03,603 epoch 73 - iter 4/25 - loss 0.25989691 - samples/sec: 69.07 - lr: 0.006250\n",
            "2022-12-12 11:44:06,063 epoch 73 - iter 6/25 - loss 0.25826810 - samples/sec: 26.04 - lr: 0.006250\n",
            "2022-12-12 11:44:07,077 epoch 73 - iter 8/25 - loss 0.25537694 - samples/sec: 63.15 - lr: 0.006250\n",
            "2022-12-12 11:44:07,936 epoch 73 - iter 10/25 - loss 0.25508776 - samples/sec: 74.65 - lr: 0.006250\n",
            "2022-12-12 11:44:08,683 epoch 73 - iter 12/25 - loss 0.24807898 - samples/sec: 85.81 - lr: 0.006250\n",
            "2022-12-12 11:44:09,470 epoch 73 - iter 14/25 - loss 0.25017409 - samples/sec: 81.41 - lr: 0.006250\n",
            "2022-12-12 11:44:10,784 epoch 73 - iter 16/25 - loss 0.25150282 - samples/sec: 48.78 - lr: 0.006250\n",
            "2022-12-12 11:44:11,936 epoch 73 - iter 18/25 - loss 0.25474515 - samples/sec: 55.60 - lr: 0.006250\n",
            "2022-12-12 11:44:13,129 epoch 73 - iter 20/25 - loss 0.25698023 - samples/sec: 53.69 - lr: 0.006250\n",
            "2022-12-12 11:44:14,279 epoch 73 - iter 22/25 - loss 0.25692857 - samples/sec: 55.73 - lr: 0.006250\n",
            "2022-12-12 11:44:15,312 epoch 73 - iter 24/25 - loss 0.25829683 - samples/sec: 62.00 - lr: 0.006250\n",
            "2022-12-12 11:44:15,392 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:44:15,394 EPOCH 73 done: loss 0.2580 - lr 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  6.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:44:16,013 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:44:16,022 DEV : loss 0.26052001118659973 - f1-score (micro avg)  0.6528\n",
            "2022-12-12 11:44:16,031 Epoch    73: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2022-12-12 11:44:16,033 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 11:44:16,034 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:44:17,361 epoch 74 - iter 2/25 - loss 0.29764234 - samples/sec: 48.27 - lr: 0.003125\n",
            "2022-12-12 11:44:19,969 epoch 74 - iter 4/25 - loss 0.27116590 - samples/sec: 24.55 - lr: 0.003125\n",
            "2022-12-12 11:44:21,156 epoch 74 - iter 6/25 - loss 0.27028923 - samples/sec: 54.01 - lr: 0.003125\n",
            "2022-12-12 11:44:22,173 epoch 74 - iter 8/25 - loss 0.26275360 - samples/sec: 62.97 - lr: 0.003125\n",
            "2022-12-12 11:44:23,158 epoch 74 - iter 10/25 - loss 0.26590911 - samples/sec: 65.08 - lr: 0.003125\n",
            "2022-12-12 11:44:24,466 epoch 74 - iter 12/25 - loss 0.26457166 - samples/sec: 48.99 - lr: 0.003125\n",
            "2022-12-12 11:44:25,705 epoch 74 - iter 14/25 - loss 0.26184080 - samples/sec: 51.73 - lr: 0.003125\n",
            "2022-12-12 11:44:26,933 epoch 74 - iter 16/25 - loss 0.25750017 - samples/sec: 52.17 - lr: 0.003125\n",
            "2022-12-12 11:44:28,025 epoch 74 - iter 18/25 - loss 0.25619821 - samples/sec: 58.71 - lr: 0.003125\n",
            "2022-12-12 11:44:28,826 epoch 74 - iter 20/25 - loss 0.25438682 - samples/sec: 80.03 - lr: 0.003125\n",
            "2022-12-12 11:44:29,792 epoch 74 - iter 22/25 - loss 0.25413027 - samples/sec: 66.32 - lr: 0.003125\n",
            "2022-12-12 11:44:30,762 epoch 74 - iter 24/25 - loss 0.25322618 - samples/sec: 66.05 - lr: 0.003125\n",
            "2022-12-12 11:44:30,847 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:44:30,848 EPOCH 74 done: loss 0.2534 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:44:31,322 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:44:31,329 DEV : loss 0.259115993976593 - f1-score (micro avg)  0.6596\n",
            "2022-12-12 11:44:31,338 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:44:31,340 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:44:32,381 epoch 75 - iter 2/25 - loss 0.27202282 - samples/sec: 61.57 - lr: 0.003125\n",
            "2022-12-12 11:44:33,212 epoch 75 - iter 4/25 - loss 0.26527376 - samples/sec: 77.18 - lr: 0.003125\n",
            "2022-12-12 11:44:34,047 epoch 75 - iter 6/25 - loss 0.27141666 - samples/sec: 76.77 - lr: 0.003125\n",
            "2022-12-12 11:44:34,953 epoch 75 - iter 8/25 - loss 0.27820584 - samples/sec: 70.76 - lr: 0.003125\n",
            "2022-12-12 11:44:35,880 epoch 75 - iter 10/25 - loss 0.27826746 - samples/sec: 69.11 - lr: 0.003125\n",
            "2022-12-12 11:44:37,103 epoch 75 - iter 12/25 - loss 0.28021035 - samples/sec: 52.41 - lr: 0.003125\n",
            "2022-12-12 11:44:38,062 epoch 75 - iter 14/25 - loss 0.27537842 - samples/sec: 66.82 - lr: 0.003125\n",
            "2022-12-12 11:44:40,396 epoch 75 - iter 16/25 - loss 0.27476151 - samples/sec: 27.43 - lr: 0.003125\n",
            "2022-12-12 11:44:41,575 epoch 75 - iter 18/25 - loss 0.27635007 - samples/sec: 54.35 - lr: 0.003125\n",
            "2022-12-12 11:44:42,440 epoch 75 - iter 20/25 - loss 0.27386776 - samples/sec: 74.10 - lr: 0.003125\n",
            "2022-12-12 11:44:43,492 epoch 75 - iter 22/25 - loss 0.27051205 - samples/sec: 60.89 - lr: 0.003125\n",
            "2022-12-12 11:44:44,491 epoch 75 - iter 24/25 - loss 0.26811000 - samples/sec: 64.17 - lr: 0.003125\n",
            "2022-12-12 11:44:44,590 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:44:44,591 EPOCH 75 done: loss 0.2687 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:44:45,052 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:44:45,061 DEV : loss 0.26033222675323486 - f1-score (micro avg)  0.6607\n",
            "2022-12-12 11:44:45,068 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:44:45,070 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:44:46,049 epoch 76 - iter 2/25 - loss 0.25655944 - samples/sec: 65.48 - lr: 0.003125\n",
            "2022-12-12 11:44:47,032 epoch 76 - iter 4/25 - loss 0.23139119 - samples/sec: 65.19 - lr: 0.003125\n",
            "2022-12-12 11:44:49,213 epoch 76 - iter 6/25 - loss 0.24609413 - samples/sec: 29.36 - lr: 0.003125\n",
            "2022-12-12 11:44:50,090 epoch 76 - iter 8/25 - loss 0.24785333 - samples/sec: 73.05 - lr: 0.003125\n",
            "2022-12-12 11:44:51,081 epoch 76 - iter 10/25 - loss 0.25075956 - samples/sec: 64.66 - lr: 0.003125\n",
            "2022-12-12 11:44:52,075 epoch 76 - iter 12/25 - loss 0.25521176 - samples/sec: 64.48 - lr: 0.003125\n",
            "2022-12-12 11:44:53,271 epoch 76 - iter 14/25 - loss 0.25981514 - samples/sec: 53.57 - lr: 0.003125\n",
            "2022-12-12 11:44:54,325 epoch 76 - iter 16/25 - loss 0.26250343 - samples/sec: 60.79 - lr: 0.003125\n",
            "2022-12-12 11:44:55,406 epoch 76 - iter 18/25 - loss 0.25782421 - samples/sec: 59.29 - lr: 0.003125\n",
            "2022-12-12 11:44:56,702 epoch 76 - iter 20/25 - loss 0.26184374 - samples/sec: 49.47 - lr: 0.003125\n",
            "2022-12-12 11:44:57,754 epoch 76 - iter 22/25 - loss 0.26337817 - samples/sec: 60.91 - lr: 0.003125\n",
            "2022-12-12 11:44:58,864 epoch 76 - iter 24/25 - loss 0.26324377 - samples/sec: 57.70 - lr: 0.003125\n",
            "2022-12-12 11:44:58,952 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:44:58,953 EPOCH 76 done: loss 0.2628 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:44:59,401 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:44:59,408 DEV : loss 0.26010578870773315 - f1-score (micro avg)  0.6627\n",
            "2022-12-12 11:44:59,418 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 11:44:59,420 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:45:00,364 epoch 77 - iter 2/25 - loss 0.26410275 - samples/sec: 67.85 - lr: 0.003125\n",
            "2022-12-12 11:45:02,719 epoch 77 - iter 4/25 - loss 0.24620246 - samples/sec: 27.19 - lr: 0.003125\n",
            "2022-12-12 11:45:04,204 epoch 77 - iter 6/25 - loss 0.24944924 - samples/sec: 43.14 - lr: 0.003125\n",
            "2022-12-12 11:45:05,072 epoch 77 - iter 8/25 - loss 0.25460529 - samples/sec: 73.91 - lr: 0.003125\n",
            "2022-12-12 11:45:05,927 epoch 77 - iter 10/25 - loss 0.25646724 - samples/sec: 74.97 - lr: 0.003125\n",
            "2022-12-12 11:45:06,732 epoch 77 - iter 12/25 - loss 0.25701588 - samples/sec: 79.64 - lr: 0.003125\n",
            "2022-12-12 11:45:07,618 epoch 77 - iter 14/25 - loss 0.26207842 - samples/sec: 72.28 - lr: 0.003125\n",
            "2022-12-12 11:45:08,810 epoch 77 - iter 16/25 - loss 0.26840208 - samples/sec: 53.76 - lr: 0.003125\n",
            "2022-12-12 11:45:10,047 epoch 77 - iter 18/25 - loss 0.26717373 - samples/sec: 51.79 - lr: 0.003125\n",
            "2022-12-12 11:45:11,189 epoch 77 - iter 20/25 - loss 0.26627764 - samples/sec: 56.12 - lr: 0.003125\n",
            "2022-12-12 11:45:12,100 epoch 77 - iter 22/25 - loss 0.26722738 - samples/sec: 70.37 - lr: 0.003125\n",
            "2022-12-12 11:45:13,088 epoch 77 - iter 24/25 - loss 0.26664740 - samples/sec: 64.87 - lr: 0.003125\n",
            "2022-12-12 11:45:13,137 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:45:13,138 EPOCH 77 done: loss 0.2665 - lr 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:45:13,595 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:45:13,604 DEV : loss 0.26077553629875183 - f1-score (micro avg)  0.6578\n",
            "2022-12-12 11:45:13,613 Epoch    77: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2022-12-12 11:45:13,615 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 11:45:13,616 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:45:16,000 epoch 78 - iter 2/25 - loss 0.23744466 - samples/sec: 26.86 - lr: 0.001563\n",
            "2022-12-12 11:45:17,209 epoch 78 - iter 4/25 - loss 0.25765668 - samples/sec: 53.02 - lr: 0.001563\n",
            "2022-12-12 11:45:18,330 epoch 78 - iter 6/25 - loss 0.25759974 - samples/sec: 57.13 - lr: 0.001563\n",
            "2022-12-12 11:45:19,452 epoch 78 - iter 8/25 - loss 0.25860389 - samples/sec: 57.12 - lr: 0.001563\n",
            "2022-12-12 11:45:20,507 epoch 78 - iter 10/25 - loss 0.25989337 - samples/sec: 60.71 - lr: 0.001563\n",
            "2022-12-12 11:45:21,458 epoch 78 - iter 12/25 - loss 0.26535189 - samples/sec: 67.37 - lr: 0.001563\n",
            "2022-12-12 11:45:22,764 epoch 78 - iter 14/25 - loss 0.26746176 - samples/sec: 49.07 - lr: 0.001563\n",
            "2022-12-12 11:45:23,590 epoch 78 - iter 16/25 - loss 0.26206410 - samples/sec: 77.60 - lr: 0.001563\n",
            "2022-12-12 11:45:24,678 epoch 78 - iter 18/25 - loss 0.26280916 - samples/sec: 58.92 - lr: 0.001563\n",
            "2022-12-12 11:45:25,718 epoch 78 - iter 20/25 - loss 0.26130710 - samples/sec: 61.62 - lr: 0.001563\n",
            "2022-12-12 11:45:26,761 epoch 78 - iter 22/25 - loss 0.26367536 - samples/sec: 61.44 - lr: 0.001563\n",
            "2022-12-12 11:45:27,916 epoch 78 - iter 24/25 - loss 0.26512851 - samples/sec: 55.46 - lr: 0.001563\n",
            "2022-12-12 11:45:28,000 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:45:28,001 EPOCH 78 done: loss 0.2653 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:45:28,461 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:45:28,470 DEV : loss 0.26148906350135803 - f1-score (micro avg)  0.6578\n",
            "2022-12-12 11:45:28,481 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:45:28,483 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:45:29,445 epoch 79 - iter 2/25 - loss 0.25229326 - samples/sec: 66.68 - lr: 0.001563\n",
            "2022-12-12 11:45:30,413 epoch 79 - iter 4/25 - loss 0.25703590 - samples/sec: 66.17 - lr: 0.001563\n",
            "2022-12-12 11:45:31,666 epoch 79 - iter 6/25 - loss 0.26529903 - samples/sec: 51.16 - lr: 0.001563\n",
            "2022-12-12 11:45:32,488 epoch 79 - iter 8/25 - loss 0.25374341 - samples/sec: 77.95 - lr: 0.001563\n",
            "2022-12-12 11:45:33,310 epoch 79 - iter 10/25 - loss 0.26447244 - samples/sec: 78.00 - lr: 0.001563\n",
            "2022-12-12 11:45:34,295 epoch 79 - iter 12/25 - loss 0.27113488 - samples/sec: 65.05 - lr: 0.001563\n",
            "2022-12-12 11:45:35,394 epoch 79 - iter 14/25 - loss 0.26448744 - samples/sec: 58.35 - lr: 0.001563\n",
            "2022-12-12 11:45:36,381 epoch 79 - iter 16/25 - loss 0.26420435 - samples/sec: 64.94 - lr: 0.001563\n",
            "2022-12-12 11:45:37,574 epoch 79 - iter 18/25 - loss 0.26228260 - samples/sec: 53.70 - lr: 0.001563\n",
            "2022-12-12 11:45:39,898 epoch 79 - iter 20/25 - loss 0.26440222 - samples/sec: 27.55 - lr: 0.001563\n",
            "2022-12-12 11:45:41,163 epoch 79 - iter 22/25 - loss 0.26593937 - samples/sec: 50.65 - lr: 0.001563\n",
            "2022-12-12 11:45:42,127 epoch 79 - iter 24/25 - loss 0.26416641 - samples/sec: 66.51 - lr: 0.001563\n",
            "2022-12-12 11:45:42,197 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:45:42,198 EPOCH 79 done: loss 0.2641 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:45:42,682 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:45:42,690 DEV : loss 0.26147228479385376 - f1-score (micro avg)  0.6598\n",
            "2022-12-12 11:45:42,698 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:45:42,700 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:45:43,959 epoch 80 - iter 2/25 - loss 0.27306344 - samples/sec: 50.90 - lr: 0.001563\n",
            "2022-12-12 11:45:44,808 epoch 80 - iter 4/25 - loss 0.26338961 - samples/sec: 75.44 - lr: 0.001563\n",
            "2022-12-12 11:45:46,034 epoch 80 - iter 6/25 - loss 0.26883660 - samples/sec: 52.28 - lr: 0.001563\n",
            "2022-12-12 11:45:48,432 epoch 80 - iter 8/25 - loss 0.26728416 - samples/sec: 26.70 - lr: 0.001563\n",
            "2022-12-12 11:45:49,405 epoch 80 - iter 10/25 - loss 0.27216128 - samples/sec: 65.91 - lr: 0.001563\n",
            "2022-12-12 11:45:50,531 epoch 80 - iter 12/25 - loss 0.27045471 - samples/sec: 56.89 - lr: 0.001563\n",
            "2022-12-12 11:45:51,460 epoch 80 - iter 14/25 - loss 0.26812934 - samples/sec: 68.97 - lr: 0.001563\n",
            "2022-12-12 11:45:52,321 epoch 80 - iter 16/25 - loss 0.26934331 - samples/sec: 74.48 - lr: 0.001563\n",
            "2022-12-12 11:45:53,539 epoch 80 - iter 18/25 - loss 0.26561232 - samples/sec: 52.58 - lr: 0.001563\n",
            "2022-12-12 11:45:54,459 epoch 80 - iter 20/25 - loss 0.26669800 - samples/sec: 69.68 - lr: 0.001563\n",
            "2022-12-12 11:45:55,672 epoch 80 - iter 22/25 - loss 0.26408658 - samples/sec: 52.84 - lr: 0.001563\n",
            "2022-12-12 11:45:56,675 epoch 80 - iter 24/25 - loss 0.26087640 - samples/sec: 63.85 - lr: 0.001563\n",
            "2022-12-12 11:45:56,740 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:45:56,741 EPOCH 80 done: loss 0.2610 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:45:57,252 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:45:57,259 DEV : loss 0.26173296570777893 - f1-score (micro avg)  0.6578\n",
            "2022-12-12 11:45:57,268 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 11:45:57,270 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:45:58,366 epoch 81 - iter 2/25 - loss 0.29063625 - samples/sec: 58.44 - lr: 0.001563\n",
            "2022-12-12 11:45:59,542 epoch 81 - iter 4/25 - loss 0.27362637 - samples/sec: 54.52 - lr: 0.001563\n",
            "2022-12-12 11:46:00,635 epoch 81 - iter 6/25 - loss 0.27270933 - samples/sec: 58.63 - lr: 0.001563\n",
            "2022-12-12 11:46:03,053 epoch 81 - iter 8/25 - loss 0.27105360 - samples/sec: 26.48 - lr: 0.001563\n",
            "2022-12-12 11:46:04,102 epoch 81 - iter 10/25 - loss 0.26000830 - samples/sec: 61.10 - lr: 0.001563\n",
            "2022-12-12 11:46:05,003 epoch 81 - iter 12/25 - loss 0.26673520 - samples/sec: 71.13 - lr: 0.001563\n",
            "2022-12-12 11:46:05,830 epoch 81 - iter 14/25 - loss 0.27213142 - samples/sec: 77.53 - lr: 0.001563\n",
            "2022-12-12 11:46:07,190 epoch 81 - iter 16/25 - loss 0.26749628 - samples/sec: 47.10 - lr: 0.001563\n",
            "2022-12-12 11:46:08,145 epoch 81 - iter 18/25 - loss 0.26522164 - samples/sec: 67.08 - lr: 0.001563\n",
            "2022-12-12 11:46:09,071 epoch 81 - iter 20/25 - loss 0.26085687 - samples/sec: 69.25 - lr: 0.001563\n",
            "2022-12-12 11:46:10,132 epoch 81 - iter 22/25 - loss 0.26417271 - samples/sec: 60.39 - lr: 0.001563\n",
            "2022-12-12 11:46:11,204 epoch 81 - iter 24/25 - loss 0.26354849 - samples/sec: 59.75 - lr: 0.001563\n",
            "2022-12-12 11:46:11,258 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:46:11,259 EPOCH 81 done: loss 0.2633 - lr 0.001563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:46:11,711 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:46:11,718 DEV : loss 0.2614869177341461 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:46:11,727 Epoch    81: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2022-12-12 11:46:11,728 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 11:46:11,729 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:46:12,931 epoch 82 - iter 2/25 - loss 0.24333885 - samples/sec: 53.28 - lr: 0.000781\n",
            "2022-12-12 11:46:13,821 epoch 82 - iter 4/25 - loss 0.23211623 - samples/sec: 72.01 - lr: 0.000781\n",
            "2022-12-12 11:46:14,737 epoch 82 - iter 6/25 - loss 0.25190825 - samples/sec: 69.95 - lr: 0.000781\n",
            "2022-12-12 11:46:15,627 epoch 82 - iter 8/25 - loss 0.25187957 - samples/sec: 72.04 - lr: 0.000781\n",
            "2022-12-12 11:46:16,755 epoch 82 - iter 10/25 - loss 0.25444579 - samples/sec: 56.79 - lr: 0.000781\n",
            "2022-12-12 11:46:17,812 epoch 82 - iter 12/25 - loss 0.26133205 - samples/sec: 60.66 - lr: 0.000781\n",
            "2022-12-12 11:46:19,007 epoch 82 - iter 14/25 - loss 0.25666162 - samples/sec: 53.61 - lr: 0.000781\n",
            "2022-12-12 11:46:20,102 epoch 82 - iter 16/25 - loss 0.25997953 - samples/sec: 58.55 - lr: 0.000781\n",
            "2022-12-12 11:46:21,293 epoch 82 - iter 18/25 - loss 0.25931292 - samples/sec: 53.78 - lr: 0.000781\n",
            "2022-12-12 11:46:22,361 epoch 82 - iter 20/25 - loss 0.25764746 - samples/sec: 60.03 - lr: 0.000781\n",
            "2022-12-12 11:46:23,390 epoch 82 - iter 22/25 - loss 0.26040298 - samples/sec: 62.27 - lr: 0.000781\n",
            "2022-12-12 11:46:25,719 epoch 82 - iter 24/25 - loss 0.26002847 - samples/sec: 27.49 - lr: 0.000781\n",
            "2022-12-12 11:46:25,800 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:46:25,801 EPOCH 82 done: loss 0.2603 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:46:26,260 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:46:26,267 DEV : loss 0.261610209941864 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:46:26,277 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:46:26,278 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:46:27,356 epoch 83 - iter 2/25 - loss 0.24191784 - samples/sec: 59.44 - lr: 0.000781\n",
            "2022-12-12 11:46:28,391 epoch 83 - iter 4/25 - loss 0.28286152 - samples/sec: 61.95 - lr: 0.000781\n",
            "2022-12-12 11:46:29,414 epoch 83 - iter 6/25 - loss 0.26719009 - samples/sec: 62.60 - lr: 0.000781\n",
            "2022-12-12 11:46:30,183 epoch 83 - iter 8/25 - loss 0.28095537 - samples/sec: 83.49 - lr: 0.000781\n",
            "2022-12-12 11:46:31,310 epoch 83 - iter 10/25 - loss 0.28094168 - samples/sec: 56.83 - lr: 0.000781\n",
            "2022-12-12 11:46:32,407 epoch 83 - iter 12/25 - loss 0.27962144 - samples/sec: 58.45 - lr: 0.000781\n",
            "2022-12-12 11:46:33,591 epoch 83 - iter 14/25 - loss 0.27960550 - samples/sec: 54.10 - lr: 0.000781\n",
            "2022-12-12 11:46:34,647 epoch 83 - iter 16/25 - loss 0.28073961 - samples/sec: 60.72 - lr: 0.000781\n",
            "2022-12-12 11:46:35,824 epoch 83 - iter 18/25 - loss 0.27857185 - samples/sec: 54.45 - lr: 0.000781\n",
            "2022-12-12 11:46:36,561 epoch 83 - iter 20/25 - loss 0.27367475 - samples/sec: 87.00 - lr: 0.000781\n",
            "2022-12-12 11:46:38,746 epoch 83 - iter 22/25 - loss 0.26608543 - samples/sec: 29.30 - lr: 0.000781\n",
            "2022-12-12 11:46:39,645 epoch 83 - iter 24/25 - loss 0.26527660 - samples/sec: 71.36 - lr: 0.000781\n",
            "2022-12-12 11:46:39,732 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:46:39,733 EPOCH 83 done: loss 0.2653 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  6.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:46:40,323 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:46:40,330 DEV : loss 0.2617023289203644 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:46:40,342 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:46:40,344 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:46:41,244 epoch 84 - iter 2/25 - loss 0.26790541 - samples/sec: 71.16 - lr: 0.000781\n",
            "2022-12-12 11:46:42,638 epoch 84 - iter 4/25 - loss 0.23410546 - samples/sec: 45.97 - lr: 0.000781\n",
            "2022-12-12 11:46:43,660 epoch 84 - iter 6/25 - loss 0.24288443 - samples/sec: 62.70 - lr: 0.000781\n",
            "2022-12-12 11:46:44,983 epoch 84 - iter 8/25 - loss 0.25086989 - samples/sec: 48.41 - lr: 0.000781\n",
            "2022-12-12 11:46:45,817 epoch 84 - iter 10/25 - loss 0.25672071 - samples/sec: 76.86 - lr: 0.000781\n",
            "2022-12-12 11:46:46,851 epoch 84 - iter 12/25 - loss 0.25245061 - samples/sec: 61.98 - lr: 0.000781\n",
            "2022-12-12 11:46:48,087 epoch 84 - iter 14/25 - loss 0.25646845 - samples/sec: 51.86 - lr: 0.000781\n",
            "2022-12-12 11:46:50,400 epoch 84 - iter 16/25 - loss 0.25578948 - samples/sec: 27.68 - lr: 0.000781\n",
            "2022-12-12 11:46:51,305 epoch 84 - iter 18/25 - loss 0.25156747 - samples/sec: 70.81 - lr: 0.000781\n",
            "2022-12-12 11:46:52,196 epoch 84 - iter 20/25 - loss 0.25068623 - samples/sec: 72.00 - lr: 0.000781\n",
            "2022-12-12 11:46:53,051 epoch 84 - iter 22/25 - loss 0.25126359 - samples/sec: 74.91 - lr: 0.000781\n",
            "2022-12-12 11:46:54,103 epoch 84 - iter 24/25 - loss 0.25484600 - samples/sec: 60.91 - lr: 0.000781\n",
            "2022-12-12 11:46:54,169 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:46:54,170 EPOCH 84 done: loss 0.2559 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:46:54,627 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:46:54,634 DEV : loss 0.26181963086128235 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:46:54,644 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 11:46:54,646 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:46:55,842 epoch 85 - iter 2/25 - loss 0.27489437 - samples/sec: 53.60 - lr: 0.000781\n",
            "2022-12-12 11:46:57,030 epoch 85 - iter 4/25 - loss 0.25802898 - samples/sec: 53.91 - lr: 0.000781\n",
            "2022-12-12 11:46:57,877 epoch 85 - iter 6/25 - loss 0.25775475 - samples/sec: 75.73 - lr: 0.000781\n",
            "2022-12-12 11:46:58,963 epoch 85 - iter 8/25 - loss 0.25854366 - samples/sec: 59.01 - lr: 0.000781\n",
            "2022-12-12 11:47:00,004 epoch 85 - iter 10/25 - loss 0.25403063 - samples/sec: 61.55 - lr: 0.000781\n",
            "2022-12-12 11:47:02,598 epoch 85 - iter 12/25 - loss 0.25671873 - samples/sec: 24.68 - lr: 0.000781\n",
            "2022-12-12 11:47:03,666 epoch 85 - iter 14/25 - loss 0.25487029 - samples/sec: 59.98 - lr: 0.000781\n",
            "2022-12-12 11:47:04,569 epoch 85 - iter 16/25 - loss 0.25877253 - samples/sec: 70.95 - lr: 0.000781\n",
            "2022-12-12 11:47:05,703 epoch 85 - iter 18/25 - loss 0.26211710 - samples/sec: 56.53 - lr: 0.000781\n",
            "2022-12-12 11:47:06,798 epoch 85 - iter 20/25 - loss 0.26307814 - samples/sec: 58.52 - lr: 0.000781\n",
            "2022-12-12 11:47:07,666 epoch 85 - iter 22/25 - loss 0.26124630 - samples/sec: 73.80 - lr: 0.000781\n",
            "2022-12-12 11:47:08,594 epoch 85 - iter 24/25 - loss 0.26332904 - samples/sec: 69.04 - lr: 0.000781\n",
            "2022-12-12 11:47:08,676 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:47:08,677 EPOCH 85 done: loss 0.2633 - lr 0.000781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:47:09,184 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:47:09,195 DEV : loss 0.26179251074790955 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:47:09,205 Epoch    85: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2022-12-12 11:47:09,206 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 11:47:09,207 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:47:10,056 epoch 86 - iter 2/25 - loss 0.24609881 - samples/sec: 75.49 - lr: 0.000391\n",
            "2022-12-12 11:47:10,774 epoch 86 - iter 4/25 - loss 0.24028115 - samples/sec: 89.27 - lr: 0.000391\n",
            "2022-12-12 11:47:12,012 epoch 86 - iter 6/25 - loss 0.25901034 - samples/sec: 51.75 - lr: 0.000391\n",
            "2022-12-12 11:47:13,150 epoch 86 - iter 8/25 - loss 0.25652402 - samples/sec: 56.34 - lr: 0.000391\n",
            "2022-12-12 11:47:15,585 epoch 86 - iter 10/25 - loss 0.25981885 - samples/sec: 26.30 - lr: 0.000391\n",
            "2022-12-12 11:47:16,502 epoch 86 - iter 12/25 - loss 0.26185877 - samples/sec: 69.86 - lr: 0.000391\n",
            "2022-12-12 11:47:17,723 epoch 86 - iter 14/25 - loss 0.26302794 - samples/sec: 52.48 - lr: 0.000391\n",
            "2022-12-12 11:47:18,522 epoch 86 - iter 16/25 - loss 0.26276557 - samples/sec: 80.17 - lr: 0.000391\n",
            "2022-12-12 11:47:19,497 epoch 86 - iter 18/25 - loss 0.26807878 - samples/sec: 65.77 - lr: 0.000391\n",
            "2022-12-12 11:47:20,824 epoch 86 - iter 20/25 - loss 0.26535265 - samples/sec: 48.28 - lr: 0.000391\n",
            "2022-12-12 11:47:21,702 epoch 86 - iter 22/25 - loss 0.26230686 - samples/sec: 72.96 - lr: 0.000391\n",
            "2022-12-12 11:47:22,838 epoch 86 - iter 24/25 - loss 0.25857028 - samples/sec: 56.41 - lr: 0.000391\n",
            "2022-12-12 11:47:22,948 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:47:22,949 EPOCH 86 done: loss 0.2589 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:47:23,420 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:47:23,429 DEV : loss 0.26166436076164246 - f1-score (micro avg)  0.6598\n",
            "2022-12-12 11:47:23,438 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:47:23,440 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:47:24,532 epoch 87 - iter 2/25 - loss 0.27548417 - samples/sec: 58.65 - lr: 0.000391\n",
            "2022-12-12 11:47:25,630 epoch 87 - iter 4/25 - loss 0.27304299 - samples/sec: 58.35 - lr: 0.000391\n",
            "2022-12-12 11:47:26,590 epoch 87 - iter 6/25 - loss 0.26365968 - samples/sec: 66.78 - lr: 0.000391\n",
            "2022-12-12 11:47:27,602 epoch 87 - iter 8/25 - loss 0.25939811 - samples/sec: 63.29 - lr: 0.000391\n",
            "2022-12-12 11:47:28,653 epoch 87 - iter 10/25 - loss 0.26053087 - samples/sec: 61.01 - lr: 0.000391\n",
            "2022-12-12 11:47:29,513 epoch 87 - iter 12/25 - loss 0.25488090 - samples/sec: 74.54 - lr: 0.000391\n",
            "2022-12-12 11:47:30,199 epoch 87 - iter 14/25 - loss 0.25660161 - samples/sec: 93.49 - lr: 0.000391\n",
            "2022-12-12 11:47:31,121 epoch 87 - iter 16/25 - loss 0.25606379 - samples/sec: 69.49 - lr: 0.000391\n",
            "2022-12-12 11:47:32,182 epoch 87 - iter 18/25 - loss 0.25683499 - samples/sec: 60.42 - lr: 0.000391\n",
            "2022-12-12 11:47:33,303 epoch 87 - iter 20/25 - loss 0.25561058 - samples/sec: 57.15 - lr: 0.000391\n",
            "2022-12-12 11:47:34,336 epoch 87 - iter 22/25 - loss 0.25742711 - samples/sec: 62.03 - lr: 0.000391\n",
            "2022-12-12 11:47:36,780 epoch 87 - iter 24/25 - loss 0.25392554 - samples/sec: 26.22 - lr: 0.000391\n",
            "2022-12-12 11:47:36,835 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:47:36,836 EPOCH 87 done: loss 0.2537 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  7.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:47:37,370 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:47:37,378 DEV : loss 0.2618527114391327 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:47:37,386 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:47:37,388 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:47:38,412 epoch 88 - iter 2/25 - loss 0.24605132 - samples/sec: 62.58 - lr: 0.000391\n",
            "2022-12-12 11:47:39,414 epoch 88 - iter 4/25 - loss 0.25195033 - samples/sec: 63.95 - lr: 0.000391\n",
            "2022-12-12 11:47:40,617 epoch 88 - iter 6/25 - loss 0.25802094 - samples/sec: 53.27 - lr: 0.000391\n",
            "2022-12-12 11:47:41,824 epoch 88 - iter 8/25 - loss 0.25361648 - samples/sec: 53.09 - lr: 0.000391\n",
            "2022-12-12 11:47:42,904 epoch 88 - iter 10/25 - loss 0.25804801 - samples/sec: 59.36 - lr: 0.000391\n",
            "2022-12-12 11:47:43,968 epoch 88 - iter 12/25 - loss 0.25715751 - samples/sec: 60.20 - lr: 0.000391\n",
            "2022-12-12 11:47:45,153 epoch 88 - iter 14/25 - loss 0.25881405 - samples/sec: 54.04 - lr: 0.000391\n",
            "2022-12-12 11:47:46,090 epoch 88 - iter 16/25 - loss 0.25625259 - samples/sec: 68.45 - lr: 0.000391\n",
            "2022-12-12 11:47:46,891 epoch 88 - iter 18/25 - loss 0.25615372 - samples/sec: 80.00 - lr: 0.000391\n",
            "2022-12-12 11:47:48,053 epoch 88 - iter 20/25 - loss 0.25674502 - samples/sec: 55.14 - lr: 0.000391\n",
            "2022-12-12 11:47:48,984 epoch 88 - iter 22/25 - loss 0.26201460 - samples/sec: 68.82 - lr: 0.000391\n",
            "2022-12-12 11:47:51,374 epoch 88 - iter 24/25 - loss 0.25991212 - samples/sec: 26.80 - lr: 0.000391\n",
            "2022-12-12 11:47:51,441 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:47:51,442 EPOCH 88 done: loss 0.2602 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:47:51,919 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:47:51,927 DEV : loss 0.26191282272338867 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:47:51,936 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 11:47:51,937 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:47:52,821 epoch 89 - iter 2/25 - loss 0.25253024 - samples/sec: 72.51 - lr: 0.000391\n",
            "2022-12-12 11:47:55,261 epoch 89 - iter 4/25 - loss 0.24341588 - samples/sec: 26.24 - lr: 0.000391\n",
            "2022-12-12 11:47:56,289 epoch 89 - iter 6/25 - loss 0.25455089 - samples/sec: 62.39 - lr: 0.000391\n",
            "2022-12-12 11:47:57,182 epoch 89 - iter 8/25 - loss 0.24636264 - samples/sec: 71.73 - lr: 0.000391\n",
            "2022-12-12 11:47:58,324 epoch 89 - iter 10/25 - loss 0.24769382 - samples/sec: 56.12 - lr: 0.000391\n",
            "2022-12-12 11:47:59,578 epoch 89 - iter 12/25 - loss 0.25498796 - samples/sec: 51.07 - lr: 0.000391\n",
            "2022-12-12 11:48:00,501 epoch 89 - iter 14/25 - loss 0.25947926 - samples/sec: 69.48 - lr: 0.000391\n",
            "2022-12-12 11:48:01,602 epoch 89 - iter 16/25 - loss 0.26095788 - samples/sec: 58.20 - lr: 0.000391\n",
            "2022-12-12 11:48:02,609 epoch 89 - iter 18/25 - loss 0.26415110 - samples/sec: 63.62 - lr: 0.000391\n",
            "2022-12-12 11:48:03,618 epoch 89 - iter 20/25 - loss 0.25884399 - samples/sec: 63.54 - lr: 0.000391\n",
            "2022-12-12 11:48:04,381 epoch 89 - iter 22/25 - loss 0.25688074 - samples/sec: 84.07 - lr: 0.000391\n",
            "2022-12-12 11:48:05,428 epoch 89 - iter 24/25 - loss 0.25663941 - samples/sec: 61.17 - lr: 0.000391\n",
            "2022-12-12 11:48:05,509 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:48:05,510 EPOCH 89 done: loss 0.2567 - lr 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:48:05,946 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:48:05,955 DEV : loss 0.2618909776210785 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:48:05,962 Epoch    89: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2022-12-12 11:48:05,964 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 11:48:05,965 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:48:06,752 epoch 90 - iter 2/25 - loss 0.25789565 - samples/sec: 81.44 - lr: 0.000195\n",
            "2022-12-12 11:48:08,922 epoch 90 - iter 4/25 - loss 0.24110459 - samples/sec: 29.52 - lr: 0.000195\n",
            "2022-12-12 11:48:09,861 epoch 90 - iter 6/25 - loss 0.25264321 - samples/sec: 68.29 - lr: 0.000195\n",
            "2022-12-12 11:48:10,754 epoch 90 - iter 8/25 - loss 0.25884017 - samples/sec: 71.76 - lr: 0.000195\n",
            "2022-12-12 11:48:11,951 epoch 90 - iter 10/25 - loss 0.26845957 - samples/sec: 53.53 - lr: 0.000195\n",
            "2022-12-12 11:48:13,023 epoch 90 - iter 12/25 - loss 0.26506201 - samples/sec: 59.74 - lr: 0.000195\n",
            "2022-12-12 11:48:14,120 epoch 90 - iter 14/25 - loss 0.25958815 - samples/sec: 58.45 - lr: 0.000195\n",
            "2022-12-12 11:48:15,058 epoch 90 - iter 16/25 - loss 0.26276275 - samples/sec: 68.30 - lr: 0.000195\n",
            "2022-12-12 11:48:16,002 epoch 90 - iter 18/25 - loss 0.26751794 - samples/sec: 67.89 - lr: 0.000195\n",
            "2022-12-12 11:48:17,059 epoch 90 - iter 20/25 - loss 0.26493744 - samples/sec: 60.62 - lr: 0.000195\n",
            "2022-12-12 11:48:17,909 epoch 90 - iter 22/25 - loss 0.26444776 - samples/sec: 75.44 - lr: 0.000195\n",
            "2022-12-12 11:48:18,772 epoch 90 - iter 24/25 - loss 0.26531493 - samples/sec: 74.28 - lr: 0.000195\n",
            "2022-12-12 11:48:18,842 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:48:18,843 EPOCH 90 done: loss 0.2649 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:48:19,294 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:48:19,302 DEV : loss 0.26189085841178894 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:48:19,311 BAD EPOCHS (no improvement): 1\n",
            "2022-12-12 11:48:19,313 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:48:20,175 epoch 91 - iter 2/25 - loss 0.25258351 - samples/sec: 74.29 - lr: 0.000195\n",
            "2022-12-12 11:48:22,611 epoch 91 - iter 4/25 - loss 0.24290835 - samples/sec: 26.29 - lr: 0.000195\n",
            "2022-12-12 11:48:23,686 epoch 91 - iter 6/25 - loss 0.23962378 - samples/sec: 59.59 - lr: 0.000195\n",
            "2022-12-12 11:48:24,872 epoch 91 - iter 8/25 - loss 0.24376670 - samples/sec: 54.07 - lr: 0.000195\n",
            "2022-12-12 11:48:26,192 epoch 91 - iter 10/25 - loss 0.25709046 - samples/sec: 48.54 - lr: 0.000195\n",
            "2022-12-12 11:48:27,198 epoch 91 - iter 12/25 - loss 0.25705473 - samples/sec: 63.66 - lr: 0.000195\n",
            "2022-12-12 11:48:27,985 epoch 91 - iter 14/25 - loss 0.25811961 - samples/sec: 81.52 - lr: 0.000195\n",
            "2022-12-12 11:48:28,945 epoch 91 - iter 16/25 - loss 0.26427634 - samples/sec: 66.77 - lr: 0.000195\n",
            "2022-12-12 11:48:29,906 epoch 91 - iter 18/25 - loss 0.26323019 - samples/sec: 66.71 - lr: 0.000195\n",
            "2022-12-12 11:48:30,715 epoch 91 - iter 20/25 - loss 0.26372503 - samples/sec: 79.24 - lr: 0.000195\n",
            "2022-12-12 11:48:31,815 epoch 91 - iter 22/25 - loss 0.26207658 - samples/sec: 58.26 - lr: 0.000195\n",
            "2022-12-12 11:48:33,024 epoch 91 - iter 24/25 - loss 0.26152886 - samples/sec: 53.00 - lr: 0.000195\n",
            "2022-12-12 11:48:33,123 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:48:33,124 EPOCH 91 done: loss 0.2620 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:48:33,599 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:48:33,611 DEV : loss 0.26188018918037415 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:48:33,624 BAD EPOCHS (no improvement): 2\n",
            "2022-12-12 11:48:33,626 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:48:34,515 epoch 92 - iter 2/25 - loss 0.23836448 - samples/sec: 72.21 - lr: 0.000195\n",
            "2022-12-12 11:48:35,459 epoch 92 - iter 4/25 - loss 0.25233995 - samples/sec: 67.90 - lr: 0.000195\n",
            "2022-12-12 11:48:36,610 epoch 92 - iter 6/25 - loss 0.26131786 - samples/sec: 55.68 - lr: 0.000195\n",
            "2022-12-12 11:48:37,523 epoch 92 - iter 8/25 - loss 0.26671453 - samples/sec: 70.19 - lr: 0.000195\n",
            "2022-12-12 11:48:38,360 epoch 92 - iter 10/25 - loss 0.26443022 - samples/sec: 76.62 - lr: 0.000195\n",
            "2022-12-12 11:48:40,893 epoch 92 - iter 12/25 - loss 0.26470888 - samples/sec: 25.27 - lr: 0.000195\n",
            "2022-12-12 11:48:41,600 epoch 92 - iter 14/25 - loss 0.27046536 - samples/sec: 90.74 - lr: 0.000195\n",
            "2022-12-12 11:48:42,828 epoch 92 - iter 16/25 - loss 0.26605624 - samples/sec: 52.17 - lr: 0.000195\n",
            "2022-12-12 11:48:44,046 epoch 92 - iter 18/25 - loss 0.26178200 - samples/sec: 52.60 - lr: 0.000195\n",
            "2022-12-12 11:48:44,981 epoch 92 - iter 20/25 - loss 0.26245863 - samples/sec: 68.58 - lr: 0.000195\n",
            "2022-12-12 11:48:46,109 epoch 92 - iter 22/25 - loss 0.25971114 - samples/sec: 56.80 - lr: 0.000195\n",
            "2022-12-12 11:48:47,032 epoch 92 - iter 24/25 - loss 0.26334006 - samples/sec: 69.47 - lr: 0.000195\n",
            "2022-12-12 11:48:47,103 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:48:47,104 EPOCH 92 done: loss 0.2631 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  8.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:48:47,569 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:48:47,579 DEV : loss 0.26180300116539 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:48:47,591 BAD EPOCHS (no improvement): 3\n",
            "2022-12-12 11:48:47,593 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:48:48,574 epoch 93 - iter 2/25 - loss 0.27011378 - samples/sec: 65.33 - lr: 0.000195\n",
            "2022-12-12 11:48:49,829 epoch 93 - iter 4/25 - loss 0.26888267 - samples/sec: 51.03 - lr: 0.000195\n",
            "2022-12-12 11:48:50,920 epoch 93 - iter 6/25 - loss 0.26716669 - samples/sec: 58.78 - lr: 0.000195\n",
            "2022-12-12 11:48:52,023 epoch 93 - iter 8/25 - loss 0.25697899 - samples/sec: 58.09 - lr: 0.000195\n",
            "2022-12-12 11:48:53,091 epoch 93 - iter 10/25 - loss 0.26482845 - samples/sec: 59.97 - lr: 0.000195\n",
            "2022-12-12 11:48:53,957 epoch 93 - iter 12/25 - loss 0.26966501 - samples/sec: 74.05 - lr: 0.000195\n",
            "2022-12-12 11:48:55,027 epoch 93 - iter 14/25 - loss 0.27334908 - samples/sec: 59.88 - lr: 0.000195\n",
            "2022-12-12 11:48:56,366 epoch 93 - iter 16/25 - loss 0.27609729 - samples/sec: 47.85 - lr: 0.000195\n",
            "2022-12-12 11:48:57,360 epoch 93 - iter 18/25 - loss 0.27271900 - samples/sec: 64.47 - lr: 0.000195\n",
            "2022-12-12 11:48:58,291 epoch 93 - iter 20/25 - loss 0.27212891 - samples/sec: 68.85 - lr: 0.000195\n",
            "2022-12-12 11:49:00,510 epoch 93 - iter 22/25 - loss 0.26901744 - samples/sec: 28.86 - lr: 0.000195\n",
            "2022-12-12 11:49:01,410 epoch 93 - iter 24/25 - loss 0.26465845 - samples/sec: 71.28 - lr: 0.000195\n",
            "2022-12-12 11:49:01,487 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:49:01,488 EPOCH 93 done: loss 0.2641 - lr 0.000195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:49:01,936 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:49:01,944 DEV : loss 0.2617446184158325 - f1-score (micro avg)  0.6588\n",
            "2022-12-12 11:49:01,952 Epoch    93: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2022-12-12 11:49:01,954 BAD EPOCHS (no improvement): 4\n",
            "2022-12-12 11:49:01,955 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:49:01,955 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:49:01,956 learning rate too small - quitting training!\n",
            "2022-12-12 11:49:01,956 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:49:02,390 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-12 11:49:02,391 loading file resources/taggers/re3d-ner/best-model.pt\n",
            "2022-12-12 11:49:02,640 SequenceTagger predicts: Dictionary with 43 tags: O, S-Organisation, B-Organisation, E-Organisation, I-Organisation, S-Location, B-Location, E-Location, I-Location, S-Person, B-Person, E-Person, I-Person, S-Temporal, B-Temporal, E-Temporal, I-Temporal, S-Quantity, B-Quantity, E-Quantity, I-Quantity, S-Weapon, B-Weapon, E-Weapon, I-Weapon, S-DocumentReference, B-DocumentReference, E-DocumentReference, I-DocumentReference, S-MilitaryPlatform, B-MilitaryPlatform, E-MilitaryPlatform, I-MilitaryPlatform, S-Nationality, B-Nationality, E-Nationality, I-Nationality, S-Money, B-Money, E-Money, I-Money, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  6.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 11:49:03,136 Evaluating as a multi-label problem: False\n",
            "2022-12-12 11:49:03,143 0.6523\t0.6176\t0.6345\t0.4736\n",
            "2022-12-12 11:49:03,143 \n",
            "Results:\n",
            "- F-score (micro) 0.6345\n",
            "- F-score (macro) 0.3169\n",
            "- Accuracy 0.4736\n",
            "\n",
            "By class:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Organisation     0.6496    0.6357    0.6426       140\n",
            "         Location     0.6061    0.5882    0.5970        68\n",
            "           Person     0.7419    0.7419    0.7419        62\n",
            "         Temporal     0.7619    0.8421    0.8000        19\n",
            "         Quantity     0.4000    0.3750    0.3871        16\n",
            "DocumentReference     0.0000    0.0000    0.0000         4\n",
            "           Weapon     0.0000    0.0000    0.0000         4\n",
            " MilitaryPlatform     0.0000    0.0000    0.0000         3\n",
            "      Nationality     0.0000    0.0000    0.0000         2\n",
            "            Money     0.0000    0.0000    0.0000         1\n",
            "\n",
            "        micro avg     0.6523    0.6176    0.6345       319\n",
            "        macro avg     0.3160    0.3183    0.3169       319\n",
            "     weighted avg     0.6239    0.6176    0.6205       319\n",
            "\n",
            "2022-12-12 11:49:03,144 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_score': 0.6344605475040257,\n",
              " 'dev_score_history': [0.0,\n",
              "  0.0,\n",
              "  0.022922636103151862,\n",
              "  0.07027027027027027,\n",
              "  0.11165048543689318,\n",
              "  0.20179372197309417,\n",
              "  0.2570806100217865,\n",
              "  0.3063829787234042,\n",
              "  0.21078431372549017,\n",
              "  0.35958904109589046,\n",
              "  0.34146341463414637,\n",
              "  0.4212523719165086,\n",
              "  0.4725274725274725,\n",
              "  0.39215686274509803,\n",
              "  0.40408163265306124,\n",
              "  0.5130718954248366,\n",
              "  0.46307385229540915,\n",
              "  0.5135135135135136,\n",
              "  0.5103189493433395,\n",
              "  0.543046357615894,\n",
              "  0.56,\n",
              "  0.5537974683544303,\n",
              "  0.5530546623794211,\n",
              "  0.49508196721311476,\n",
              "  0.5604900459418071,\n",
              "  0.5551948051948051,\n",
              "  0.5736196319018404,\n",
              "  0.5780730897009967,\n",
              "  0.5321375186846039,\n",
              "  0.5844155844155844,\n",
              "  0.5388127853881278,\n",
              "  0.5965463108320251,\n",
              "  0.583196046128501,\n",
              "  0.5976331360946746,\n",
              "  0.6130952380952382,\n",
              "  0.5993690851735015,\n",
              "  0.5856697819314641,\n",
              "  0.608955223880597,\n",
              "  0.5945945945945946,\n",
              "  0.613953488372093,\n",
              "  0.6188340807174888,\n",
              "  0.6174298375184638,\n",
              "  0.624405705229794,\n",
              "  0.6212361331220285,\n",
              "  0.6214177978883861,\n",
              "  0.6228070175438595,\n",
              "  0.6304675716440423,\n",
              "  0.6322188449848023,\n",
              "  0.6253687315634219,\n",
              "  0.6399999999999999,\n",
              "  0.6393939393939394,\n",
              "  0.6357039187227866,\n",
              "  0.6519823788546255,\n",
              "  0.6421725239616614,\n",
              "  0.658753709198813,\n",
              "  0.6547085201793723,\n",
              "  0.6666666666666666,\n",
              "  0.6345029239766081,\n",
              "  0.6527570789865872,\n",
              "  0.6344410876132931,\n",
              "  0.6488188976377953,\n",
              "  0.6555386949924128,\n",
              "  0.6524390243902438,\n",
              "  0.6462480857580398,\n",
              "  0.6498516320474778,\n",
              "  0.6549192364170338,\n",
              "  0.6586466165413535,\n",
              "  0.6528803545051699,\n",
              "  0.6559297218155198,\n",
              "  0.6567164179104477,\n",
              "  0.6567164179104477,\n",
              "  0.655786350148368,\n",
              "  0.6528189910979229,\n",
              "  0.659606656580938,\n",
              "  0.6607142857142857,\n",
              "  0.662704309063893,\n",
              "  0.6577777777777778,\n",
              "  0.6578171091445427,\n",
              "  0.6597633136094674,\n",
              "  0.6578171091445427,\n",
              "  0.6587887740029542,\n",
              "  0.6587887740029542,\n",
              "  0.6587887740029542,\n",
              "  0.6587887740029542,\n",
              "  0.6587887740029542,\n",
              "  0.6597633136094674,\n",
              "  0.6587887740029542,\n",
              "  0.6587887740029542,\n",
              "  0.6587887740029542,\n",
              "  0.6587887740029542,\n",
              "  0.6587887740029542,\n",
              "  0.6587887740029542,\n",
              "  0.6587887740029542],\n",
              " 'train_loss_history': [1.887020254130414,\n",
              "  1.5631915664559621,\n",
              "  1.4217878526427383,\n",
              "  1.2833662613381545,\n",
              "  1.1449536604450543,\n",
              "  1.03018501140579,\n",
              "  0.9116680627998193,\n",
              "  0.8412796628926927,\n",
              "  0.7889258578232444,\n",
              "  0.7539006036290596,\n",
              "  0.7040303517982587,\n",
              "  0.6651329673856918,\n",
              "  0.6547660521917437,\n",
              "  0.6163564568588756,\n",
              "  0.5839595234192384,\n",
              "  0.5669625383156089,\n",
              "  0.5552579857681016,\n",
              "  0.5452243544126673,\n",
              "  0.5131707142873017,\n",
              "  0.505139775218154,\n",
              "  0.4834779939607141,\n",
              "  0.4744764135324296,\n",
              "  0.46757161446255535,\n",
              "  0.45845407810741473,\n",
              "  0.44209064903723516,\n",
              "  0.4302263404255134,\n",
              "  0.44181691629544345,\n",
              "  0.41054249800571385,\n",
              "  0.4040740169662154,\n",
              "  0.401776587136294,\n",
              "  0.4051629316798537,\n",
              "  0.40025541706185225,\n",
              "  0.3844513606751509,\n",
              "  0.3734027986723697,\n",
              "  0.3741366411984539,\n",
              "  0.3711361793071943,\n",
              "  0.36485290074426296,\n",
              "  0.3625058402196111,\n",
              "  0.3497386406611368,\n",
              "  0.33094056437911223,\n",
              "  0.3387576056314621,\n",
              "  0.3229308158079642,\n",
              "  0.3239799100189496,\n",
              "  0.32890187723294345,\n",
              "  0.32349522040436857,\n",
              "  0.3158141540303904,\n",
              "  0.3171975617122377,\n",
              "  0.30408809394266506,\n",
              "  0.31647540596622004,\n",
              "  0.3158099298202592,\n",
              "  0.2987245548558162,\n",
              "  0.3054984154894195,\n",
              "  0.2966491074192662,\n",
              "  0.298529718824979,\n",
              "  0.29742877915290766,\n",
              "  0.2963653017932729,\n",
              "  0.2940047881104796,\n",
              "  0.2867972454260893,\n",
              "  0.2873396201174774,\n",
              "  0.28745684723265746,\n",
              "  0.2809542932130114,\n",
              "  0.27672453937207814,\n",
              "  0.27934305144427285,\n",
              "  0.26907733612649337,\n",
              "  0.2689252102116726,\n",
              "  0.27034010018582416,\n",
              "  0.26920575634171395,\n",
              "  0.26991002033853007,\n",
              "  0.2705621550459884,\n",
              "  0.2695452813827592,\n",
              "  0.2615541507384656,\n",
              "  0.26661626571031755,\n",
              "  0.25795127541796914,\n",
              "  0.25344645725792614,\n",
              "  0.26873577597634996,\n",
              "  0.2627786010005442,\n",
              "  0.26652024720983525,\n",
              "  0.26527944964707706,\n",
              "  0.26406768409319115,\n",
              "  0.2610279059473787,\n",
              "  0.2632504821094948,\n",
              "  0.26032290067566105,\n",
              "  0.2652957652435348,\n",
              "  0.25593140397261027,\n",
              "  0.26325098484786996,\n",
              "  0.25894064491387464,\n",
              "  0.2537291200222077,\n",
              "  0.26016208629432647,\n",
              "  0.25674504300565976,\n",
              "  0.2648959840642624,\n",
              "  0.2619612510638125,\n",
              "  0.2631073768006549,\n",
              "  0.26414880311912536],\n",
              " 'dev_loss_history': [1.450675368309021,\n",
              "  1.3440138101577759,\n",
              "  1.1883928775787354,\n",
              "  1.036251425743103,\n",
              "  0.9149270057678223,\n",
              "  0.8102611899375916,\n",
              "  0.7067591547966003,\n",
              "  0.6560428738594055,\n",
              "  0.6681855916976929,\n",
              "  0.6133589148521423,\n",
              "  0.5548257827758789,\n",
              "  0.5143325328826904,\n",
              "  0.48121148347854614,\n",
              "  0.4857262372970581,\n",
              "  0.4894569218158722,\n",
              "  0.436246782541275,\n",
              "  0.44525179266929626,\n",
              "  0.4129801094532013,\n",
              "  0.3978044092655182,\n",
              "  0.375402569770813,\n",
              "  0.37522342801094055,\n",
              "  0.38068726658821106,\n",
              "  0.366337388753891,\n",
              "  0.3842059373855591,\n",
              "  0.3569372892379761,\n",
              "  0.34899047017097473,\n",
              "  0.3372529149055481,\n",
              "  0.3261798620223999,\n",
              "  0.38586798310279846,\n",
              "  0.32165244221687317,\n",
              "  0.3821359872817993,\n",
              "  0.3108314871788025,\n",
              "  0.317490816116333,\n",
              "  0.33128082752227783,\n",
              "  0.3163817226886749,\n",
              "  0.2966867685317993,\n",
              "  0.30230945348739624,\n",
              "  0.31106799840927124,\n",
              "  0.32281503081321716,\n",
              "  0.28660207986831665,\n",
              "  0.298443466424942,\n",
              "  0.30214735865592957,\n",
              "  0.2766439914703369,\n",
              "  0.28180190920829773,\n",
              "  0.28439563512802124,\n",
              "  0.2956168055534363,\n",
              "  0.289211630821228,\n",
              "  0.28374603390693665,\n",
              "  0.29108917713165283,\n",
              "  0.2750115990638733,\n",
              "  0.2766735255718231,\n",
              "  0.28717613220214844,\n",
              "  0.27533185482025146,\n",
              "  0.26894286274909973,\n",
              "  0.2734452188014984,\n",
              "  0.2727002501487732,\n",
              "  0.25879597663879395,\n",
              "  0.2830386757850647,\n",
              "  0.2663547396659851,\n",
              "  0.2708333134651184,\n",
              "  0.26524314284324646,\n",
              "  0.26385605335235596,\n",
              "  0.26488929986953735,\n",
              "  0.2623550295829773,\n",
              "  0.2628309726715088,\n",
              "  0.2661665678024292,\n",
              "  0.2598554790019989,\n",
              "  0.26272353529930115,\n",
              "  0.2630848288536072,\n",
              "  0.26068106293678284,\n",
              "  0.26059040427207947,\n",
              "  0.2612302899360657,\n",
              "  0.26052001118659973,\n",
              "  0.259115993976593,\n",
              "  0.26033222675323486,\n",
              "  0.26010578870773315,\n",
              "  0.26077553629875183,\n",
              "  0.26148906350135803,\n",
              "  0.26147228479385376,\n",
              "  0.26173296570777893,\n",
              "  0.2614869177341461,\n",
              "  0.261610209941864,\n",
              "  0.2617023289203644,\n",
              "  0.26181963086128235,\n",
              "  0.26179251074790955,\n",
              "  0.26166436076164246,\n",
              "  0.2618527114391327,\n",
              "  0.26191282272338867,\n",
              "  0.2618909776210785,\n",
              "  0.26189085841178894,\n",
              "  0.26188018918037415,\n",
              "  0.26180300116539,\n",
              "  0.2617446184158325]}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from flair.models import SequenceTagger\n",
        "\n",
        "# initialize a BiLSTM-CRF sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                                       embeddings=embeddings,\n",
        "                                       tag_dictionary=tag_dictionary,\n",
        "                                       tag_type=tag_type,\n",
        "                                       use_crf=True)\n",
        "print(tagger)\n",
        "\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# start training\n",
        "trainer.train('resources/taggers/re3d-ner',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## On general (docred) data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:16:58,545 Reading data from docred_preprocessed\n",
            "2022-12-09 11:16:58,547 Train: docred_preprocessed/train.txt\n",
            "2022-12-09 11:16:58,549 Dev: docred_preprocessed/dev.txt\n",
            "2022-12-09 11:16:58,549 Test: docred_preprocessed/test.txt\n"
          ]
        }
      ],
      "source": [
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = 'docred_preprocessed'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')\n",
        "\n",
        "downsampled_corpus = corpus.downsample(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"Del ia ĠBuckley ĠGallagher Ġ( Ġborn Ġ11 ĠMarch Ġ1970 Ġ) Ġis Ġan ĠAmerican Ġjournalist Ġbased Ġin ĠRome Ġwho Ġcurrently Ġserves Ġas Ġthe ĠSenior ĠEditor Ġfor ĠInside Ġthe ĠVatican Ġmagazine Ġ. She Ġformerly Ġserved Ġas ĠCNN ĠâĢ Ļ s ĠFaith Ġand ĠValues ĠCorrespond ent Ġ. Based Ġin ĠNew ĠYork Ġ, ĠGallagher Ġwas Ġa Ġlong Ġtime ĠCNN ĠVatican ĠAnalyst Ġ, ĠVatican ologist Ġ, Ġand Ġreligious Ġjournalist Ġ. Prior Ġto Ġjoining ĠCNN Ġfull Ġtime Ġ, Ġshe Ġlived Ġin ĠRome Ġfor Ġ7 Ġyears Ġ. In ĠRome Ġ, Ġshe Ġwrote Ġa Ġweekly Ġcolumn Ġfor ĠZen it ĠNews ĠAgency Ġand Ġwas Ġa Ġcontributing Ġeditor Ġfor Ġthe Ġmagazine Ġ. The ĠHistory ĠChannel ĠDocument ary Ġ, Ġ\" ĠAngels Ġand ĠDemons ĠDec oded Ġ\" Ġreleased Ġby ĠA Ġ& ĠE ĠTelevision ĠNetworks Ġprof iled ĠGallagher Ġcommenting Ġon ĠDan ĠBrown Ġ' s Ġbest seller Ġbook Ġwhich Ġwas Ġmade Ġinto Ġa Ġmovie Ġ. Sub sequently Ġ, ĠGallagher Ġmoder ated Ġthe ĠAngels Ġand ĠDemons Ġmovie Ġpress Ġconference Ġfilm Ġdebut Ġin ĠRome Ġon Ġstage Ġwith ĠTom ĠH anks Ġ, ĠRon ĠHoward Ġand ĠDan ĠBrown Ġoften Ġspeaking Ġin ĠItalian Ġand ĠEnglish Ġ. She Ġknows ĠPope ĠBenedict ĠXVI Ġpersonally Ġand Ġtravelled Ġextensively Ġwith ĠJohn ĠPaul ĠII Ġ, Ġincluding Ġhis Ġlast Ġtrip Ġto ĠPoland Ġ. Upon Ġthe Ġdeath Ġof ĠPope ĠJohn ĠPaul ĠII Ġ, Ġshe Ġbroadcast Ġand Ġcommented Ġfor ĠCNN ĠWorldwide Ġcovering Ġthe Ġunfolding Ġevent Ġ.\" → [\"Del ia ĠBuckley ĠGallagher\"/PER, \"Ġ11 ĠMarch Ġ1970\"/TIME, \"ĠCNN\"/ORG, \"ĠAngels Ġand ĠDemons ĠDec oded\"/MISC, \"ĠTom ĠH anks\"/PER, \"ĠDan ĠBrown\"/PER, \"ĠCNN ĠWorldwide\"/ORG]\n",
            "301\n"
          ]
        }
      ],
      "source": [
        "print(downsampled_corpus.train[0].to_tagged_string('ner'))\n",
        "print(len(downsampled_corpus.train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 10:56:58,844 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "3008it [00:00, 25790.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 10:56:59,000 Dictionary created for label 'ner' with 7 values: LOC (seen 10903 times), PER (seen 5336 times), MISC (seen 4419 times), ORG (seen 4334 times), TIME (seen 3340 times), NUM (seen 8 times)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Define tags to predict\n",
        "tag_type = 'ner'# make tag dictionary from the corpus\n",
        "tag_dictionary = downsampled_corpus.make_label_dictionary(label_type=tag_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Embeddings\n",
        "\n",
        "from typing import List\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_types = [\n",
        "    # init standard GloVe embedding\n",
        "    WordEmbeddings('glove'),\n",
        "\n",
        "    # init Flair forward and backwards embeddings\n",
        "    FlairEmbeddings('news-forward'),\n",
        "    FlairEmbeddings('news-backward'),\n",
        "]\n",
        "\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:18:12,896 SequenceTagger predicts: Dictionary with 25 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-MISC, B-MISC, E-MISC, I-MISC, S-ORG, B-ORG, E-ORG, I-ORG, S-TIME, B-TIME, E-TIME, I-TIME, S-NUM, B-NUM, E-NUM, I-NUM\n",
            "SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
            "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=27, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\n",
            "2022-12-09 11:18:13,012 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:18:13,012 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
            "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=27, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-12-09 11:18:13,013 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:18:13,014 Corpus: \"Corpus: 301 train + 30 dev + 70 test sentences\"\n",
            "2022-12-09 11:18:13,015 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:18:13,016 Parameters:\n",
            "2022-12-09 11:18:13,016  - learning_rate: \"0.100000\"\n",
            "2022-12-09 11:18:13,017  - mini_batch_size: \"64\"\n",
            "2022-12-09 11:18:13,017  - patience: \"3\"\n",
            "2022-12-09 11:18:13,018  - anneal_factor: \"0.5\"\n",
            "2022-12-09 11:18:13,018  - max_epochs: \"150\"\n",
            "2022-12-09 11:18:13,018  - shuffle: \"True\"\n",
            "2022-12-09 11:18:13,019  - train_with_dev: \"False\"\n",
            "2022-12-09 11:18:13,020  - batch_growth_annealing: \"False\"\n",
            "2022-12-09 11:18:13,020 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:18:13,021 Model training base path: \"resources/taggers/docred-ner\"\n",
            "2022-12-09 11:18:13,022 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:18:13,023 Device: cpu\n",
            "2022-12-09 11:18:13,023 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:18:13,023 Embeddings storage mode: cpu\n",
            "2022-12-09 11:18:13,024 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:19:21,612 epoch 1 - iter 1/5 - loss 3.56210742 - samples/sec: 0.93 - lr: 0.100000\n",
            "2022-12-09 11:20:41,340 epoch 1 - iter 2/5 - loss 2.96705841 - samples/sec: 0.80 - lr: 0.100000\n",
            "2022-12-09 11:21:58,301 epoch 1 - iter 3/5 - loss 2.38906567 - samples/sec: 0.83 - lr: 0.100000\n",
            "2022-12-09 11:23:08,269 epoch 1 - iter 4/5 - loss 2.01742559 - samples/sec: 0.91 - lr: 0.100000\n",
            "2022-12-09 11:24:21,215 epoch 1 - iter 5/5 - loss 1.87108151 - samples/sec: 0.88 - lr: 0.100000\n",
            "2022-12-09 11:24:21,216 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:24:21,217 EPOCH 1 done: loss 1.8711 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:29<00:00, 29.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:24:50,576 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:24:50,581 DEV : loss 0.9319246411323547 - f1-score (micro avg)  0.0\n",
            "2022-12-09 11:24:50,600 BAD EPOCHS (no improvement): 0\n",
            "2022-12-09 11:24:50,601 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:25:20,274 epoch 2 - iter 1/5 - loss 0.90134813 - samples/sec: 2.16 - lr: 0.100000\n",
            "2022-12-09 11:25:48,091 epoch 2 - iter 2/5 - loss 0.93840038 - samples/sec: 2.30 - lr: 0.100000\n",
            "2022-12-09 11:26:19,322 epoch 2 - iter 3/5 - loss 0.91924218 - samples/sec: 2.05 - lr: 0.100000\n",
            "2022-12-09 11:26:45,252 epoch 2 - iter 4/5 - loss 0.93913768 - samples/sec: 2.47 - lr: 0.100000\n",
            "2022-12-09 11:27:10,925 epoch 2 - iter 5/5 - loss 0.93488603 - samples/sec: 2.49 - lr: 0.100000\n",
            "2022-12-09 11:27:10,926 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:27:10,926 EPOCH 2 done: loss 0.9349 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:27:12,570 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:27:12,576 DEV : loss 0.8952202200889587 - f1-score (micro avg)  0.0\n",
            "2022-12-09 11:27:12,610 BAD EPOCHS (no improvement): 0\n",
            "2022-12-09 11:27:12,612 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:27:51,803 epoch 3 - iter 1/5 - loss 0.93787773 - samples/sec: 1.63 - lr: 0.100000\n",
            "2022-12-09 11:28:17,708 epoch 3 - iter 2/5 - loss 0.87763922 - samples/sec: 2.47 - lr: 0.100000\n",
            "2022-12-09 11:28:48,144 epoch 3 - iter 3/5 - loss 0.87597248 - samples/sec: 2.10 - lr: 0.100000\n",
            "2022-12-09 11:29:24,463 epoch 3 - iter 4/5 - loss 0.87139243 - samples/sec: 1.76 - lr: 0.100000\n",
            "2022-12-09 11:29:49,401 epoch 3 - iter 5/5 - loss 0.88037029 - samples/sec: 2.57 - lr: 0.100000\n",
            "2022-12-09 11:29:49,403 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:29:49,403 EPOCH 3 done: loss 0.8804 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:29:51,446 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:29:51,455 DEV : loss 0.8871385455131531 - f1-score (micro avg)  0.0\n",
            "2022-12-09 11:29:51,505 BAD EPOCHS (no improvement): 0\n",
            "2022-12-09 11:29:51,506 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:30:33,282 epoch 4 - iter 1/5 - loss 0.84545739 - samples/sec: 1.53 - lr: 0.100000\n",
            "2022-12-09 11:31:07,296 epoch 4 - iter 2/5 - loss 0.85193636 - samples/sec: 1.88 - lr: 0.100000\n",
            "2022-12-09 11:31:39,928 epoch 4 - iter 3/5 - loss 0.85269189 - samples/sec: 1.96 - lr: 0.100000\n",
            "2022-12-09 11:32:14,196 epoch 4 - iter 4/5 - loss 0.83863095 - samples/sec: 1.87 - lr: 0.100000\n",
            "2022-12-09 11:32:33,063 epoch 4 - iter 5/5 - loss 0.83809332 - samples/sec: 3.39 - lr: 0.100000\n",
            "2022-12-09 11:32:33,065 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:32:33,066 EPOCH 4 done: loss 0.8381 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:32:35,037 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:32:35,046 DEV : loss 0.7917019724845886 - f1-score (micro avg)  0.0\n",
            "2022-12-09 11:32:35,079 BAD EPOCHS (no improvement): 0\n",
            "2022-12-09 11:32:35,080 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:33:01,560 epoch 5 - iter 1/5 - loss 0.83295365 - samples/sec: 2.42 - lr: 0.100000\n",
            "2022-12-09 11:33:34,764 epoch 5 - iter 2/5 - loss 0.82610632 - samples/sec: 1.93 - lr: 0.100000\n",
            "2022-12-09 11:34:09,123 epoch 5 - iter 3/5 - loss 0.82558673 - samples/sec: 1.86 - lr: 0.100000\n",
            "2022-12-09 11:34:50,750 epoch 5 - iter 4/5 - loss 0.81371176 - samples/sec: 1.54 - lr: 0.100000\n",
            "2022-12-09 11:35:08,915 epoch 5 - iter 5/5 - loss 0.80057598 - samples/sec: 3.52 - lr: 0.100000\n",
            "2022-12-09 11:35:08,916 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:35:08,917 EPOCH 5 done: loss 0.8006 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:35:11,142 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:35:11,151 DEV : loss 0.8529025316238403 - f1-score (micro avg)  0.0\n",
            "2022-12-09 11:35:11,187 BAD EPOCHS (no improvement): 1\n",
            "2022-12-09 11:35:11,188 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:35:44,379 epoch 6 - iter 1/5 - loss 0.77767155 - samples/sec: 1.93 - lr: 0.100000\n",
            "2022-12-09 11:36:19,566 epoch 6 - iter 2/5 - loss 0.77038829 - samples/sec: 1.82 - lr: 0.100000\n",
            "2022-12-09 11:36:58,086 epoch 6 - iter 3/5 - loss 0.79013852 - samples/sec: 1.66 - lr: 0.100000\n",
            "2022-12-09 11:37:28,000 epoch 6 - iter 4/5 - loss 0.79034168 - samples/sec: 2.14 - lr: 0.100000\n",
            "2022-12-09 11:49:35,057 epoch 6 - iter 5/5 - loss 0.78124586 - samples/sec: 0.09 - lr: 0.100000\n",
            "2022-12-09 11:49:35,062 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:49:35,062 EPOCH 6 done: loss 0.7812 - lr 0.100000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:49:36,713 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:49:36,727 DEV : loss 0.7337616086006165 - f1-score (micro avg)  0.0\n",
            "2022-12-09 11:49:36,749 BAD EPOCHS (no improvement): 0\n",
            "2022-12-09 11:49:36,750 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:50:04,201 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:50:04,202 Exiting from training early.\n",
            "2022-12-09 11:50:04,203 Saving model ...\n",
            "2022-12-09 11:50:05,187 Done.\n",
            "2022-12-09 11:50:05,188 ----------------------------------------------------------------------------------------------------\n",
            "2022-12-09 11:50:05,188 Testing using last state of model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [01:00<00:00, 30.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-09 11:51:05,250 Evaluating as a multi-label problem: False\n",
            "2022-12-09 11:51:05,263 0.0\t0.0\t0.0\t0.0\n",
            "2022-12-09 11:51:05,264 \n",
            "Results:\n",
            "- F-score (micro) 0.0\n",
            "- F-score (macro) 0.0\n",
            "- Accuracy 0.0\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC     0.0000    0.0000    0.0000     345.0\n",
            "         ORG     0.0000    0.0000    0.0000     112.0\n",
            "         PER     0.0000    0.0000    0.0000     106.0\n",
            "        MISC     0.0000    0.0000    0.0000      75.0\n",
            "        TIME     0.0000    0.0000    0.0000      65.0\n",
            "\n",
            "   micro avg     0.0000    0.0000    0.0000     703.0\n",
            "   macro avg     0.0000    0.0000    0.0000     703.0\n",
            "weighted avg     0.0000    0.0000    0.0000     703.0\n",
            "\n",
            "2022-12-09 11:51:05,265 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_score': 0.0,\n",
              " 'dev_score_history': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " 'train_loss_history': [1.8710815052353171,\n",
              "  0.934886026183842,\n",
              "  0.880370293021754,\n",
              "  0.8380933155376087,\n",
              "  0.8005759801253864,\n",
              "  0.781245861723047],\n",
              " 'dev_loss_history': [0.9319246411323547,\n",
              "  0.8952202200889587,\n",
              "  0.8871385455131531,\n",
              "  0.7917019724845886,\n",
              "  0.8529025316238403,\n",
              "  0.7337616086006165]}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from flair.models import SequenceTagger\n",
        "\n",
        "# initialize a BiLSTM-CRF sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                                       embeddings=embeddings,\n",
        "                                       tag_dictionary=tag_dictionary,\n",
        "                                       tag_type=tag_type,\n",
        "                                       use_crf=True)\n",
        "print(tagger)\n",
        "\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# initialize trainer\n",
        "trainer = ModelTrainer(tagger, downsampled_corpus)\n",
        "\n",
        "# start training\n",
        "trainer.train('resources/taggers/docred-ner',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=64,\n",
        "              max_epochs=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformer Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## On domain-specific (re3d) data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 10:57:44,994 SequenceTagger predicts: Dictionary with 41 tags: O, S-Organisation, B-Organisation, E-Organisation, I-Organisation, S-Location, B-Location, E-Location, I-Location, S-Person, B-Person, E-Person, I-Person, S-Temporal, B-Temporal, E-Temporal, I-Temporal, S-Quantity, B-Quantity, E-Quantity, I-Quantity, S-Weapon, B-Weapon, E-Weapon, I-Weapon, S-DocumentReference, B-DocumentReference, E-DocumentReference, I-DocumentReference, S-MilitaryPlatform, B-MilitaryPlatform, E-MilitaryPlatform, I-MilitaryPlatform, S-Nationality, B-Nationality, E-Nationality, I-Nationality, S-Money, B-Money, E-Money, I-Money\n",
            "2022-11-30 10:57:44,999 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 10:57:45,000 Model: \"SequenceTagger(\n",
            "  (embeddings): TransformerWordEmbeddings(\n",
            "    (model): XLMRobertaModel(\n",
            "      (embeddings): XLMRobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
            "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
            "        (token_type_embeddings): Embedding(1, 1024)\n",
            "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): XLMRobertaEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (12): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (13): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (14): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (15): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (16): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (17): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (18): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (19): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (20): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (21): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (22): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (23): XLMRobertaLayer(\n",
            "            (attention): XLMRobertaAttention(\n",
            "              (self): XLMRobertaSelfAttention(\n",
            "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): XLMRobertaSelfOutput(\n",
            "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): XLMRobertaIntermediate(\n",
            "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): XLMRobertaOutput(\n",
            "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): XLMRobertaPooler(\n",
            "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (linear): Linear(in_features=1024, out_features=41, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2022-11-30 10:57:45,001 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 10:57:45,001 Corpus: \"Corpus: 771 train + 98 dev + 96 test sentences\"\n",
            "2022-11-30 10:57:45,002 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 10:57:45,002 Parameters:\n",
            "2022-11-30 10:57:45,002  - learning_rate: \"0.000005\"\n",
            "2022-11-30 10:57:45,003  - mini_batch_size: \"4\"\n",
            "2022-11-30 10:57:45,003  - patience: \"3\"\n",
            "2022-11-30 10:57:45,003  - anneal_factor: \"0.5\"\n",
            "2022-11-30 10:57:45,004  - max_epochs: \"10\"\n",
            "2022-11-30 10:57:45,004  - shuffle: \"True\"\n",
            "2022-11-30 10:57:45,004  - train_with_dev: \"False\"\n",
            "2022-11-30 10:57:45,005  - batch_growth_annealing: \"False\"\n",
            "2022-11-30 10:57:45,005 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 10:57:45,005 Model training base path: \"resources/taggers/sota-ner-flert\"\n",
            "2022-11-30 10:57:45,006 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 10:57:45,006 Device: cpu\n",
            "2022-11-30 10:57:45,006 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 10:57:45,007 Embeddings storage mode: none\n",
            "2022-11-30 10:57:45,007 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 10:59:15,363 epoch 1 - iter 19/193 - loss 4.54514738 - samples/sec: 0.84 - lr: 0.000000\n",
            "2022-11-30 11:00:48,207 epoch 1 - iter 38/193 - loss 4.43272621 - samples/sec: 0.82 - lr: 0.000001\n",
            "2022-11-30 11:02:23,672 epoch 1 - iter 57/193 - loss 4.36420443 - samples/sec: 0.80 - lr: 0.000001\n",
            "2022-11-30 11:04:02,863 epoch 1 - iter 76/193 - loss 4.23338053 - samples/sec: 0.77 - lr: 0.000002\n",
            "2022-11-30 11:05:40,397 epoch 1 - iter 95/193 - loss 4.07733612 - samples/sec: 0.78 - lr: 0.000002\n",
            "2022-11-30 11:07:24,554 epoch 1 - iter 114/193 - loss 3.79461002 - samples/sec: 0.73 - lr: 0.000003\n",
            "2022-11-30 11:09:04,787 epoch 1 - iter 133/193 - loss 3.51177080 - samples/sec: 0.76 - lr: 0.000003\n",
            "2022-11-30 11:10:43,154 epoch 1 - iter 152/193 - loss 3.30658618 - samples/sec: 0.77 - lr: 0.000004\n",
            "2022-11-30 11:12:23,546 epoch 1 - iter 171/193 - loss 3.13841904 - samples/sec: 0.76 - lr: 0.000004\n",
            "2022-11-30 11:14:05,709 epoch 1 - iter 190/193 - loss 2.99444204 - samples/sec: 0.74 - lr: 0.000005\n",
            "2022-11-30 11:14:19,530 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 11:14:19,531 EPOCH 1 done: loss 2.9750 - lr 0.000005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:26<00:00,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 11:14:46,124 Evaluating as a multi-label problem: False\n",
            "2022-11-30 11:14:46,130 DEV : loss 1.2281770706176758 - f1-score (micro avg)  0.0106\n",
            "2022-11-30 11:14:46,132 BAD EPOCHS (no improvement): 4\n",
            "2022-11-30 11:14:46,133 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 11:16:25,474 epoch 2 - iter 19/193 - loss 1.70634697 - samples/sec: 0.77 - lr: 0.000005\n",
            "2022-11-30 11:18:08,092 epoch 2 - iter 38/193 - loss 1.60078184 - samples/sec: 0.74 - lr: 0.000005\n",
            "2022-11-30 11:19:53,055 epoch 2 - iter 57/193 - loss 1.52618754 - samples/sec: 0.72 - lr: 0.000005\n",
            "2022-11-30 11:21:36,149 epoch 2 - iter 76/193 - loss 1.47910050 - samples/sec: 0.74 - lr: 0.000005\n",
            "2022-11-30 11:23:18,441 epoch 2 - iter 95/193 - loss 1.48425810 - samples/sec: 0.74 - lr: 0.000005\n",
            "2022-11-30 11:24:58,056 epoch 2 - iter 114/193 - loss 1.48248315 - samples/sec: 0.76 - lr: 0.000005\n",
            "2022-11-30 11:26:40,738 epoch 2 - iter 133/193 - loss 1.47193090 - samples/sec: 0.74 - lr: 0.000005\n",
            "2022-11-30 11:28:24,931 epoch 2 - iter 152/193 - loss 1.45062939 - samples/sec: 0.73 - lr: 0.000005\n",
            "2022-11-30 11:30:03,297 epoch 2 - iter 171/193 - loss 1.42916158 - samples/sec: 0.77 - lr: 0.000005\n",
            "2022-11-30 11:31:45,988 epoch 2 - iter 190/193 - loss 1.41856586 - samples/sec: 0.74 - lr: 0.000004\n",
            "2022-11-30 11:32:01,487 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 11:32:01,488 EPOCH 2 done: loss 1.4151 - lr 0.000004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:27<00:00,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 11:32:28,840 Evaluating as a multi-label problem: False\n",
            "2022-11-30 11:32:28,847 DEV : loss 0.859157383441925 - f1-score (micro avg)  0.3359\n",
            "2022-11-30 11:32:28,849 BAD EPOCHS (no improvement): 4\n",
            "2022-11-30 11:32:28,849 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 11:34:11,962 epoch 3 - iter 19/193 - loss 1.18107933 - samples/sec: 0.74 - lr: 0.000004\n",
            "2022-11-30 11:35:55,932 epoch 3 - iter 38/193 - loss 1.16100328 - samples/sec: 0.73 - lr: 0.000004\n",
            "2022-11-30 11:37:38,751 epoch 3 - iter 57/193 - loss 1.15240414 - samples/sec: 0.74 - lr: 0.000004\n",
            "2022-11-30 11:39:19,589 epoch 3 - iter 76/193 - loss 1.15514344 - samples/sec: 0.75 - lr: 0.000004\n",
            "2022-11-30 11:41:01,863 epoch 3 - iter 95/193 - loss 1.14931780 - samples/sec: 0.74 - lr: 0.000004\n",
            "2022-11-30 11:42:44,019 epoch 3 - iter 114/193 - loss 1.13944827 - samples/sec: 0.74 - lr: 0.000004\n",
            "2022-11-30 11:44:25,660 epoch 3 - iter 133/193 - loss 1.15121117 - samples/sec: 0.75 - lr: 0.000004\n",
            "2022-11-30 11:46:04,166 epoch 3 - iter 152/193 - loss 1.13607780 - samples/sec: 0.77 - lr: 0.000004\n",
            "2022-11-30 11:47:44,469 epoch 3 - iter 171/193 - loss 1.11264134 - samples/sec: 0.76 - lr: 0.000004\n",
            "2022-11-30 11:49:27,149 epoch 3 - iter 190/193 - loss 1.09650235 - samples/sec: 0.74 - lr: 0.000004\n",
            "2022-11-30 11:49:43,246 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 11:49:43,247 EPOCH 3 done: loss 1.1024 - lr 0.000004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:26<00:00,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 11:50:09,675 Evaluating as a multi-label problem: False\n",
            "2022-11-30 11:50:09,681 DEV : loss 0.6455650925636292 - f1-score (micro avg)  0.5599\n",
            "2022-11-30 11:50:09,683 BAD EPOCHS (no improvement): 4\n",
            "2022-11-30 11:50:09,684 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 11:51:53,879 epoch 4 - iter 19/193 - loss 0.97260906 - samples/sec: 0.73 - lr: 0.000004\n",
            "2022-11-30 11:53:35,434 epoch 4 - iter 38/193 - loss 0.96436763 - samples/sec: 0.75 - lr: 0.000004\n",
            "2022-11-30 11:55:19,071 epoch 4 - iter 57/193 - loss 0.95113051 - samples/sec: 0.73 - lr: 0.000004\n",
            "2022-11-30 11:57:00,701 epoch 4 - iter 76/193 - loss 0.95500763 - samples/sec: 0.75 - lr: 0.000004\n",
            "2022-11-30 11:58:40,334 epoch 4 - iter 95/193 - loss 0.95968059 - samples/sec: 0.76 - lr: 0.000004\n",
            "2022-11-30 12:00:22,610 epoch 4 - iter 114/193 - loss 0.94483429 - samples/sec: 0.74 - lr: 0.000004\n",
            "2022-11-30 12:02:05,488 epoch 4 - iter 133/193 - loss 0.92717997 - samples/sec: 0.74 - lr: 0.000004\n",
            "2022-11-30 12:03:49,268 epoch 4 - iter 152/193 - loss 0.92088186 - samples/sec: 0.73 - lr: 0.000003\n",
            "2022-11-30 12:05:31,793 epoch 4 - iter 171/193 - loss 0.91177261 - samples/sec: 0.74 - lr: 0.000003\n",
            "2022-11-30 12:07:18,415 epoch 4 - iter 190/193 - loss 0.89612654 - samples/sec: 0.71 - lr: 0.000003\n",
            "2022-11-30 12:07:33,625 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 12:07:33,626 EPOCH 4 done: loss 0.8985 - lr 0.000003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:27<00:00,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 12:08:01,514 Evaluating as a multi-label problem: False\n",
            "2022-11-30 12:08:01,522 DEV : loss 0.5550165176391602 - f1-score (micro avg)  0.5924\n",
            "2022-11-30 12:08:01,524 BAD EPOCHS (no improvement): 4\n",
            "2022-11-30 12:08:01,525 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 12:09:43,916 epoch 5 - iter 19/193 - loss 0.90112426 - samples/sec: 0.74 - lr: 0.000003\n",
            "2022-11-30 12:11:23,647 epoch 5 - iter 38/193 - loss 0.81213309 - samples/sec: 0.76 - lr: 0.000003\n",
            "2022-11-30 12:13:03,346 epoch 5 - iter 57/193 - loss 0.81167060 - samples/sec: 0.76 - lr: 0.000003\n",
            "2022-11-30 12:14:50,957 epoch 5 - iter 76/193 - loss 0.78997312 - samples/sec: 0.71 - lr: 0.000003\n",
            "2022-11-30 12:16:31,213 epoch 5 - iter 95/193 - loss 0.75432254 - samples/sec: 0.76 - lr: 0.000003\n",
            "2022-11-30 12:18:15,060 epoch 5 - iter 114/193 - loss 0.74496969 - samples/sec: 0.73 - lr: 0.000003\n",
            "2022-11-30 12:19:54,546 epoch 5 - iter 133/193 - loss 0.75262086 - samples/sec: 0.76 - lr: 0.000003\n",
            "2022-11-30 12:21:37,658 epoch 5 - iter 152/193 - loss 0.75793603 - samples/sec: 0.74 - lr: 0.000003\n",
            "2022-11-30 12:23:20,441 epoch 5 - iter 171/193 - loss 0.76534126 - samples/sec: 0.74 - lr: 0.000003\n",
            "2022-11-30 12:25:02,747 epoch 5 - iter 190/193 - loss 0.76612795 - samples/sec: 0.74 - lr: 0.000003\n",
            "2022-11-30 12:25:17,041 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 12:25:17,042 EPOCH 5 done: loss 0.7659 - lr 0.000003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:26<00:00,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 12:25:43,226 Evaluating as a multi-label problem: False\n",
            "2022-11-30 12:25:43,232 DEV : loss 0.5053684711456299 - f1-score (micro avg)  0.623\n",
            "2022-11-30 12:25:43,234 BAD EPOCHS (no improvement): 4\n",
            "2022-11-30 12:25:43,234 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 12:27:24,162 epoch 6 - iter 19/193 - loss 0.79235249 - samples/sec: 0.75 - lr: 0.000003\n",
            "2022-11-30 12:29:03,098 epoch 6 - iter 38/193 - loss 0.74641216 - samples/sec: 0.77 - lr: 0.000003\n",
            "2022-11-30 12:30:42,563 epoch 6 - iter 57/193 - loss 0.72770857 - samples/sec: 0.76 - lr: 0.000003\n",
            "2022-11-30 12:32:28,887 epoch 6 - iter 76/193 - loss 0.73241454 - samples/sec: 0.71 - lr: 0.000003\n",
            "2022-11-30 12:34:12,246 epoch 6 - iter 95/193 - loss 0.72672889 - samples/sec: 0.74 - lr: 0.000003\n",
            "2022-11-30 12:35:58,964 epoch 6 - iter 114/193 - loss 0.72559303 - samples/sec: 0.71 - lr: 0.000002\n",
            "2022-11-30 12:37:40,439 epoch 6 - iter 133/193 - loss 0.71672081 - samples/sec: 0.75 - lr: 0.000002\n",
            "2022-11-30 12:39:24,112 epoch 6 - iter 152/193 - loss 0.70523662 - samples/sec: 0.73 - lr: 0.000002\n",
            "2022-11-30 12:41:10,651 epoch 6 - iter 171/193 - loss 0.70170923 - samples/sec: 0.71 - lr: 0.000002\n",
            "2022-11-30 12:42:52,383 epoch 6 - iter 190/193 - loss 0.70025214 - samples/sec: 0.75 - lr: 0.000002\n",
            "2022-11-30 12:43:08,578 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 12:43:08,579 EPOCH 6 done: loss 0.7034 - lr 0.000002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:27<00:00,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 12:43:36,092 Evaluating as a multi-label problem: False\n",
            "2022-11-30 12:43:36,098 DEV : loss 0.4809141457080841 - f1-score (micro avg)  0.6421\n",
            "2022-11-30 12:43:36,100 BAD EPOCHS (no improvement): 4\n",
            "2022-11-30 12:43:36,100 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 12:45:24,084 epoch 7 - iter 19/193 - loss 0.69150056 - samples/sec: 0.70 - lr: 0.000002\n",
            "2022-11-30 12:47:09,434 epoch 7 - iter 38/193 - loss 0.58645489 - samples/sec: 0.72 - lr: 0.000002\n",
            "2022-11-30 12:48:49,413 epoch 7 - iter 57/193 - loss 0.61262007 - samples/sec: 0.76 - lr: 0.000002\n",
            "2022-11-30 12:50:29,186 epoch 7 - iter 76/193 - loss 0.63671129 - samples/sec: 0.76 - lr: 0.000002\n",
            "2022-11-30 12:52:09,915 epoch 7 - iter 95/193 - loss 0.64163365 - samples/sec: 0.75 - lr: 0.000002\n",
            "2022-11-30 12:53:53,555 epoch 7 - iter 114/193 - loss 0.65008152 - samples/sec: 0.73 - lr: 0.000002\n",
            "2022-11-30 12:55:38,674 epoch 7 - iter 133/193 - loss 0.64602801 - samples/sec: 0.72 - lr: 0.000002\n",
            "2022-11-30 12:57:21,753 epoch 7 - iter 152/193 - loss 0.65226260 - samples/sec: 0.74 - lr: 0.000002\n",
            "2022-11-30 12:59:06,954 epoch 7 - iter 171/193 - loss 0.66175506 - samples/sec: 0.72 - lr: 0.000002\n",
            "2022-11-30 13:00:52,739 epoch 7 - iter 190/193 - loss 0.65414160 - samples/sec: 0.72 - lr: 0.000002\n",
            "2022-11-30 13:01:08,817 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 13:01:08,818 EPOCH 7 done: loss 0.6550 - lr 0.000002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:26<00:00,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 13:01:35,457 Evaluating as a multi-label problem: False\n",
            "2022-11-30 13:01:35,465 DEV : loss 0.45765113830566406 - f1-score (micro avg)  0.661\n",
            "2022-11-30 13:01:35,466 BAD EPOCHS (no improvement): 4\n",
            "2022-11-30 13:01:35,467 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 13:03:20,419 epoch 8 - iter 19/193 - loss 0.50555353 - samples/sec: 0.72 - lr: 0.000002\n",
            "2022-11-30 13:05:01,410 epoch 8 - iter 38/193 - loss 0.55136883 - samples/sec: 0.75 - lr: 0.000002\n",
            "2022-11-30 13:06:42,901 epoch 8 - iter 57/193 - loss 0.56670320 - samples/sec: 0.75 - lr: 0.000002\n",
            "2022-11-30 13:08:25,543 epoch 8 - iter 76/193 - loss 0.59016058 - samples/sec: 0.74 - lr: 0.000001\n",
            "2022-11-30 13:10:06,352 epoch 8 - iter 95/193 - loss 0.59977417 - samples/sec: 0.75 - lr: 0.000001\n",
            "2022-11-30 13:11:50,935 epoch 8 - iter 114/193 - loss 0.61038794 - samples/sec: 0.73 - lr: 0.000001\n",
            "2022-11-30 13:13:29,730 epoch 8 - iter 133/193 - loss 0.62400247 - samples/sec: 0.77 - lr: 0.000001\n",
            "2022-11-30 13:15:12,836 epoch 8 - iter 152/193 - loss 0.62570289 - samples/sec: 0.74 - lr: 0.000001\n",
            "2022-11-30 13:17:01,364 epoch 8 - iter 171/193 - loss 0.61821157 - samples/sec: 0.70 - lr: 0.000001\n",
            "2022-11-30 13:18:46,696 epoch 8 - iter 190/193 - loss 0.60843392 - samples/sec: 0.72 - lr: 0.000001\n",
            "2022-11-30 13:19:01,293 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 13:19:01,294 EPOCH 8 done: loss 0.6058 - lr 0.000001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:26<00:00,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 13:19:28,125 Evaluating as a multi-label problem: False\n",
            "2022-11-30 13:19:28,131 DEV : loss 0.4889335632324219 - f1-score (micro avg)  0.6419\n",
            "2022-11-30 13:19:28,134 BAD EPOCHS (no improvement): 4\n",
            "2022-11-30 13:19:28,134 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 13:21:11,378 epoch 9 - iter 19/193 - loss 0.66303300 - samples/sec: 0.74 - lr: 0.000001\n",
            "2022-11-30 13:22:52,696 epoch 9 - iter 38/193 - loss 0.62461309 - samples/sec: 0.75 - lr: 0.000001\n",
            "2022-11-30 13:24:37,609 epoch 9 - iter 57/193 - loss 0.61340325 - samples/sec: 0.72 - lr: 0.000001\n",
            "2022-11-30 13:26:20,461 epoch 9 - iter 76/193 - loss 0.59152182 - samples/sec: 0.74 - lr: 0.000001\n",
            "2022-11-30 13:28:08,073 epoch 9 - iter 95/193 - loss 0.58175577 - samples/sec: 0.71 - lr: 0.000001\n",
            "2022-11-30 13:29:49,074 epoch 9 - iter 114/193 - loss 0.58923351 - samples/sec: 0.75 - lr: 0.000001\n",
            "2022-11-30 13:31:30,265 epoch 9 - iter 133/193 - loss 0.59469105 - samples/sec: 0.75 - lr: 0.000001\n",
            "2022-11-30 13:33:15,066 epoch 9 - iter 152/193 - loss 0.57817741 - samples/sec: 0.73 - lr: 0.000001\n",
            "2022-11-30 13:35:02,542 epoch 9 - iter 171/193 - loss 0.57518395 - samples/sec: 0.71 - lr: 0.000001\n",
            "2022-11-30 13:36:49,040 epoch 9 - iter 190/193 - loss 0.56979070 - samples/sec: 0.71 - lr: 0.000001\n",
            "2022-11-30 13:37:04,026 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 13:37:04,026 EPOCH 9 done: loss 0.5743 - lr 0.000001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:26<00:00,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 13:37:30,898 Evaluating as a multi-label problem: False\n",
            "2022-11-30 13:37:30,904 DEV : loss 0.46722859144210815 - f1-score (micro avg)  0.6482\n",
            "2022-11-30 13:37:30,906 BAD EPOCHS (no improvement): 4\n",
            "2022-11-30 13:37:30,906 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 13:39:13,814 epoch 10 - iter 19/193 - loss 0.53720905 - samples/sec: 0.74 - lr: 0.000001\n",
            "2022-11-30 13:40:57,712 epoch 10 - iter 38/193 - loss 0.56221663 - samples/sec: 0.73 - lr: 0.000000\n",
            "2022-11-30 13:42:38,199 epoch 10 - iter 57/193 - loss 0.58304729 - samples/sec: 0.76 - lr: 0.000000\n",
            "2022-11-30 13:44:24,311 epoch 10 - iter 76/193 - loss 0.57824880 - samples/sec: 0.72 - lr: 0.000000\n",
            "2022-11-30 13:46:13,821 epoch 10 - iter 95/193 - loss 0.58562080 - samples/sec: 0.69 - lr: 0.000000\n",
            "2022-11-30 13:48:02,806 epoch 10 - iter 114/193 - loss 0.56670210 - samples/sec: 0.70 - lr: 0.000000\n",
            "2022-11-30 13:49:48,802 epoch 10 - iter 133/193 - loss 0.57123660 - samples/sec: 0.72 - lr: 0.000000\n",
            "2022-11-30 13:51:34,919 epoch 10 - iter 152/193 - loss 0.56817223 - samples/sec: 0.72 - lr: 0.000000\n",
            "2022-11-30 13:53:18,517 epoch 10 - iter 171/193 - loss 0.56762156 - samples/sec: 0.73 - lr: 0.000000\n",
            "2022-11-30 13:55:04,497 epoch 10 - iter 190/193 - loss 0.56048843 - samples/sec: 0.72 - lr: 0.000000\n",
            "2022-11-30 13:55:19,602 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 13:55:19,603 EPOCH 10 done: loss 0.5605 - lr 0.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:26<00:00,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 13:55:45,704 Evaluating as a multi-label problem: False\n",
            "2022-11-30 13:55:45,711 DEV : loss 0.4879798889160156 - f1-score (micro avg)  0.6458\n",
            "2022-11-30 13:55:45,713 BAD EPOCHS (no improvement): 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 13:55:47,663 ----------------------------------------------------------------------------------------------------\n",
            "2022-11-30 13:55:47,665 Testing using last state of model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [00:25<00:00,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-11-30 13:56:13,300 Evaluating as a multi-label problem: False\n",
            "2022-11-30 13:56:13,306 0.6446\t0.7618\t0.6983\t0.5473\n",
            "2022-11-30 13:56:13,307 \n",
            "Results:\n",
            "- F-score (micro) 0.6983\n",
            "- F-score (macro) 0.3655\n",
            "- Accuracy 0.5473\n",
            "\n",
            "By class:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Organisation     0.6606    0.7786    0.7148       140\n",
            "         Location     0.5934    0.7941    0.6792        68\n",
            "           Person     0.7568    0.9032    0.8235        62\n",
            "         Temporal     0.7826    0.9474    0.8571        19\n",
            "         Quantity     0.2778    0.3125    0.2941        16\n",
            "DocumentReference     0.3333    0.2500    0.2857         4\n",
            "           Weapon     0.0000    0.0000    0.0000         4\n",
            "            Money     0.0000    0.0000    0.0000         1\n",
            " MilitaryPlatform     0.0000    0.0000    0.0000         3\n",
            "      Nationality     0.0000    0.0000    0.0000         2\n",
            "\n",
            "        micro avg     0.6446    0.7618    0.6983       319\n",
            "        macro avg     0.3404    0.3986    0.3655       319\n",
            "     weighted avg     0.6282    0.7618    0.6879       319\n",
            "\n",
            "2022-11-30 13:56:13,307 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_score': 0.6982758620689655,\n",
              " 'dev_score_history': [0.010554089709762533,\n",
              "  0.33587786259541985,\n",
              "  0.5598845598845599,\n",
              "  0.5923984272608126,\n",
              "  0.6229508196721312,\n",
              "  0.6420765027322404,\n",
              "  0.6610169491525424,\n",
              "  0.6418732782369146,\n",
              "  0.6481994459833795,\n",
              "  0.6457765667574932],\n",
              " 'train_loss_history': [2.9750299324347216,\n",
              "  1.4151145429336154,\n",
              "  1.102379407128485,\n",
              "  0.8985091482578567,\n",
              "  0.7659444744710038,\n",
              "  0.7034005997481789,\n",
              "  0.6549618372841,\n",
              "  0.6058066446442902,\n",
              "  0.57429869816408,\n",
              "  0.5604896890343632],\n",
              " 'dev_loss_history': [1.2281770706176758,\n",
              "  0.859157383441925,\n",
              "  0.6455650925636292,\n",
              "  0.5550165176391602,\n",
              "  0.5053684711456299,\n",
              "  0.4809141457080841,\n",
              "  0.45765113830566406,\n",
              "  0.4889335632324219,\n",
              "  0.46722859144210815,\n",
              "  0.4879798889160156]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "\n",
        "# 4. initialize fine-tuneable transformer embeddings WITH document context\n",
        "embeddings = TransformerWordEmbeddings(model='xlm-roberta-large',\n",
        "                                       layers=\"-1\",\n",
        "                                       subtoken_pooling=\"first\",\n",
        "                                       fine_tune=True,\n",
        "                                       use_context=True,\n",
        "                                       )\n",
        "\n",
        "# 5. initialize bare-bones sequence tagger (no CRF, no RNN, no reprojection)\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=tag_dictionary,\n",
        "                        tag_type='ner',\n",
        "                        use_crf=False,\n",
        "                        use_rnn=False,\n",
        "                        reproject_embeddings=False,\n",
        "                        )\n",
        "\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 7. run fine-tuning\n",
        "trainer.fine_tune('resources/taggers/sota-ner-flert',\n",
        "                  learning_rate=5.0e-6,\n",
        "                  mini_batch_size=4,\n",
        "                  mini_batch_chunk_size=1,  # remove this parameter to speed up computation if you have a big GPU\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. run training with XLM parameters (20 epochs, small LR)\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "trainer.train('resources/taggers/ner-english-ontonotes-large',\n",
        "              learning_rate=5.0e-6,\n",
        "              mini_batch_size=4,\n",
        "              mini_batch_chunk_size=1,\n",
        "              max_epochs=20,\n",
        "              scheduler=OneCycleLR,\n",
        "              embeddings_storage_mode='none',\n",
        "              weight_decay=0.,\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_sentence = 'My name is Eugene, I currently live in Singapore, I work for DSO.'\n",
        "tagger: SequenceTagger = SequenceTagger.load(\"/content/model/conllpp/final-model.pt\")\n",
        "sentence: Sentence = Sentence(input_sentence)\n",
        "tagger.predict(sentence)\n",
        "print(sentence.to_tagged_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Zero-shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-12-12 12:14:09,599 loading file /home/digitalhub/.flair/models/tars-ner.pt\n",
            "2022-12-12 12:14:17,812 SequenceTagger predicts: Dictionary with 5 tags: O, S-entity, B-entity, E-entity, I-entity\n",
            "Sentence: \"My name is Clara , I live in Singapore , I work for DSTA and my monthly pay is S $ 3000 .\" → [\"Clara\"/Person, \"Singapore\"/Location, \"DSTA\"/Organisation, \"S $ 3000\"/Money]\n",
            "Sentence: \"Missiles and other explosives or ammonium nitrate are dangerous .\"\n",
            "Sentence: \"Ammonium nitrate was also used in the IRA 's bombing of London 's Canary Wharf in 1996 .\" → [\"IRA\"/Organisation, \"London\"/Location, \"Canary Wharf\"/Location]\n",
            "Sentence: \"These have included such naval craft as the ship of the line , battleship , submarine , and aircraft carrier ; aircraft such as the fighter , bomber , and helicopter ; and ground vehicles such as the chariot and tank .\"\n",
            "Sentence: \"George Washington went to Washington\" → [\"George Washington\"/Person, \"Washington\"/Location]\n"
          ]
        }
      ],
      "source": [
        "from flair.models import TARSTagger\n",
        "from flair.data import Sentence\n",
        "\n",
        "# 1. Load zero-shot NER tagger\n",
        "tars = TARSTagger.load('tars-ner')\n",
        "\n",
        "# 2. Prepare some test sentences\n",
        "sentences = [\n",
        "            'My name is Clara, I live in Singapore, I work for DSTA and my monthly pay is S$3000.',\n",
        "            'Missiles and other explosives or ammonium nitrate are dangerous.',\n",
        "            'Ammonium nitrate was also used in the IRA\\'s bombing of London\\'s Canary Wharf in 1996.',\n",
        "            'These have included such naval craft as the ship of the line, battleship, submarine, and aircraft carrier; aircraft such as the fighter, bomber, and helicopter; and ground vehicles such as the chariot and tank.',\n",
        "            'George Washington went to Washington'\n",
        "            ]\n",
        "\n",
        "\n",
        "# 3. Define some classes of named entities\n",
        "labels = ['Organisation' , 'Location' , 'Person' , 'Temporal' , 'Quantity' , 'Weapon', 'Document Reference', 'Military Platform' , 'Nationality' , 'Money'] \n",
        "tars.add_and_switch_to_new_task('task 1', labels, label_type='ner')\n",
        "\n",
        "# 4. Predict for these classes and print results\n",
        "for i in sentences:\n",
        "    sentence = Sentence(i)\n",
        "    tars.predict(sentence)\n",
        "    print(sentence.to_tagged_string(\"ner\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training TARS model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ColumnCorpus' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [4], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m data_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity-recognition-datasets-master/data/re3d/CONLL-format/data/splits\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# init a corpus using column format, data folder and the names of the train, dev and test files\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m corpus: Corpus \u001b[38;5;241m=\u001b[39m \u001b[43mColumnCorpus\u001b[49m(data_folder, columns,\n\u001b[1;32m     28\u001b[0m                               train_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.conll\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m                               test_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.conll\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     30\u001b[0m                               dev_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval.conll\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 3. what label do you want to predict?\u001b[39;00m\n\u001b[1;32m     34\u001b[0m label_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ColumnCorpus' is not defined"
          ]
        }
      ],
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import TREC_6\n",
        "from flair.models import TARSTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "# 1. define label names in natural language since some datasets come with cryptic set of labels\n",
        "label_name_map = {'Organisation': 'Organisation', \n",
        "                    'Location': 'Location',\n",
        "                    'Person': 'Person',\n",
        "                    'Temporal': 'Temporal',\n",
        "                    'Quantity': 'Quantity',\n",
        "                    'Weapon': 'Weapon',\n",
        "                    'DocumentReference': 'Document Reference',\n",
        "                    'MilitaryPlatform': 'Military Platform',\n",
        "                    'Nationality': 'Nationality',\n",
        "                    'Money': 'Money'\n",
        "\n",
        "                  }\n",
        "\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner'}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = 'entity-recognition-datasets-master/data/re3d/CONLL-format/data/splits'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.conll',\n",
        "                              test_file='test.conll',\n",
        "                              dev_file='val.conll')\n",
        "\n",
        "\n",
        "# 3. what label do you want to predict?\n",
        "label_type = 'ner'\n",
        "\n",
        "# 4. make a label dictionary\n",
        "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
        "\n",
        "# 5. start from our existing TARS base model for English\n",
        "tars = TARSTagger.load(\"tars-ner\")\n",
        "\n",
        "# 5a: alternatively, comment out previous line and comment in next line to train a new TARS model from scratch instead\n",
        "# tars = TARSClassifier(embeddings=\"bert-base-uncased\")\n",
        "\n",
        "# 6. switch to a new task (TARS can do multiple tasks so you must define one)\n",
        "tars.add_and_switch_to_new_task(task_name=\"ner\",\n",
        "                                label_dictionary=label_dict,\n",
        "                                label_type=label_type,\n",
        "                                )\n",
        "\n",
        "# 7. initialize the text classifier trainer\n",
        "trainer = ModelTrainer(tars, corpus)\n",
        "\n",
        "# 8. start the training\n",
        "trainer.train(base_path='resources/taggers/trec',  # path to store the model artifacts\n",
        "              learning_rate=0.02,  # use very small learning rate\n",
        "              mini_batch_size=32,\n",
        "              mini_batch_chunk_size=4,  # optionally set this if transformer is too much for your machine\n",
        "              max_epochs=150,  # terminate after 10 epochs\n",
        "              )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "flair.set_seed(123)\n",
        "\n",
        "# load your corpus (example is for WNUT 2020, downsampled to 1% of data)\n",
        "corpus = NER_ENGLISH_WNUT_2020().downsample(0.01)\n",
        "dictionary = corpus.make_label_dictionary('ner')\n",
        "print(dictionary)\n",
        "\n",
        "# init the TARS sequence tagger\n",
        "tars_tagger: FewshotClassifier = TARSTagger.load('tars-ner')\n",
        "\n",
        "# add a new task\n",
        "tars_tagger.add_and_switch_to_new_task(task_name=\"lab report NER\",\n",
        "                                       label_dictionary=dictionary,\n",
        "                                       label_type=\"ner\")\n",
        "\n",
        "# train the model\n",
        "trainer = ModelTrainer(tars_tagger, corpus, optimizer=torch.optim.AdamW)\n",
        "\n",
        "trainer.train(\n",
        "    f'resources/taggers/few-shot-sequence-tagger-wnut2020',\n",
        "    learning_rate=5e-6,\n",
        "    mini_batch_size=2, # set this higher if you have a big GPU\n",
        "    max_epochs=10,\n",
        "    embeddings_storage_mode=\"none\",\n",
        "    weight_decay=0.,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "a6a6a43afd82b9c8d81670bbd4cadbd88e22e52abfa29754676dca3e7b854911"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
